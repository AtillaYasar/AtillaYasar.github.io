[
  [
    "yea, I got animal, anthro, furry in uc on the furry model but every now and then a creature slips in through the cracks",
    "You'll want `feral`. That's the 'animal' tag.",
    "y22-m11-d11",
    "nsfw-discussion"
  ],
  [
    "Good for fanfiction I guess",
    "Rarely good even for fanfiction, as it tends to make the name ratio very unbalanced. And then you run into the Count Grey problem, with the same character popping up everywhere. Two characters if you're lucky.",
    "y22-m11-d08",
    "module-discussion"
  ],
  [
    "How would you format their appearance in the entry?",
    "Can include that in `Attributes:`, or add a separate `Appearance:` field.\n...honestly, I no longer remember what went in Euterpe, so not sure which works best. It was ages ago.",
    "y22-m11-d07",
    "novelai-discussion"
  ],
  [
    "is there a way to get the AI to properly read the entry logs in the lorebook? I have a party of three with a half-elf in it but the AI keeps getting him confused with another character's name.",
    "Not with complete accuracy. But there are various tricks to make it work better, such as adding a short 'active characters' list to Memory. ```\n----\nCharacters:\nGorran: small description, something simple like `Male half-elf, warrior, party leader`\nName#2: -\"-\nName#3: -\"-\n***```",
    "y22-m11-d07",
    "novelai-discussion"
  ],
  [
    "honestly, probably *every* specific name it spits out comes from somewhere, at some point",
    "Challenge accepted.",
    "y22-m11-d07",
    "novelai-discussion"
  ],
  [
    "they are known to be particularly aggresive",
    "Dunno how much stock I'd put to that, considering that most of that research comes from whaling nations. Kind of feels overplayed on part of that industry, for the purpose of making people not care about dolphin hunting.",
    "y22-m11-d07",
    "nsfw-discussion"
  ],
  [
    "If you clear all the text from a story but keep the same settings, does it mess anything up or is it a clean start?",
    "Clean. In the sense that the AI will disregard the old outputs. Though they'll still remain in the tree, and can be undoed to.",
    "y22-m11-d07",
    "novelai-discussion"
  ],
  [
    "Hypernetworks. Far better modules to influence your stories",
    "I wouldn't go that far.\nBetter is subjective, as learning _too_ well can be a hindrance for some types of modules. For example, if it learns names too strongly, you won't be able to easily add your own characters.",
    "y22-m11-d06",
    "nsfw-discussion"
  ],
  [
    "But if for instance, 1 person is sitting and another one is standing",
    "Yea, boorus aren't designed with character-specific tagging. `sitting` just means that someone is sitting, doesn't specify if it's one character or all. Not to mention that a lot of content just isn't well-tagged... So can't expect the AI to be that consistent with it.",
    "y22-m11-d06",
    "nsfw-discussion"
  ],
  [
    "So if a city gets destroyed in my story, then *** happens and something completely different is being talked about, will the city being destroyed be brought up again?",
    "It might, but without a chapter header it's always hard to know where the AI is going. It might've even turned into some kind of '500 years in the future, after the apocalypse' scenario.",
    "y22-m11-d06",
    "novelai-discussion"
  ],
  [
    "Thanks for the reminder. I don't suppose there's much use for ---- with prose, I've noticed it has an all or nothing view to lb entries. It either copies the info direct into the story, or it takes a general approach and misses out the details while paraphrasing. Krake is better at all of it, which does make sense",
    "Right. `----` is mostly for mixed data\/prose, and for data-only (useful for generators.)\n(`----` does have other potential uses, such as using it for character lists and glossaries, but those are still weak in current Krake.)",
    "y22-m11-d06",
    "ai-writing-help"
  ],
  [
    "Ah I never visited e621",
    "Then it's worth pointing out that e621 is not just 'furry'. There's plenty of humanoids like orcs, monster girls, demons, angels, etc in that data. Once the full version is done, it'll likely be better at those than Anime (which is heavily focused on human-only content.)",
    "y22-m11-d06",
    "nsfw-discussion"
  ],
  [
    "still waiting for the DF steam release <:pepehands:838312017336336405>",
    "Actually, that just got announced. Dec 6th.",
    "y22-m11-d04",
    "novelai-discussion"
  ],
  [
    "Does it work better?",
    "Seems to work reliably. Guess whoever wrote that didn't think to check the tags.",
    "y22-m11-d03",
    "nsfw-discussion"
  ],
  [
    "Yes. And I tried clearing cache and I tried opening it on an incognito tab",
    "Tried another browser?",
    "y22-m11-d03",
    "novelai-discussion"
  ],
  [
    "Any tip's on how to get male's and female's to show up togther?",
    "`man on left, woman on right` is reliable, though it often gets left\/right mixed up. (Which I don't see as an issue. Even if you want it to be that specific, mirroring the result is easy enough...)",
    "y22-m11-d03",
    "nsfw-discussion"
  ],
  [
    "I notice the AI likes to skip time - is there a way to make it less likely to do so?",
    "This may sound counter-productive, but add some *** in the existing context, such as short five-minute skips. The longer it goes without a break, the more likely it is to try to insert one.",
    "y22-m11-d03",
    "ai-writing-help"
  ],
  [
    "Ironically the no-embed policy makes this the safest channel to peruse while at work",
    "Stickers still work, though. And I've seen some nsfw ones...",
    "y22-m11-d02",
    "nsfw-discussion"
  ],
  [
    "adult ads bring more money <:goosip:1004468272974008490>",
    "Do they, though? I've seen studies which claim that those just cause users to spend their money elsewhere..",
    "y22-m11-d02",
    "novelai-discussion"
  ],
  [
    "is croissant an austrian or french invention",
    "French. But croissants were supposedly based on this, which is Austrian.",
    "y22-m11-d02",
    "novelai-discussion"
  ],
  [
    "my first guess would be Wien",
    "German word for Vienna (Austria), which is where wieners originated.",
    "y22-m11-d02",
    "novelai-discussion"
  ],
  [
    "Yeah. As I said, abstinence increase your chances of prostate cancer. Nutting is also a good physical exercise",
    "Also good as stress relief (which is major, as suicide is one of the leading male death causes), reducing blood pressure, and for preventing future erectile dysfunctions.",
    "y22-m11-d02",
    "nsfw-discussion"
  ],
  [
    "guys i made it through day 1, are you proud?",
    "Not particularly. Not a fan of anyone subjecting themselves to unhealthy habits. (Studies show that those who nut daily live on average four years longer than those who abstain.)",
    "y22-m11-d02",
    "nsfw-discussion"
  ],
  [
    "Just for a silly role<:berk:837330926866268160>",
    "I'm assuming \u2014 hoping \u2014 that the Patreon consists mostly of folks who wanted to donate extra to NAI. Instead of just those who wanted a colored name.",
    "y22-m11-d01",
    "novelai-discussion"
  ],
  [
    "Does the AI do better with 1st person or 3rd person? (At least with Euterpe.)",
    "As _Okeri said. But it also depends on what you're writing.\nFirst person is dominant in young adult fiction and light novels, so it's slanted towards more terse and action-packed prose than third person. And while it is easier to get the models to generate verbose prose in third person, that's not what everyone wants. So I wouldn't universally recommend third.",
    "y22-m10-d31",
    "ai-writing-help"
  ],
  [
    "Hello everyone.\nQuestion: Is it necessary to put `***` between metaprose in memory and lorebook (attribute style)? Or how to do it right?\nHere is my example:\n\n[ ATTG ]  \nMetaprose\n\\*\\*\\*\nLorebook\n----\nLorebook \n----\nLorebook \n\\*\\*\\*\nStory",
    "If those `Lorebook` are in data-style, then the first `***` should be `----` instead.",
    "y22-m10-d31",
    "ai-writing-help"
  ],
  [
    "How big is default bias? Tried to find it bit ago and couldn't find it. <:minakothonk:665924889009455105>",
    "I don't know. Settings aren't my area.",
    "y22-m10-d31",
    "ai-writing-help"
  ],
  [
    "<@409511804293611530> so i redid the discord, where do you want this channel",
    "Well... not OFF-TOPIC, and this may be too technical for CHATTING. So NOVEL AI CONTENT might be the best fit.",
    "y22-m10-d31",
    "community-research"
  ],
  [
    "But it does creepy stuff so well too.",
    "",
    "y22-m10-d30",
    "novelai-discussion"
  ],
  [
    "auto quality is just masterpiece and best quality added in front?",
    "Yes. And it's good to still have those somewhere in the prompt. I just don't like to start the prompt with those, puts too much focus on that instead of the subject.",
    "y22-m10-d30",
    "novelai-discussion"
  ],
  [
    "Is it recommended to remove the standard UC filter in general? Never played around with it <:thonk:845080036478550036>",
    "I can get better results by building my own UC list. But it's definitely for advanced users.",
    "y22-m10-d30",
    "novelai-discussion"
  ],
  [
    "there are 2? NovelAi underground or Unofficial NSFW NovelAi?",
    "Why not both? ...I prefer Underground despite it being less active. There are some folks on Unofficial that are a bit too eager to filter things that don't need filtering by Discord rules.",
    "y22-m10-d30",
    "nsfw-discussion"
  ],
  [
    "yeah the randomness is very low there",
    "Also Top-K 20. ...yea, it's restrictive.",
    "y22-m10-d29",
    "novelai-discussion"
  ],
  [
    "This might sound dumb but is there a module information page? Like describes what types of content some of the default modules contain? Some seem pretty obvious and others not so much,",
    "Which ones are unclear?",
    "y22-m10-d29",
    "novelai-discussion"
  ],
  [
    "i mean [ Genre: erotica ]",
    "Nowadays erotica is a vague and poorly defined genre. You'll generally get better results with `[ Tags: nsfw ]`. `[ Genre: erotica ]` seems to trend towards softcore and short scenes.",
    "y22-m10-d29",
    "nsfw-discussion"
  ],
  [
    "my character is pretty much completely expendable and only summoned to act as a meat shield",
    "That'd be multiple traits. `self-centered`, `callous` or `uncaring`, `entitled` if he actually is in superior position, etc... `cruel` or `cold` might work too, in a mix.",
    "y22-m10-d29",
    "ai-writing-help"
  ],
  [
    "Or look around at the modules people were into LOL",
    "Yea, that's been useful at least. Though not everyone lists the contents.",
    "y22-m10-d28",
    "novelai-discussion"
  ],
  [
    "I want to generate backgrounds, but some generic anime girl is placed in each one. How do i stop this?",
    "`scenery`",
    "y22-m10-d28",
    "novelai-discussion"
  ],
  [
    "as long as I can access it, I was just giving you some details if you need to fix it",
    "You could switch to Brave. It's almost identical (except for additional privacy and ad blocker features) and you can import everything from Chrome.",
    "y22-m10-d28",
    "novelai-discussion"
  ],
  [
    "yeah trying to get nai to make a face that isn't completely immaculate or ugly as a troll",
    "I don't have much trouble with that. Unless you count something like this as 'ugly as a troll'. Selecting the right artist helps a lot.",
    "y22-m10-d28",
    "novelai-discussion"
  ],
  [
    "Can we instruct the image gen to look for a negative prompt like in that one creepypasta",
    "It can already do negatives via prompt mixing (the following is `human, photo:1|happy:-0.3`), but I'm not sure if that's what you meant.",
    "y22-m10-d27",
    "novelai-discussion"
  ],
  [
    "Anyone else getting an internal error right now?",
    "Restart your browser. If that doesn't fix it, you may need to clean the cache - but careful with that, it'll erase your stories if you have them saved locally.",
    "y22-m10-d27",
    "novelai-discussion"
  ],
  [
    "<:risitas:837136229010243654> When that happened I was talking about the title in ATTG but didn't make it at all clear, that confused me at the time",
    "Figures. I rarely have time to read the whole conversation. My bad.",
    "y22-m10-d26",
    "ai-writing-help"
  ],
  [
    "Oh, so it doesn't really matter if I undertilise it? Good! :') Though I noticed it mentioned `Title` as having a lot of influence (the rentry guide did) yet Zaltys said `Title` is purely cosmetic before",
    "I was talking about the story Title, not the Title in ATTG. Confusing, I know.",
    "y22-m10-d26",
    "ai-writing-help"
  ],
  [
    "How does these prompts work?",
    "First row in Memory, that's all it needs.",
    "y22-m10-d26",
    "nsfw-discussion"
  ],
  [
    "Aight it sucks",
    "Try with `[ Author: Joe Abercrombie, Brandon Sanderson ]`.",
    "y22-m10-d26",
    "nsfw-discussion"
  ],
  [
    "uh, should I turn off bad anatomy if I want a nine tailed fox? I'm assuming it wouldn't matter, considering tails aren't really human anatomy, but still",
    "Yep. It's a hindrance if you're trying to generate non-humans, as it'll try to vector towards a 'normal human'.",
    "y22-m10-d26",
    "novelai-discussion"
  ],
  [
    "I used to live in central stockholm and basically the water in the tap there comes out with a heap of limy crappy water and then has this almost oily texture to it.",
    "I used to have that in my old apartment. It was from decades old hot water heater that needed replacement.",
    "y22-m10-d26",
    "novelai-discussion"
  ],
  [
    "Tied for 11th <:sadge:980995949209993248>",
    "Anything above 90 is probably fine. ...hm. Canada is 88.",
    "y22-m10-d26",
    "novelai-discussion"
  ],
  [
    "not sure if what Zaltys said is still true in Euterpe, but it's still the same soft-prompt. It's not like I did anything much in 700< steps area",
    "It isn't. That got fixed ages ago.",
    "y22-m10-d26",
    "module-discussion"
  ],
  [
    "ive been just doing [ Tags:  ]   do i have to use the ATTG format with the semi colons ? if its any better at all ill do it",
    "Nope, single category is fine if you have nothing to put in the others. I tend to only use Tags and Genre myself. Author and Title have limited uses.",
    "y22-m10-d26",
    "novelai-discussion"
  ],
  [
    "\"Local teen girl simps for fictional men\"",
    "",
    "y22-m10-d25",
    "novelai-discussion"
  ],
  [
    "No plans for image gen modules at this time.",
    "^",
    "y22-m10-d25",
    "novelai-discussion"
  ],
  [
    "That I did not know",
    "Trying to figure out where Kurumuz said that. ...oh, in furry-central. <:kek:692062611659030548>\nhttps:\/\/discord.com\/channels\/836774308772446268\/975739920306036766\/1011204038391517364",
    "y22-m10-d25",
    "novelai-discussion"
  ],
  [
    "I had been using a \"Characters In Scene:\" bit in memory, but I may have to switch to this.",
    "Can combine it. ```Characters:\nChar #1: summary.\nChar #2: summary, etc.```",
    "y22-m10-d25",
    "novelai-discussion"
  ],
  [
    "If training % is at 70% for example, does that still affect output or does it need to get to 100% to be able to affect the response?",
    "Training at less than 100% simply means that some of material goes unused, at random. If you want to train for lower steps, I'd recommend pruning down the data, as that gives you better control over exactly what gets included.",
    "y22-m10-d25",
    "module-discussion"
  ],
  [
    "Training my first module today and would love to know if this looks like a positive or negative result. Not sure what a **good** graph looks like in practice.",
    "Impossible to say without knowing the % trained.",
    "y22-m10-d24",
    "module-discussion"
  ],
  [
    "Gen X were already in adulthood by the time it rolled around. Primarily anyway.",
    "Not all of us. <:shrug:332268181517238272>",
    "y22-m10-d24",
    "novelai-discussion"
  ],
  [
    "I feel like the younger generations are usually the ones to lead early adoption of new tech.",
    "Someone born in 1980 (Gen X) was only 2 when ZX Spectrum was popular.",
    "y22-m10-d24",
    "novelai-discussion"
  ],
  [
    "Considering the Millennial generation was the first to grow up with computers, I'd disagree.",
    "Gen X.",
    "y22-m10-d24",
    "novelai-discussion"
  ],
  [
    "I only have one tab open <:cry:837394871672111124>",
    "Meh. Guess that's not it, then. ...the errors stopped for me when I closed the other tabs.",
    "y22-m10-d24",
    "novelai-discussion"
  ],
  [
    "Anyone else having connectivity issues with Krake? <:SadHolo:837316963575136327>",
    "Do you by any chance have multiple tabs open?",
    "y22-m10-d24",
    "novelai-discussion"
  ],
  [
    "And somebody will still complain about it <:schizo:837170919448248331>",
    "Probably mods, for having to moderate it. (At least Clyde's pretty good at pruning nsfw. Too good, maybe.)",
    "y22-m10-d24",
    "novelai-discussion"
  ],
  [
    "is there a rule of thumb regarding how many steps you should train at?",
    "No. Depends too much on what you're planning to train.",
    "y22-m10-d24",
    "module-discussion"
  ],
  [
    "But what if I use it before starting anew story",
    "Yep, that's good. Same effect as putting it in Memory.",
    "y22-m10-d24",
    "novelai-discussion"
  ],
  [
    "I heard putting tags is actually GOOD",
    "It's bad in AN. ATTG starts a new story, so that'll cause memory issues for things further down in the context.",
    "y22-m10-d24",
    "novelai-discussion"
  ],
  [
    "My stories are about self inserts and they're very personal",
    "As long as you're not going to publish them...",
    "y22-m10-d24",
    "novelai-discussion"
  ],
  [
    "I was going to have a character make a `:|` facial expression, only to realize that won't work. How do?",
    "I don't think we have one. But you can use the `\ud83d\ude10` emoji. ...or `\ud83d\ude11` might work better.",
    "y22-m10-d23",
    "novelai-discussion"
  ],
  [
    "I mean, I imagine if we're messing with it we're using our free time to do so. Can just try at the next time slot and check in for updates.",
    "Yep. And then when the same repeats on the next day, it's bound to get annoying. 'Why did I pay for this if it never works when I have time for it?'",
    "y22-m10-d23",
    "novelai-discussion"
  ],
  [
    "I just go by stuff happens, they're on it, if I can't mess with it I'll do other stuff until it's back like chat here or, god forbid, go outside. If it persists I'll want an update but stuff gets complicated and some things aint a quick fix",
    "People have schedules. They can't necessarily just 'do other stuff' and try again later.",
    "y22-m10-d23",
    "novelai-discussion"
  ],
  [
    "true, but only for moments",
    "Which is unfortunate if those moments are the only time you can spare the time to use NAI. I can relate. Was busy working most of that time, then when I tried to take a break, Krake was unusably slow. <:shrug:332268181517238272>",
    "y22-m10-d23",
    "novelai-discussion"
  ],
  [
    "Why is the AI so wacky? It's the third time it thinks I'm gay when I'm getting downed by a girl bro what \"She moves further down my body and licks me.\nFuck! Why is this happening? I'm not gay! I don't even like girls! How come my dick is hard?!\"",
    "What are you even using for it to go _that_ wrong? (As in model\/preset?)",
    "y22-m10-d23",
    "nsfw-discussion"
  ],
  [
    "Just in the folder where it's installed?\n\nI don't have any modifications, installed notepad++ for this purpose",
    "Let's see... should be something like `C:\\Users\\YourUsername\\AppData\\Roaming\\Notepad++`",
    "y22-m10-d23",
    "module-discussion"
  ],
  [
    "What would be better? Training on a lot of small stories or on a couple of the large ones?",
    "Smaller. So it doesn't overtrain names.",
    "y22-m10-d22",
    "module-discussion"
  ],
  [
    "and train with like, 10k steps",
    "No, it checks the total file size.",
    "y22-m10-d22",
    "module-discussion"
  ],
  [
    "can u generate ihop with nai diffusion?",
    "Not quite the same...  I'm not sure which tags to use for food.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "Sorry for the Discord question, how do you put the emoji in the dark background? Backticks just give me `:rabbit2::crown:`.",
    "Add the backticks first, then the emoji between those. ...or what pume said, yea.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "this effect is very strong. UC\/quality tags\/curated model are super nice for just generating good images and if you dont want to spend a lot of time and effort crafting the prompt and custom UC, but if you want something specific, the first thing you should do is go vanilla",
    "Absolutely. I recommend playing around with UC of None and building your own list. Many of the tags in the default UC are not strictly necessary, and pruning those out allows for more varied styles.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "I'm new to this ai image generation but I have a question does the ai able to pick up very specific descriptions (example: Hairstyles, Background)",
    "Backgrounds, yes. `scenery` is the main tag for detailed backgrounds in Anime, just combo with background elements.\nHairstyles... hard to find working names for them, beyond just `long hair, curly hair` etc.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "well it's pretty good at understanding natural language. no reason to be a slave to danbooru tags",
    "'course, even that will often go with...",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "Prose works in the box?",
    "It's still built on SD, which works okay with prose.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "`man with black hair, woman with red hair`",
    "That's more like it. Doesn't follow the tags at all, but nothing wrong in using prose.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "i found that if you want to specify which character has what hair color you can put it in brackets",
    "Sometimes works, but Danbooru's character count tagging is lacking. Will still frequently end up with one character.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "For instance, booru tags like `red hair` don't specify who has red hair. Only that someone in the image does. But if you add `black hair` too, the chances are that one character ends up with red and one with black hair.",
    "...or it might just generate this. (`red hair, black hair, 1girl, 1boy`)",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "you can kinda wrangle it by using tags to define how the two characters exist in the image",
    "That's the best that can be done, but still very random.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "if you describe one character in one, and another in the other",
    "It'll try to merge them.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "Is there a way to separate the parameters for 1girl and 1boy?",
    "No, because booru tag systems don't work that way.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "what's the pros and cons of high scale?",
    "I can't think of real pros for going too high on the scale.\nIt's like boiling an egg. Raw is no good, but neither is letting it boil for an hour.\nThe only reason it even goes that high is to let the users experiment.",
    "y22-m10-d21",
    "nsfw-discussion"
  ],
  [
    "does anyone know what to put in the memory or authors notes to make my world not have buildings and items and stuff.. my caveman people keep reading books and they gonna evole too quick i",
    "`[ Tags: stone age ]` in Memory should be more than enough... Unless you combine it with sci-fi elements, in which case all bets are off as it'll assume 'time travel'.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "Well, I'm using GPT-2 tokenizer for Krake and it still shows a good performance",
    "It will show Pile for Krake if you check the tokenizer. Maybe you checked with no stories active, in which case it's not actually on Krake.",
    "y22-m10-d21",
    "module-discussion"
  ],
  [
    "Ok, I jettisoned every potentially interferent tag and knocked the Steps down to 30",
    "Try the default 28\/11.",
    "y22-m10-d21",
    "nsfw-discussion"
  ],
  [
    "Last I checked (a few days ago), the UC presets were using username and not twitter username, from the network tab",
    "Metadata still shows twitter username.",
    "y22-m10-d21",
    "nsfw-discussion"
  ],
  [
    "Full, natch",
    "Zero issues here with those settings. You'd better double-check everything, including sampling. (`plms` for instance seems really bad at those.)",
    "y22-m10-d21",
    "nsfw-discussion"
  ],
  [
    "I'll take your word for it, I just copy and pasted the details",
    "If you check the metadata for the defaults, we use `twitter username`.",
    "y22-m10-d21",
    "nsfw-discussion"
  ],
  [
    "FYI, the prompts if you want everything but NSFW from Low Quality+ Bad Anatomy is {lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry}",
    "`twitter username` instead of just `username`. Adding `username` to UC seems to drastically reduce the quality, for some reason. (Probably because 'username' isn't a valid tag, whereas 'twitter username' is at 143k.)",
    "y22-m10-d21",
    "nsfw-discussion"
  ],
  [
    "Are there any alternatives to the \"NSFW\" tag (or workarounds within it) that don't just instantly strip like all the clothes off the girl's body?",
    "Easy. Just don't prompt with 'nsfw', especially not as the first tag, as that's way too generic and will default to similar content no matter what else you tag. Use tags from Danbooru instead.",
    "y22-m10-d21",
    "nsfw-discussion"
  ],
  [
    "They're using GPT-2 tokenizer, right?",
    "Can check by going to the Tokenizer. `The tokenizer for your currently selected model is the Pile Tokenizer.`, etc.",
    "y22-m10-d21",
    "module-discussion"
  ],
  [
    "What was the last really scary game with pixel art?",
    "https:\/\/www.youtube.com\/watch?v=wzTLPpAQpF8\nToo bad it never got finished.",
    "y22-m10-d21",
    "novelai-discussion"
  ],
  [
    "Humans are just too overwhelmingly prevalent in NovelAI's dataset.",
    "Fiction written by humans tends to be humanocentric. Much datasetting time has been spent looking for works featuring nonhuman protagonists. (Furry fiction and such tend to be unreliable in that regard. A lot of the time the authors seem to forget about it and just write them as humans, maybe mentioning fur or tail in couple of sentences.)",
    "y22-m10-d20",
    "ai-writing-help"
  ],
  [
    "just try disabling it",
    "I keep it disabled too. That setting places them first in the prompt, which makes them too strong for my tastes.",
    "y22-m10-d20",
    "novelai-discussion"
  ],
  [
    "Yeah, like anything describing characters a certain way",
    "Attributes.",
    "y22-m10-d20",
    "novelai-discussion"
  ],
  [
    "Do you do any character tagging metadata in the finetune, or is it all ATTG data that you put in?",
    "By character tagging metadata, you mean...?",
    "y22-m10-d20",
    "novelai-discussion"
  ],
  [
    "And so I'm asking how to apply that number to all words of a tag.",
    "You don't. Numbers are for prompt mixing.",
    "y22-m10-d19",
    "nsfw-discussion"
  ],
  [
    "just so we're clear, it's (tag with multiple words):1.5 when you want to use numerical strength, right?",
    "Can't say anything conclusive from that example. If you use it like that without pipes, then it does nothing. But not sure if that's what you meant.",
    "y22-m10-d19",
    "nsfw-discussion"
  ],
  [
    "still just servants, mostly for the evil guys",
    "Still servants, but.. https:\/\/www.goodreads.com\/en\/book\/show\/55577671",
    "y22-m10-d19",
    "novelai-discussion"
  ],
  [
    "Spoiler:||The dragon will become your best friend||",
    "Almost guaranteed. ...it's interesting how dragons have shifted from monsters to allies in modern fantasy.",
    "y22-m10-d19",
    "novelai-discussion"
  ],
  [
    "Yeah, the discord will have to change, it will end up in probably getting more channels or even make split offs, but that's a long ways away because there's maybe only 100 regulars here anyway\nIf it even has to happen it'll be months\/years down the line.",
    "...I still miss the games off-topic channel. Maybe we'll get that back one day.",
    "y22-m10-d19",
    "novelai-discussion"
  ],
  [
    "{black shirt|blue shirt}, {red skirt|green skirt} is returning black *or* blue *or white for some reason* shirts *and* skirts",
    "I don't know what you're trying to do, but `|` is for prompt mixing. That gets split into three different prompts.",
    "y22-m10-d19",
    "nsfw-discussion"
  ],
  [
    "The Stand is highly rated, but I doubt many folks read it",
    "720k user ratings on Goodread which puts it as third most-read King, but yea, hard to say how many actually finished it.",
    "y22-m10-d19",
    "novelai-discussion"
  ],
  [
    "It's easily one of Stephen King's most underrated works",
    "Fifth most rated King on Goodreads, with average of 4.20. Underrated. <:thonk:733040009136832642>\nOnly ones that beat it in ratings are The Stand, It, Carrie, and The Shining.",
    "y22-m10-d19",
    "novelai-discussion"
  ],
  [
    "I swear the AI hates the colour Gray\/Grey. I keep getting pink",
    "...can't replicate. It does 'grey' anything well, as far as I can see. (Dunno what's up with those sunglasses, though.)",
    "y22-m10-d18",
    "novelai-discussion"
  ],
  [
    "how do i make a poem in novelai",
    "`[ Style: poem ]` is also usually enough to generate one, at least in Krake. If you don't want to look up how to add an em space.",
    "y22-m10-d18",
    "novelai-discussion"
  ],
  [
    "There's a list of  Tags\/Genre here https:\/\/docs.google.com\/spreadsheets\/d\/1Jfxf10C_s8n4dcWYQ-kW_X1lVZEkz_ORSuEs-F3-v1U\/edit#gid=1099421859",
    "This is ancient, and it wasn't all that accurate even in Sigurd.",
    "y22-m10-d18",
    "ai-writing-help"
  ],
  [
    "Why is there an attributes attribute? What kind of attributes does that take",
    "Catch-all, like _Okeri said. ```----\nRamune\nAttributes: soft drink, bottled, Japanese, sealed with marble, carbonated, made since 1884, expensive, multiple flavors```",
    "y22-m10-d17",
    "ai-writing-help"
  ],
  [
    "Thank you! I'll try this and avoid using scene.",
    "If you want to really emphasize it, add something like `Summary: In this chapter, John eats an apple.` on the row after the chapter title. But that's an overkill, imo.",
    "y22-m10-d17",
    "ai-writing-help"
  ],
  [
    "Isn\u2019t there 1man too?",
    "Not an actual tag. The AI may understand it anyway, but all males are under `#boy(s)` tags in Anime.\n(Furry uses a much more logical `male` + character age tagging.)",
    "y22-m10-d17",
    "nsfw-discussion"
  ],
  [
    "Hello! I have a question that I have partially resolved by searching first, but I haven't found any consensus on the matter and was wondering if someone could please help me with the latest \"best practices\".\n\n**What's the best way to steer the AI?**\n\nWhen I write [Scene: John will eat an apple] or [Next: description of John eating an apple] the AI often treats this as if it had already happened and skips that scene.\n\nIf I teach it by sprinkling a few of these tags here and there as an example on previously played out scenes, then it mostly does it right but that forces me to keep putting the tags all over the story or to create several examples first.\n\nWhat's the best practice regarding this situation? Thank you!",
    "Yeah, that's to be expected. `Scene:` comes mostly from scripts, describing what's currently happening. Can't really use it for future events. Characters tend treat it as something that's already happened and react to it.",
    "y22-m10-d17",
    "ai-writing-help"
  ],
  [
    "I'm talking fantasy weapons like cool swords and stuff",
    "About this level. Getting someone to _hold_ a weapon correctly is pure luck, though.",
    "y22-m10-d17",
    "novelai-discussion"
  ],
  [
    "Is there a way I can stop the ai from generating *** and starting a new story?",
    "By using breaks in your existing context. If there's none, it puts major pressure on the AI to add them. 2048 tokens is a _lot_ without scene breaks.\nAlso, the writing gets worse if you ban them, as the AI struggles to try to figure out how to extend the scene long beyond where it should've ended.",
    "y22-m10-d17",
    "ai-writing-help"
  ],
  [
    "OH? The bot just uses Danbooru tags?",
    "Danbooru for Anime, e621 for Furry. Can also understand prose to some level.",
    "y22-m10-d17",
    "nsfw-discussion"
  ],
  [
    "It's good, better than a lot of digital artists online, and I draw too lol",
    "Sure, the quality is great overall. But getting it to output _exactly_ what you want?",
    "y22-m10-d17",
    "novelai-discussion"
  ],
  [
    "Meh, me and aini was letting it go off topic last night too to avoid people just mad about down time",
    "Yea, well, don't expect me to be reading this. Too busy working to keep up with this level of spam.",
    "y22-m10-d17",
    "novelai-discussion"
  ],
  [
    "You don\u2019t have the entire discord muted, are you high ?",
    "Keep the off-topic to <#847676684454592513>. Allowing it here will only make this harder to moderate in the future.",
    "y22-m10-d17",
    "novelai-discussion"
  ],
  [
    "Not really, would you rather have them talking about off topic stuff or bitching about the down time ?",
    "Considering that I'm already thinking of muting this channel... on-topic.",
    "y22-m10-d17",
    "novelai-discussion"
  ],
  [
    "But it\u2019s not on fire",
    "It is definitely on fire.",
    "y22-m10-d17",
    "novelai-discussion"
  ],
  [
    "Then furry is just a different variant of anime smh",
    "More western styles.",
    "y22-m10-d16",
    "novelai-discussion"
  ],
  [
    "Can we all agree that Calypso sucks?",
    "I could see it working for children's literature. But with Top K of 10 it won't ever output anything complex. <:shrug:332268181517238272>",
    "y22-m10-d16",
    "novelai-discussion"
  ],
  [
    "has anyone ever generated an among us image",
    "Completely failed when I tried it. Not enough of those on danbooru.",
    "y22-m10-d16",
    "novelai-discussion"
  ],
  [
    "Is it just me or can some things be drastically different with between Euterpe and Krake with Zaltys formatting?",
    "The amount of Attributes in Euterpe was minimal. After all, those were months apart.\nSame goes for ATTG. Minimal in Euterpe, expanded in Krake. (Further expanded since then, but not yet trained.)",
    "y22-m10-d16",
    "ai-writing-help"
  ],
  [
    "Okay, so, any luck making a realistic tortoise man? Anime Full makes just... Turtles, bald humans, or mutant amalgamations of shell and flesh.\nAs far as Furry, not familiar with it, but past attempts for \"REALISTIC\" came out like....",
    "You'll want `photo`, `real`, and `photorealism`. None of those are big tags, but help when combined. Can also use `photo background`, but that interferes with `amazing background` etc.",
    "y22-m10-d16",
    "novelai-discussion"
  ],
  [
    "bah, furries",
    "",
    "y22-m10-d15",
    "general"
  ],
  [
    "One of his alts is probably still here, make that one mod",
    "Probably not, since he just complained about not having access to this Discord elsewhere.",
    "y22-m10-d15",
    "novelai-discussion"
  ],
  [
    "I can add that it does Sylveon and Weavile decently",
    "As for quadrupeds, it's very good at Arcanine etc. Not really surprising when that's just a dog with different colors.",
    "y22-m10-d15",
    "novelai-discussion"
  ],
  [
    "NAI's struggling today <:SadHolo:837316963575136327>",
    "It being weekend probably doesn't help with the load. <:shrug:332268181517238272>",
    "y22-m10-d15",
    "nai-diffusion-discussion"
  ],
  [
    "pro writer moment\nit's MorPEKO it was mentioned only a single sentence ago oh my god",
    "Yep. Pro Writer has massive rep penalty, so it causes silliness like that.",
    "y22-m10-d15",
    "novelai-discussion"
  ],
  [
    "How? They can just magically make it faster?",
    "See the announcements. `Since most of our hardware is currently quarantined for investigational purposes, we cannot perform the more compute-intensive aspects of text generation at our usual speed and scale.`\nThat hasn't changed. These investigations take time.",
    "y22-m10-d15",
    "novelai-discussion"
  ],
  [
    "It would seem this is a complete failure.\nHowever, a simple `tag1 & tag2, tagA & tagB` is working effectively.",
    "I've mostly used `-`. As in `red-and-iridescent-orange-scales`.",
    "y22-m10-d15",
    "nai-diffusion-discussion"
  ],
  [
    "different question. \nsome people seem to think that doing. \nTag}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}} gives you finer control than just adding and removing per tag.",
    "Placebo. Was confirmed by the devs that it does nothing beyond adding dozen junk vectors. About as useful as adding a random keyboard smash in middle of the prompt.",
    "y22-m10-d14",
    "community-research"
  ],
  [
    "what would y'all say is just a general overall good number for steps\/scale? and what's up with the sampling? any point changing it from k_euler_ancestral?",
    "The defaults are good for Anime. For current Furry beta, I'd go with slightly lower steps and scale of 8 or 9.",
    "y22-m10-d14",
    "nai-diffusion-discussion"
  ],
  [
    "Any suggestions for how to properly \"clean\" a dataset?",
    "https:\/\/naidb.miraheze.org\/wiki\/Datasetting_for_AI_Modules#",
    "y22-m10-d14",
    "module-discussion"
  ],
  [
    "the thing is you are piling up your own work",
    "Not really. Can't keep up with new releases unless I actually work on them, you know.",
    "y22-m10-d14",
    "novelai-discussion"
  ],
  [
    "Is the performance getting better again right now for you?",
    "Just started to lag again.",
    "y22-m10-d13",
    "novelai-discussion"
  ],
  [
    "Thanks for the tip, is there any cuide about this ? Group:",
    "Same as on Danbooru, iirc.",
    "y22-m10-d13",
    "nai-diffusion-discussion"
  ],
  [
    "do you really have to have strength on either side?",
    "If it's missing, it'll default to 1.",
    "y22-m10-d13",
    "nai-diffusion-discussion"
  ],
  [
    "I mean, is `frog:0.5|1girl:2` equivalent to `[frog],{1girl}`?",
    "Not even close. `[Frog],{1girl}` is ~`frog:0.95|1girl:1.05`.",
    "y22-m10-d13",
    "nai-diffusion-discussion"
  ],
  [
    "And what does the `|` pipe do? Like brackets except you can be more specific?",
    "Prompt mixing. Needs the :# on both sides to work.",
    "y22-m10-d13",
    "nai-diffusion-discussion"
  ],
  [
    "imagine a bog standard cop seeing the prompts and tags loaded in for the full anime \/ furry modules <:risitas:837136229010243654>",
    "Fortunately, those aren't stored anywhere. So there's nothing to see.",
    "y22-m10-d13",
    "novelai-discussion"
  ],
  [
    "I am super excited about modules v2, but rather have that next year than a dev dying from exhaustion <:goosedead:850506859050958849>",
    "Bah. I work best under stress.",
    "y22-m10-d12",
    "module-discussion"
  ],
  [
    "how do u call these type of background... like europe streets?",
    "Something like this should work - `Paris, scenery, 1girl, close-up, street`",
    "y22-m10-d12",
    "nai-diffusion-discussion"
  ],
  [
    "Oh okay!  So that only works when doing a | ?",
    "Right.",
    "y22-m10-d12",
    "novelai-discussion"
  ],
  [
    "How much does putting a tag in braces enhance the effect?  What the difference between using braces and say... \"blonde hair:2\"?",
    "`blonde hair:2` does nothing on its own. That's for prompt mixing.",
    "y22-m10-d12",
    "novelai-discussion"
  ],
  [
    "<@409511804293611530> that's a issue I can't seem to wrap my head around. How long should the subject be? Is it just a single word for a person or should I just describe a total scene?",
    "Start with tags. And if you want to improve it, add a bit of prose etc at the end. It can handle 225 tokens, so might as well use that.",
    "y22-m10-d12",
    "nai-diffusion-discussion"
  ],
  [
    "When it comes to prompting the image gen is it better to use a short prompt followed by tags, or use tags keeping subject focus at the front? Ive tried both ways and gotten mixed results. Opinions?",
    "I've had the best results by using ridiculously long prompts. Subject first, 'course.",
    "y22-m10-d12",
    "nai-diffusion-discussion"
  ],
  [
    "I really hope we can make our own trainings\/modules for niche stuff",
    "The best chance of niche stuff getting in might be by contributing well-tagged material (that wasn't already included via Danbooru\/e621). I know Aero got some contributions for Furry.\nUnless it's illegal material. In which case we don't want it. Sorry.",
    "y22-m10-d11",
    "nsfw-discussion"
  ],
  [
    "What did i do wrong? (I'm new user)",
    "Try something like this in UC if you want to use `None` mode: `lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry`",
    "y22-m10-d11",
    "nai-diffusion-discussion"
  ],
  [
    "What did i do wrong? (I'm new user)",
    "Complete lack of UCs. Never good.",
    "y22-m10-d11",
    "nai-diffusion-discussion"
  ],
  [
    "text generations are taking over a minute for me, anyone else?",
    "Not quite a minute, but can confirm that it's not just you.",
    "y22-m10-d11",
    "novelai-discussion"
  ],
  [
    "\"photorealistic\" (but at least they got the hair and eye color right)",
    "That's still very Japanese in shading, etc.",
    "y22-m10-d11",
    "novelai-discussion"
  ],
  [
    "Does the tags have to include underscore?",
    "Underscores were trained as spaces.",
    "y22-m10-d10",
    "ai-writing-help"
  ],
  [
    "Anyway, to get on topic before the mods hit us, ME WOULD LIKE CUSTOM KRAKE MODULES. <:berk:837330926866268160>",
    "Aw. I like book talk. Gives me ideas for content that might've otherwise been missed. ||Enchiridion added.||",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "``The novel intertwines the discovery of the chemical structure of DNA with the musicality of Johann Sebastian Bach's harpsichord composition the Goldberg Variations. `` this I didn't expect \ud83d\ude04",
    "Now I wonder what'd happen if that got mixed with `G\u00f6del, Escher, Bach: An Eternal Golden Braid` into one module..",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "I see; thanks.\nI can still bias against \"white background\" I suppose since all the other backgrounds are evenly biased against but white more so",
    "For both Anime and Furry, `simple background` tag covers all single-color backgrounds.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "rip general chat?",
    "Reborn as general off topic.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "may I ask how I can separate phrases in the undesired content field? or does it bias against all these words all at once?",
    "Yes, it has negative weight for everything listed.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "Saaame. I just want Krake modules. So. Bad.",
    "Don't we all...",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "not an issue",
    "In that case... ```\n----\nAnkar\nAttributes: Bloodthirsty worm, Unpredictable and violent, Blind, I can even hear your sighs, Fatal bite and whipping tail\nHorrible: +2\nQuick: +4\nViolent: +3\nInstinctive: +1\nStunts:\nDrain Life: When successful in a Violent attack, Ankar can spend a fate point to impose the Weakness from drained blood aspect on the target, with two free invocations, besides the stress caused by the attack.\nSpeed up Regeneration: Only on its turn, Ankar can make an Instinctive roll against Good +3. Each shift achieved retrieves a resistance box. Its Quick approach drops to +2 until the start of its next turn.\nEvasion: Whenever it checks one of the Shaken, Hurt, or Giving in resistance boxes, Ankar can create the Hidden under the ground aspect with a free invocation. It dives to the ground, using this aspect to escape or to make a sudden attack.\nSummary: Giant exotic sand worm, known for drinking blood, and healing quickly. It is able to  burrow under the sand dunes.\nDescription: Ankar is an irrational and violent creature. Some cultures call it Soul Eater, for it uses its sharp tongues to drink the victim's blood. For their exotic nature, Ankar is usually used in fighting arenas, public appreciation, or underground stadiums. In some regions, tribes who fear its size and power see it as an Earth God. Legends say it reproduces by turning its human victims into an Ankar after drinking their blood.``` So `Summary:` instead of `Brief:`, and the description moved to the very end with no header needed. However, Euterpe is not particularly strong in Attributes. That'd be Krake, and since Krake lacks module training atm... <:shrug:332268181517238272>",
    "y22-m10-d10",
    "module-discussion"
  ],
  [
    "if i put together a small text doc, could someone look at it to make sure im understanding the module process right?",
    "Unfortunately, what you'll likely get out of module v1 with such data is a random creature generator in the same style. Instead of actually learning much about the specific species.",
    "y22-m10-d10",
    "module-discussion"
  ],
  [
    "can you let me know when the problem is solved?",
    "We'll make an announcement as soon as registration is working again. It'll be in <#837068173009223711>.",
    "y22-m10-d10",
    "ai-writing-help"
  ],
  [
    "what is novel ai offline mods?",
    "For new sign ups. \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574 \ub178\ub825\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.",
    "y22-m10-d10",
    "ai-writing-help"
  ],
  [
    "\ud68c\uc6d0\uac00\uc785\uc774 \uc548\ub418\uc694",
    "NovelAI \uad6c\ub3c5\uc740 \ud604\uc7ac \uc624\ud504\ub77c\uc778 \uc0c1\ud0dc\uc785\ub2c8\ub2e4. \ub098\uc911\uc5d0 \ub2e4\uc2dc \uc2dc\ub3c4\ud558\uc138\uc694.",
    "y22-m10-d10",
    "ai-writing-help"
  ],
  [
    "i'd expect it to be multiplicative if it says multiplied :P",
    "Yep.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "so to confirm, there's currently **no** other way than {} to strengthen the specific parts of a single prompt?",
    "You can use the same tag more than once.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "if anything i would expect them to be the same since the weighting isn't given to the model as is (in prompt), it's parsed first",
    ":1.05 does nothing, since it's always balanced to :1 and you have no other prompt.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "Clipboard works fine but it's not named correctly",
    "Yea, that's normal. No metadata on clipboard.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "<@129290683470053376> One more thing to add, while image generation seems to work, I cannot seem to download them",
    "Which method(s)? Download ZIP, or via the diskette? Clipboard should always work, at least.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "Oh so they *can* ban but at least content of your generations doesn't matter",
    "Considering that we can't even see it... no, doesn't matter.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "Sign in is also broken iirc",
    "First I've heard of that. I just logged in without any problems.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "How do I get the AI to stop trying to force my character into sex scenes<:KEKWait:837317734437617675>",
    "There's no simple solution to that. Depends too much on what you're doing.\nCould do some sort of flowchart, like...\n`Are you playing in Second Person? -> Switch to Third (optimally) or First.`\n`Are you using Cross-Genre or one of the other horny modules? -> Switch to No Module.`\nEtc.\nSometimes it's even the protagonists' name, which may be weighted from some nsfw fiction. Hard to say.",
    "y22-m10-d10",
    "nsfw-discussion"
  ],
  [
    "I mean, when I try background prompts, even those with only 100 examples, still do insanely well",
    "Backgrounds are already strong in the base.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "Wait... Is there an eagle Pok\u00e9mon? <:Thinkquil:912816501839523871>",
    "Braviary.",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "Y is general chat above nai now?",
    "Exactly what I was wondering. <:thonk:733040009136832642>",
    "y22-m10-d10",
    "novelai-discussion"
  ],
  [
    "Would it be a problem if the main character's lore entry is at exactly 200 tokens? I've basically reduced it as much as it can be reduced now.",
    "There's no need to limit it like that. I've used much larger entries. Though it depends on how many characters you want loaded at once.",
    "y22-m10-d09",
    "novelai-discussion"
  ],
  [
    "I still can't get dog on shirt",
    "",
    "y22-m10-d09",
    "novelai-discussion"
  ],
  [
    "If the tag has \"no\" in it, it's not like krake",
    "Even Krake is not 'like Krake'. Negatives work fine there too.\nPeople really need to let go of the whole \"don't use negatives\"-thing.",
    "y22-m10-d09",
    "nai-diffusion-discussion"
  ],
  [
    "Or make the expression softer.\nUsing happy or smile, the character's smile is too big, I want the corners of the mouth to be smaller",
    "Try `[coy]` for that.",
    "y22-m10-d09",
    "nsfw-discussion"
  ],
  [
    "Does the furry model allow female pokemon?",
    "Sure, but keep in mind that it's not great at rarer species. Only popular ones like Gardevoir, Lucario, Zoroark, Pikachu, Blaziken, etc work well. And you'll want to use the `anthro` tag (`humanoid` for Gardevoir) when generating those.",
    "y22-m10-d09",
    "nsfw-discussion"
  ],
  [
    "And is ALL UPPERCASE ok when it's meant as screaming?",
    "Yep. UPPERCASE check is mostly for the books where the chapters start with those. Need to be converted to proper case so it doesn't leak. Some false positives, as there's certainly valid uses for uppercase.",
    "y22-m10-d08",
    "module-discussion"
  ],
  [
    "Ctrl+1 marks me \"Sentence...\" and \\*Sound...*\nDo I need to worry\/fix those or is it fine if encased by \"\/*",
    "Shouldn't for the first one. You sure there's nothing wrong with it?\n***** will catch false positives if you've already marked sound effects with those, just skip past.",
    "y22-m10-d08",
    "module-discussion"
  ],
  [
    "Like can I get a closeup of just someone's eye?",
    "`eye shot`",
    "y22-m10-d08",
    "nai-diffusion-discussion"
  ],
  [
    "```\u2500 text: LitRPG data blocks```\ndo these go on their own Line? since there is no \"closing point\"?",
    "Consider how LitRPG data is normally written. ```\u2500 Vitality: 890\n\u2500 Strength: 760\n\u2500 Magic: 1,390\n\u2500 Spirit: 1,230\n\u2500 Agility: 980\n\u2500 Skills: Fireball (Spell)``````\u2500 Item: Poisoned Dart. Deals 1% poison damage per second.\n\u2500 Item: Boom Powder. This dangerous combustible creates intense heat when its core ingredients are combined. Inflicts burn damage.\n\u2500 Creature: Flesh-eating Worm. Invertebrates capable of devouring living flesh. Though not particularly fast, once burrowed beneath the skin, they can eat through both flesh and bone.``` Etc.",
    "y22-m10-d08",
    "module-discussion"
  ],
  [
    "Ok, other question. Can I give Notpad++ multiple search&replace tasks at once, like a list of tasks that it just works through one by one?",
    "Alt+F6 for new instances. Each function separately.",
    "y22-m10-d08",
    "module-discussion"
  ],
  [
    "Is there a regex I can use to clean up xml files?\nI'd like to create a module of a LN in epub format, which has the actual text parts in xhtml files.\nSo I need to remove all <p>...<\/p> thingys and move them onto newlines and replace all <em>...<\/em> with just the <> to make sure it's cursive.\n\nIs there some existing regex that I can use for that?",
    "I rarely need to do anything with xml, but I'd just convert to html and then to txt with Calibre.",
    "y22-m10-d08",
    "module-discussion"
  ],
  [
    "\ud83d\udc67\ud83d\udc80\ud83d\udc31\ud83d\udcbb is the prompt",
    "Yep, those are fun. Sometimes I use random emoji generator and just throw in a bunch to see what it comes up with.",
    "y22-m10-d08",
    "novelai-discussion"
  ],
  [
    "Will the airships module be specifically airship related or will it give just broad Steampunk stuff...because I need Steampunk\/industrial revolution.",
    "To be honest, that was one of the early test modules. As of now it's mostly 'airships'. In the future it will be shifted more towards steampunk in general.",
    "y22-m10-d08",
    "module-discussion"
  ],
  [
    "Will the AI understand if I'll use the word `jizz` instead of `cum`? Or this would require a lorebook entry?",
    "It should have no trouble with that. Mostly generated: ```[ Quiz Show ]\n\"We'll start with an easy one. What is the capital of Portugal?\" the host said in a rich baritone voice.\nI was so nervous that I instantly blurted out, \"Jizzbon!\"\nA booming laugh erupted from the audience. A few people clapped, and the host continued, \"Ah, but of course. It's Lisbon. Jeez! You have to take this quiz seriously.\"\nThe audience tittered again.```",
    "y22-m10-d08",
    "nsfw-discussion"
  ],
  [
    "What format should i export discord chatlogs in? to feed the machine",
    "```RhymeAndGrind: What format should i export discord chatlogs in? to feed the machine\nZaltys\ud83d\udc0d: This is fine.```",
    "y22-m10-d08",
    "module-discussion"
  ],
  [
    "I add `masterpiece` and `high quality` manually rather than using the toggle so I can adjust the strength.",
    "Yea, same. It's nice to have for new users, but I prefer being able to adjust the exact position and strength.",
    "y22-m10-d08",
    "novelai-discussion"
  ],
  [
    "For me to set up the monster manual style thing, how would it be best for me to format it so the AI knows the break between entries. My first assumption is *** for the chapter break, and just make sure the layout of each creature is the same.\n\nAlso, does anyone have an example of how to implement things like $input and $output? I've seen them in a few of the generator modules I've looked at",
    "Actually, if you're talking about monster entries that contain data, it'd be better to use `----`.",
    "y22-m10-d08",
    "module-discussion"
  ],
  [
    "Wouldn't a lot of the tags and authors still be valid?",
    "Not really. I can guarantee that a lot of those were never in the dataset, not even all the bolded ones. So at best it'd manage vague guesses of the style.\n...the list did give me some ideas for what to add back in the day, though.",
    "y22-m10-d06",
    "ai-writing-help"
  ],
  [
    "is there a wiki for this stuff?",
    "Click the question mark in the generator.",
    "y22-m10-d06",
    "nai-diffusion-discussion"
  ],
  [
    "twitter username? \ud83e\udd28",
    "Yea. What about it? It's one of the most common text-tags on Danbooru, and text is rarely good in generation.",
    "y22-m10-d06",
    "nai-diffusion-discussion"
  ],
  [
    "Alright, I'll give it a try!",
    "Actually, `scenery` first puts in a lot of greenery. Might want to move that further back.",
    "y22-m10-d06",
    "nai-diffusion-discussion"
  ],
  [
    "Any tips for university or college background?",
    "`scenery, university`",
    "y22-m10-d06",
    "nai-diffusion-discussion"
  ],
  [
    "anybody having trouble using the select feature on the editor",
    "Not sure exactly you mean, but it has been reported that some custom themes interfere with image gen.",
    "y22-m10-d06",
    "novelai-discussion"
  ],
  [
    "`Genre: Action; Tags: combat, violence, fighting, excitement, tension, and tension building.`",
    "Could work, maybe an overkill. The authors were already enough for this \u2014 could've used some rerolls, but it's certainly descriptive already.",
    "y22-m10-d06",
    "ai-writing-help"
  ],
  [
    "the ratio of \"girl\" to \"boy\" is pretty funny",
    "The default is a bit unbalanced, but at least it can draw men just as well when prompted.",
    "y22-m10-d06",
    "novelai-discussion"
  ],
  [
    "Birds are featherlies",
    "I've heard that before, but dunno how many actually call them that. And insects seem to mostly just go under insectoid.",
    "y22-m10-d06",
    "nai-diffusion-discussion"
  ],
  [
    "but yeah, storing all the details like step and seed and everything in the metadata is just *chef's kiss* now we just need a way to upload it back again",
    "Suggested that in testing, but ght901 was already too overworked to implement it.",
    "y22-m10-d06",
    "nai-diffusion-discussion"
  ],
  [
    "If your prompt is too long it doesn't save the whole thing in the name \ud83d\ude05",
    "You can always check the metadata, as long as the image is saved (via the floppy) instead of copied to clipboard etc. If you don't have a viewer, can just open it in text editor. The tags are near the top.\n||(Not sure if modern users even know what a floppy is.)||",
    "y22-m10-d06",
    "nai-diffusion-discussion"
  ],
  [
    "well, best way to push it towards a single character is to just use 1girl",
    "`solo` is good too.",
    "y22-m10-d06",
    "nsfw-discussion"
  ],
  [
    "Okay, now it works. I don't know why, but before, whenever I tried to prompt for someone who's black or african, I got someone who was very white or at the most tan",
    "Anime tends to be predominantly white. I've found that combining the nationality with `native`, as in `native Mexican` etc helps a lot.",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "hard to say, those pieces would have more detail when scaled down to the resolution used to train the model, presumably",
    "Yep, those'd generally have more 'detail', so I expect it to do something.",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "btw, i have a question: has anyone had any luck with metallic\/glass textures? i got it to work exactly once with the image bot with a stature of a bird and never again",
    "Try `raytracing`. Worked well for my robots, despite not being on the tag list. `shiny` too. ...or `shiny metal`? Can't remember which I used.",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "Is\n\"Poggers!\" She said\nor\n\"Poggers!\" she said\nmore grammatically correct? I've seen a few stories not capitalize after punctuation in quotes, but others do and grammarly doesn't tell me anything is wrong with either.",
    "`she`, as it's the same sentence.",
    "y22-m10-d05",
    "ai-writing-help"
  ],
  [
    "than Idk what is tbh",
    "In UK there was a profession called knocker-upper. They went around waking people up each morning, so they could get to work on time.\nThey got replaced by the invention of reliable alarm clocks. Was it unethical to invent an alarm clock?",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "Whoa was this using the new imagegen?",
    "That was with Furry.",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "Oh, can you confirm that tags are interpreted first strongest, last weakest?",
    "First ones should be strong, after that the order should be irrelevant.",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "Does {} in UC make it more strongly ignored or more strongly considered to occur",
    "Yep, those work there too.",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "Twitter username?",
    "Don't want random text popping up.",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "Is it non-linear like regular SD?",
    "As far as I know.",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "",
    "Something like this? `tan` and `dark skin`. Oh anime...",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "There is\n<https:\/\/safebooru.donmai.us\/wiki_pages\/traditional_media.html>",
    "Ah, it's `* (medium)` on Anime. Good to know. Tag completion has some issues with brackets. Can just type `(medium)` and get the whole list.",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "Is there a list for (artwork) tags?",
    "No, and trying to pull them from tag completion seems difficult. I haven't even used those much myself, I usually only UC `sketch`. Furry _seems_ to have better variety (`traditional media`, `digital media (artwork)`, `digital painting (artwork)`, etc.) but not sure.",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "So it was a rumor for now. Thank you.",
    "There's `digital media (artwork)`. Someone probably got them mixed up.",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "That's all? Thanks. Some mentioned tags like `pencil (medium)` exists, but I don't know whether it's real or not.",
    "There's quite a few style tags, but those weren't added. I don't think Anime has that one? Furry has `pencil (artwork)`.",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "that said, i personally don't like using 'masterpiece' because imo that's subjective",
    "Actually, the way it is baked in, it's not subjective at all.",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "What are interesting style prompt\/tags?",
    "Besides what was already listed, I like `official art` and `absurdres`.",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "I subbed right when servers got all messed up that might be the issue \ud83d\ude26 \noh well hopefully next month it works",
    "Nooo... please bring it up in <#1020000423228215306>. I'm sure the experts can find some fix for it, no need to wait a month.",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "One more question, when the 'recommended tags' menu pops up while entering tags, if the tag you're looking for isn't on the list or doesn't have an icon next to it, is there a point in using that tag? I'm assuming the whiter the circle icon the more the AI knows the tag, but I'm curious.",
    "Use of tags is not required, but they're useful for steering. Feel free to experiment with things that aren't listed.",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "Yes it looks normal. Any setting with a selectable option works. it's only the sliders and settings I can manually type in that aren't",
    "You probably already did, but try logging out and back in. Maybe it thinks that your sub has expired, or somesuch.",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "Dumb question but are some settings just not available right now? I can't interact with most settings like uploaded image settings, model specific settings, or add anything to undesired content",
    "This isn't normal. I assume you've already tried refreshing.",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "When using the brackets to emphasize\/de-emphasize tags, should the comma after the tag be included in the brackets or just the tag itself?",
    "Good question. Can't answer it, but it is clear that emphasizing just the comma does something, as you can easily test by trying `{{{{,}}}}`. But whether it's better inside or outside... <:shrug:332268181517238272>",
    "y22-m10-d05",
    "nai-diffusion-discussion"
  ],
  [
    "Gotcha. Hoping it's an issue of Anime just being better quality so they went with that, still kinda hoping for general-purpose soon even though I'm blown away by some of the anime results.",
    "From the announcement: `Therefore we have come to the decision to only offer our own unique models and forego the basic Standard Diffusion model`\nNAI unique models are Anime and Furry.",
    "y22-m10-d05",
    "novelai-discussion"
  ],
  [
    "huh, what kind of app would i need to see this (apart from N++)? I'd only tried the Windows properties dialog",
    "There are online viewers. First hits I got for `exif metadata viewer` seem to work.",
    "y22-m10-d04",
    "feedback-discussion"
  ],
  [
    "strongly opposed to that. Twitter is one thing. But in here we should promote people learning from each other how to use this tech",
    "Rough. I'm not going to post prompts for mine. Cope.",
    "y22-m10-d04",
    "novelai-discussion"
  ],
  [
    "we're talking about our perception of the real colors from that image",
    "If the perception (gold\/white) matches the color values, isn't that more correct in this case?\n...but yea, very off-topic.",
    "y22-m10-d04",
    "novelai-discussion"
  ],
  [
    "Clockwise",
    "||Both are equal. Your brain just interprets it one way. It can also switch if you look at it from different angle. Easiest to do by looking at the left foot.||",
    "y22-m10-d04",
    "novelai-discussion"
  ],
  [
    "\"spinning balerina\" would probably work better",
    "Oh great. Just had to remind me of this. (...which way does this spin?)\nhttps:\/\/upload.wikimedia.org\/wikipedia\/commons\/2\/21\/Spinning_Dancer.gif",
    "y22-m10-d04",
    "novelai-discussion"
  ],
  [
    "any ideas on how to get the character further away from the \"camera\"?",
    "Another trick: use `scenery` (or `detailed background` in furry). Although that can make them too small without other additions, it's worth it as it tends to improve the overall quality.",
    "y22-m10-d04",
    "nai-diffusion-discussion"
  ],
  [
    "Krake is more responsive to such things?",
    "Yes. Krake is newer, so it has more tricks baked into it.",
    "y22-m10-d04",
    "ai-writing-help"
  ],
  [
    "Is there a way to direct Euterpe as to how detailed a process is described?  I want a character to plant a seed, and it always generates stuff like \"She planted the seed.\"  Can I tell it to make it more granular like digging a hole in the soil, dropping the seed in the hole, etc.?",
    "It uses the style that's already in the context. So if that's terse, then so is the generated output. Using a preset that heavily limits the token pool \u2014 many of the default presets do \u2014 also reinforces this.\nYou can use tricks like `[ Style: verbose ]` in Memory, but this is not particularly effective in Euterpe.",
    "y22-m10-d04",
    "ai-writing-help"
  ],
  [
    "Adding to the spam, it turns out *NAI Diffusion Furry (Beta)* can approximate certain traditional styles, sort of.\nThis is \"`beautiful human woman with black hair depicted in the American impressionist style by Frank W Benson`\" with \"`furry, digital, anthro, smooth, digital`\" in *Undesired Content*. It is nowhere as good as <#1025226799040442448>, but it is better than nothing.",
    "It's better at humanoids (orcs, elves, zombies, demons, etc) than humans, btw.",
    "y22-m10-d03",
    "novelai-discussion"
  ],
  [
    "Hey guys, try \"corrected\" in your prompts",
    "Hard to say without major testing. I did just try it on a seed that had mangled anatomy, and it improved. But on the other hand, anything would've likely improved it...",
    "y22-m10-d03",
    "novelai-discussion"
  ],
  [
    "its different in Linux, specifically its Ctrl+shift+u",
    "Ah, good to know. Guess things can never be easy... Would be too simple if it was Alt on everything.",
    "y22-m10-d03",
    "ai-writing-help"
  ],
  [
    "its NOT alt+ctrl+shift+u",
    "Yea, Alt + 2500 on keypad. (Sucks if you don't have a keypad. And not while in Discord, that activates some hotkeys.)\nAnother way to get it to output for copy-paste is to just play LitRPG module a bit. Or even faster, prompt it with something like `Suddenly, the GUI popped up:`",
    "y22-m10-d03",
    "ai-writing-help"
  ],
  [
    "`muscular female` tag <:dogeLick:837331647220809778>",
    "Give this a try. ```{{{1girl}}}, solo, long hair, red hair, beautiful, muscular, raytracing, cool pose, jrpg, concept art, looking to side, by James Jean, Kazuhiko Fukuchi, absurd res, {masterpiece}, best quality, bulked up, female bodybuilder, {{{{beefcake}}}}, {{{huge muscles}}}, Greek goddess, big breasts, bra, glistening muscles, hyper muscles:8|twink, short:-0.5``` (Tried to make Sakura from Danganronpa at one point...)",
    "y22-m10-d03",
    "nsfw-discussion"
  ],
  [
    "~~what is the symbol for LitRPG stats again? aka howto input it.~~ found it, \u2014",
    "Nooo.... That's em dash. That's used for things like someone getting interrupted while speakin\u2014\nYou want \u2500 (Alt + 2500) instead. We really need a better way to insert those. <:RWsnekcry:805426733398360064>",
    "y22-m10-d03",
    "ai-writing-help"
  ],
  [
    "What do the curly brackets do?",
    "Was in the announcements, but summarized: {} makes it stronger, [] makes it a bit weaker (but not negative, just weaker)",
    "y22-m10-d03",
    "novelai-discussion"
  ],
  [
    "still not working",
    "Oh, and it was in Anime Full.",
    "y22-m10-d03",
    "novelai-discussion"
  ],
  [
    "still not working",
    "Updated the prompt, check again.",
    "y22-m10-d03",
    "novelai-discussion"
  ],
  [
    "how",
    "`solo, broken robot, in pieces, lying down, metal body, haywire, raytracing, cool pose, jrpg, concept art, looking to side, by James Jean, Kazuhiko Fukuchi, absurd res, {masterpiece}, best quality`\nUC: `text, signature, jpeg artifacts, cropped, bad anatomy, worst quality, bad quality, twitter username, dated`\nNeeds some tuning, though.",
    "y22-m10-d03",
    "novelai-discussion"
  ],
  [
    "I want to get it to draw a broken robot",
    "",
    "y22-m10-d03",
    "novelai-discussion"
  ],
  [
    "Can anyone do pineapple for me?",
    "",
    "y22-m10-d03",
    "novelai-discussion"
  ],
  [
    "Seriously, I am concerned if it just doesn\u2019t work for me. Maybe because I was too nervous to get anything from it",
    "Could be. It does have a lot to do with the mental state, after all. There's also some medication that will block it.\nBut yea, there's a reason why many prefer vibrators (or shower heads) over just hands.\nIf you're really worried, you can always ask your gynaecologist to check.",
    "y22-m10-d03",
    "nsfw-discussion"
  ],
  [
    "(edit: for Krake, use ---- instead of `***`, see https:\/\/discord.com\/channels\/836774308772446268\/919724433013346324\/1025884165108945028)\nI just whipped this up\n```Quest: Get the treasure from the dragon\nDescription: In the mountains to the southwest there sleeps a dragon deep within. If you are brave enough, go steal the dragon's hoard. Try not to die...\nReward: 50000 exp, plus the the hoard will make you rich!\n***\nQuest: Protect the village from the orcs.\nDescription: Thick forest and dense green earth make the village as safe inside as it can be. Keep it that way! You will have to defeat orcs with bows, sling, and arrows placed strategically around the village.\nReward: 3000 exp.\n***\nQuest: Recover crystal shard with magic.\nDescription: The shard can be found in the crystal cave the gods abandoned. The shard is an important component in the development of magic in this world.\nReward: 15000 exp, plus you find the magic crystal so it could be used by wizards later on.\n***\nQuest: Recover pendant with magic.\nDescription: The pendant was lost in the staff cave before largetooth creature attacked and it has been purified```",
    "In Krake you'll have better results with `----` instead of `***` for that style of random generation. After all, that's what `----` was originally intended for.",
    "y22-m10-d01",
    "ai-writing-help"
  ],
  [
    "Do some research before blaming it on them",
    "Us testers got a better view of the whole situation, and I wouldn't trust anything they told the users about that incident. That's all I'm saying about that.",
    "y22-m10-d01",
    "novelai-discussion"
  ],
  [
    "I have no idea what are good horror artists other than junji ito",
    "Try `by Nekro`. Not a real artist, but works great.",
    "y22-m10-d01",
    "novelai-discussion"
  ],
  [
    "I should have said from a small number of particularly entitled fans. That would have been more accurate.",
    "Like I've said before: let's not get into some 'we're better than Reddit because we don't complain' mindset.\nWe need complaining to know what to improve, and the reason why people complain is because they care about NAI.",
    "y22-m10-d01",
    "feedback-discussion"
  ],
  [
    "damn this place gotta nsfw chat",
    "Not that there's much going on here, due to most nsfw being on the dedicated servers. (Which are in the pins, btw.)",
    "y22-m09-d30",
    "nsfw-discussion"
  ],
  [
    "Even if you don't get naked people, `mature` is going to get your results flagged even if the result is somehow SFW",
    "Eh? `mature` tag is generally used for older folks on boorus. Not for nsfw.",
    "y22-m09-d30",
    "novelai-discussion"
  ],
  [
    "It looks like Zaltys was demonstrating the AI's ability to extrapolate prose from a short description in traits format. The screenshot seems to show an AI generation in the main text area.",
    "Yep. Don't put `***` inside data entries. There's no scene breaks in those. In the screencap the lb entry is everything before the `***`.",
    "y22-m09-d30",
    "novelai-discussion"
  ],
  [
    "Wait, should I have been doing this for my lore entries all this time?",
    "Meh. Not like it's required, but it helps.",
    "y22-m09-d30",
    "novelai-discussion"
  ],
  [
    "Does the module matter? Or should I just pick whatever suits the theme?",
    "As long as it's not Cross-Genre or one of other Sage's modules, it'll work. (Those lack formatting. Though I think he's using ATTG at least.)",
    "y22-m09-d30",
    "novelai-discussion"
  ],
  [
    "Are the ```---``` & ```***``` important?",
    "Yep. `----` (note: four) for data, `***` for prose.",
    "y22-m09-d30",
    "novelai-discussion"
  ],
  [
    "anyone know the artists that could be associated with these? the tags didnt save fully in the image name x3",
    "`anime art, young boy, little boy, black hair boy, wearing black Japanese Naval Uniform, official media, delicate facial features, tone mapping, Perfectionism, Accent Lighting, by Greg Rutkowski, Hayao Miyazaki, John Singer Sargent, intricate, finely detailed`",
    "y22-m09-d30",
    "novelai-discussion"
  ],
  [
    "So if I had lorebook entries for Debra, Cain, Gregetha, and Alice, I'd load in \n```\nCharacters:\nAlice: A cheerful young new hire just waiting to have her dreams crushed\nCain: Manager of McFlopskys Restaurant, terminally unaware of the sad state of his business\nDebra: A chef who speaks caveman grunts more fluently than English\nGregetha: An unfortunately named wage-slave with a monobrow\n```\n\nAnd it'd look at this and _possibly_ randomly pick one when I fed it a prompt like ``Alice heard footsteps approaching her, and when she turned she saw``\n\nBut this wouldn't overload my context with the lorebook entries for all of these characters at once, only loading them once the names were in the main text? Because I have like-... 40 to pick from in my lorebook now. And my context tends to top out rapidly since each is like, a small paragraph about 100 tokens long. \n\n~~(Though, obviously I made up these for this example; I don't think I'd be creative enough to write an entire sitcom with profiles for 40 main characters.)~~",
    "Okay, no, it won't work well with list _that_ long. I'd limit it to dozen or so, and even that's gonna need the right preset (ones with large token pool.) Gonna need scripting for more characters than that.",
    "y22-m09-d30",
    "ai-writing-help"
  ],
  [
    "I know NovelAI has a Valentines and Christmas module (and I coulda sworn there was an Easter one too, but I'm starting to think I might've been gaslighted into thinking that last one was a thing), but--if a Halloween one isn't already a thing--can we make it a thing?",
    "Would that not be somewhat redundant with `Horror`?",
    "y22-m09-d28",
    "module-discussion"
  ],
  [
    "And as has been discussed before the exact method or terms wouldn't be that much help anyway. There might be plenty of terms not in the data that will work well",
    "Not to mention that it depends so much on the usage. Character entry is different from locations, which is different from deities, which is different from species, objects, spells,...\nI've listed some fields that are in general use (like `AKA:`), but listing everything would be a major time sink.",
    "y22-m09-d27",
    "ai-writing-help"
  ],
  [
    "those are from the anime model right",
    "Yes.",
    "y22-m09-d25",
    "novelai-discussion"
  ],
  [
    "`[ Author: W. E. B. Griffin, Tom Clancy, Yuval Noah Harari, Som Bathla; Tags: realistic swordplay, office politics, military management; Genre: kingdom building, empire, legions, military action ]`\nThere, fixed it to better conform to the finetune.",
    "Pretty much, but most of those genres would fit better in Tags.",
    "y22-m09-d25",
    "novelai-discussion"
  ],
  [
    "hmm, so for example, a character died, i add that to the lorebook and keyword is that characters name, so when the ai brings the character up, it remembers its dead?",
    "I just add a single row to the end of the entry when someone dies, and it tends to work. ```(Main character entry)\nZaltys was killed by cats.```",
    "y22-m09-d25",
    "ai-writing-help"
  ],
  [
    "Just a generic talking animals story",
    "`[ Tags: animal protagonist; Genre: fantasy, animal fiction ]`",
    "y22-m09-d24",
    "ai-writing-help"
  ],
  [
    "That's a lot of buttons",
    "About 11600 words worth of edits per day.",
    "y22-m09-d24",
    "novelai-discussion"
  ],
  [
    "How much stuff do you add to the data set in like 2 weeks?",
    "Hard to say. Not like I keep exact track of it. But here's my work-stats for past week. (Only running the logger while working.)",
    "y22-m09-d24",
    "novelai-discussion"
  ],
  [
    "After once sentence? lmfao",
    "Some authors do that. Though it's mostly to show things happening at once from various viewpoints. For instance, Pratchett's Soul Music has some of those in one scene where things start to... escalate.",
    "y22-m09-d24",
    "ai-writing-help"
  ],
  [
    "how do you tell all the Bobs apart",
    "You don't.\nhttps:\/\/www.goodreads.com\/book\/show\/32109569-we-are-legion-we-are-bob",
    "y22-m09-d24",
    "novelai-discussion"
  ],
  [
    "<@409511804293611530> \ndo i put \"Chapter 1\" as a [Tag: ] or just \n> Chapter 1\n> [Author: ; Title: ; Tags: ; Genre: ]\nor do I have to put it in []\n> [Chapter 1]\n> [Author: ; Title: ; Tags: ; Genre: ]\nor would it havw to be placed after\n> [Author: ; Title: ; Tags: ; Genre: ]\n> [Chapter 1]\n\nsimilary, where do I put [Style: ]?\n\nbasically, TLDR: what would be the correct form here?\n> Chapter 1\n> [Author: ; Title: ; Tags: ; Genre: ]\n> [Style: ]",
    "As I said, don't use chapter numbering at all. Those don't exist in the data.",
    "y22-m09-d24",
    "ai-writing-help"
  ],
  [
    "interesting that prologues got pruned. i assume thats just because there are a lot of boring isekai prologues where its 3 pages of descriptions of a landscape?",
    "Well, no. It's to avoid overusing headers in training. The AI needed to learn to start the story with prose.\nWould be a problem if the only way it knew how to start a story were `[ Prologue ]`, when most users have brackets banned. Hence the preamble instead. (Which should never be disabled btw, even though settings allow that...)",
    "y22-m09-d24",
    "ai-writing-help"
  ],
  [
    "also i heard one shouldnt use more than ~3 tags, is that true?",
    "False. But if you put in tags that contradict each other, don't expect it to work well. Definitely easier to steer with fewer tags, but there's no hard limit. (And by tags, I mean `Tags:` in ATTG.)\nChapter numbering and such? That's useless, something like `Chapter 7` doesn't mean anything when authors have anything from two to 300 chapters in their works.",
    "y22-m09-d24",
    "ai-writing-help"
  ],
  [
    "but I feel china has more of their people with internet than india",
    "Maybe not for long. Looks like the percent of internet users in India went up from 41% to 47% in just one year.",
    "y22-m09-d23",
    "novelai-discussion"
  ],
  [
    "I seen cereal boxes with more variety than the personalities and plots of the average isekai these days",
    "That's not really new. Majority of old mecha anime was pretty bad, etc. As they say, 90% of everything is crap.",
    "y22-m09-d23",
    "novelai-discussion"
  ],
  [
    "one issue I've found is the ai doesn't know non modern clothing",
    "Yea, not sure I'd agree about that. It can generate period-appropriate clothing for anything I've thrown at it so far.",
    "y22-m09-d23",
    "novelai-discussion"
  ],
  [
    "Based on my friend's playthrough, it's very very nsfw",
    "So it is. Thought that Android doesn't allow nsfw \u2014 or maybe that version is heavily censored.\n...pretty bad quality overall, can't recommend.",
    "y22-m09-d23",
    "nsfw-discussion"
  ],
  [
    "nofap 7 months going strong",
    "You'll regret that when you get to my age. <:kek:692062611659030548>",
    "y22-m09-d23",
    "novelai-discussion"
  ],
  [
    "Is porn desensitization just like getting used to drug doses? Hmmmm",
    "I got bored of anime titties when I was like 20 or so.",
    "y22-m09-d23",
    "novelai-discussion"
  ],
  [
    "Would you recommend third, then? I imagine first has a similar problem.",
    "Yes. First person is usable, but light novel and young adult authors tend to favor it. So it's slanted that way and you have to put more effort into it to make it slow down.",
    "y22-m09-d23",
    "ai-writing-help"
  ],
  [
    "Interesting! Why no second person?",
    "Because hardly anyone writes in second person, except for certain types of fanfiction. And as such, there's no good training material for it.",
    "y22-m09-d23",
    "ai-writing-help"
  ],
  [
    "Text and Image definitely can't be put in the same bucket here yeah",
    "Yep. This is worth repeating.\nImages only. There'll be no filtering of text dataset, at least as long as I'm in charge of it.",
    "y22-m09-d22",
    "novelai-discussion"
  ],
  [
    "how to stop the ai from creating a new story using the *** thing?",
    "Put in a chapter title after the `***` to steer it. Something like `[ Five Minutes Later ]`.\nBanning it is not recommended, as any longer story requires scene breaks and banning them will degrade the output quality.",
    "y22-m09-d21",
    "novelai-discussion"
  ],
  [
    "how many tokens per lorebook entry? did you split entries per character class (paladin) and link to another card?",
    "No, like I said, all that in Memory. I don't use small lorebook entries, they mess up the logic too easily.",
    "y22-m09-d20",
    "novelai-discussion"
  ],
  [
    "but you use as one line per memory?",
    "Some Attributes, some prose, etc.",
    "y22-m09-d20",
    "novelai-discussion"
  ],
  [
    "so far i never use BIAS, have no clue in how to use it, even after all these months as subscriber lol",
    "No big loss. The only thing I've ever _really_ needed it for is when playing as non-humans.",
    "y22-m09-d20",
    "novelai-discussion"
  ],
  [
    "NAI does its best, but yes sometimes it can't _logic_ through what is intended.",
    "Especially when biases and bans (including the default `***` bias) are overused. When it can't output what it thinks is best, it devolves into nonsense.",
    "y22-m09-d20",
    "novelai-discussion"
  ],
  [
    "Bizarro?",
    "Genre, not the DC character. Tends to use body- and surreal horror a lot, but not limited to those. Think David Lynch, if you're familiar with him.",
    "y22-m09-d18",
    "novelai-discussion"
  ],
  [
    "so just putting it in parentheses will make it expand them into words and dialogue?",
    "Yep. Very simple things, like `(X falls off the stage, hurting himself.)`",
    "y22-m09-d18",
    "novelai-discussion"
  ],
  [
    "Does it ever leak?",
    "Have to admit that it does. The `----` that is, not the contents.\nIf the default bias is on, whenever the AI tries to output `***` and fails, it might go for `----` instead as it's the second most common separator. So if you use `----` entries, might be worth banning it. No side-effects from doing that.",
    "y22-m09-d18",
    "novelai-discussion"
  ],
  [
    "```----\nName: Lydia Reynolds\nGender: Woman\nRace: Naiad\nClass: CloserCadet\/\nSize: 6'4'' (tall)\nAppearance: Teal Hair, Magenta eye color, Athletic Build, Fish Fins for ears, Rippling muscles\nAttributes: Brain Injury, Neural Interface\nRelationships: Married to wife Casey``` Is this right?",
    "```Height: 6 ft 4 in (tall)```  Other than that, should be ok. (Didn't use `'`s in sizes, as those are used as quotation marks too etc.)",
    "y22-m09-d18",
    "novelai-discussion"
  ],
  [
    "Does this work better with Krake or Euterpe?",
    "Krake is newest, so these are strongest in it. Euterpe's missing couple of months of work.",
    "y22-m09-d18",
    "novelai-discussion"
  ],
  [
    "Also, suppose one would train a module on the works of a popular author. Would there be any copyright restrictions on publishing said module in this Discord, should it turn out to be any good?",
    "No problems. Just don't share the original works.",
    "y22-m09-d17",
    "module-discussion"
  ],
  [
    "Mine currently have ~2.7-2.95, sounds alright?",
    "At 100% trained? Good enough. I can usually get most things in 2.1-2.6 range, but... yea.\nIf it's just novels and loss stays over 3.0, then something's sus.",
    "y22-m09-d17",
    "module-discussion"
  ],
  [
    "...for separating a story within one file",
    "Then neither. Use `***`.",
    "y22-m09-d17",
    "module-discussion"
  ],
  [
    "what was that trick where if ur writing first person u make it where it remembers your person's name",
    "Put this in Memory: ```***\n[ Name ]```\nThat'll act as a chapter header, and the AI has learned that names in those indicate the 'active' character. (Replace Name with the actual name, of course.)",
    "y22-m09-d16",
    "ai-writing-help"
  ],
  [
    "I've considered doing this but I don't have an appropriate character to transform it into",
    "I'm waiting for customizable bot myself. Whenever that'll be. <:RWsnekcry:805426733398360064>",
    "y22-m09-d15",
    "novelai-discussion"
  ],
  [
    "Its over, BIRB COMPLETE",
    "I'd guess... Charlie Bowater?",
    "y22-m09-d15",
    "novelai-discussion"
  ],
  [
    "`RENNTFEAS` pls don't remind me ai",
    "",
    "y22-m09-d15",
    "novelai-discussion"
  ],
  [
    "I wanted to ask about this in order to test out how the AI could handle fanfiction. Would I be able to generate a functioning module by training the AI on the scripts\/books of a series and tell it \u201cOkay, now let\u2019s write this Star Wars [or whatever movie\/series\/etc.] fanfic\u201d?",
    "If it's nothing but scripts, you're going to get script-style output from the module\nBut otherwise, yes. With some caveats. It's easy to accidentally overtrain so that same names etc pop up constantly ('course, for some franchises you might want this.)",
    "y22-m09-d15",
    "module-discussion"
  ],
  [
    "Quick Q: `----` is supposed to be a **prefix** right?",
    "Right. It marks where the data entry begins.",
    "y22-m09-d14",
    "ai-writing-help"
  ],
  [
    "There isn't any `Bio:` or `Description:` tag?",
    "Those tend to work better in the 'brief prose description' part. Categories are (mostly) for content that can be easily summarized\/listed. `Attributes:` and `Occupation:` can be handy for 'bio' type of data. `Occupation: former mercenary`, etc.",
    "y22-m09-d14",
    "ai-writing-help"
  ],
  [
    "<@409511804293611530> i see you have no counter argument, i shall now claim whatever prize you have laying around",
    "I didn't think it needed one. Complete fail at depth of field. People in front are just as blurry as in the back.",
    "y22-m09-d14",
    "novelai-discussion"
  ],
  [
    "<@409511804293611530> i\u2019m talking about as if you actually took a picture of someone with no filter lmao",
    "The thing is, that looks fake to me. Everything's in focus. Actual photo would be like this:",
    "y22-m09-d14",
    "novelai-discussion"
  ],
  [
    "I'm mainly concerned with backgrounds",
    "Put in something like `in park`. That's usually enough.",
    "y22-m09-d14",
    "novelai-discussion"
  ],
  [
    "Hey <@409511804293611530>  or anyone else on the datasetting team...\n\nIs there any special formatting applied to written letters in the dataset? Do they get enclosed in quotes, do they have a certain number of newline breaks? Anything at all that signifies them separately from standard text?",
    "En space, `\u2002`. Same as quotations, but you can prompt for letter with one of the standard openings, such as `\u2002Dear`. (And for emails with `\u2002From:`.)",
    "y22-m09-d14",
    "ai-writing-help"
  ],
  [
    "Quick question. Anyone know what sorta Author's note one should use if they were to write a Martial arts\/fighting story?",
    "Use Memory instead. AN's too strong for most things.\nUsing ATTG helps. Try something like `[ Tags: martial arts; Genre: fantasy, action ]` in Memory. (`martial arts` tends to feature long descriptive battles, and is rarely lethal. Good for tournaments, etc. Use `dark fantasy` instead if you want grittier fights.)",
    "y22-m09-d14",
    "ai-writing-help"
  ],
  [
    "Bro how\u2019d you actually get that to generate lol, i\u2019ve done 5-6 attempts",
    "`-large bowl with dirt sand small rock 'soup' in it, by noob chef`",
    "y22-m09-d13",
    "novelai-discussion"
  ],
  [
    "Will the ai have any idea what I\u2019m talking about if I describe a character with a dnd alignment (or Lawful Good)?",
    "Should. With Krake, at least.\nWas strong enough to override the normal 'goblins are evil' on first try.",
    "y22-m09-d13",
    "ai-writing-help"
  ],
  [
    "my favorite artist...Dadtggathet [Eldritch Horror] a blox.",
    "",
    "y22-m09-d13",
    "novelai-discussion"
  ],
  [
    "How about thanos burger? <:thonkg:849933565344088065>",
    "How about a Lovecraftian bur... er... Okay, no.",
    "y22-m09-d13",
    "novelai-discussion"
  ],
  [
    "",
    "",
    "y22-m09-d12",
    "novelai-discussion"
  ],
  [
    "maybe ask zaltys the next time he's online",
    "Doesn't ring a bell. But it is a workable idea, as long as the content is kept balanced. I'm curious about which books that included..",
    "y22-m09-d12",
    "novelai-discussion"
  ],
  [
    "Is this 1.5?",
    "No comment.",
    "y22-m09-d11",
    "novelai-discussion"
  ],
  [
    "coherent reflections, dang",
    "",
    "y22-m09-d11",
    "novelai-discussion"
  ],
  [
    "I think this might explain the `dynamic lightning` images I was confused by",
    "For a similar effect without side-effects (don't mean lightning, but light fixtures popping up), `play of light and shadow` works nicely. ...kind of long, though.",
    "y22-m09-d09",
    "community-research"
  ],
  [
    "I was moreso curious about raw cleaned data in and of itself.",
    "Well, this heavily depends on what it is about.",
    "y22-m09-d09",
    "module-discussion"
  ],
  [
    "Just keep in mind that module *don't learn the content*, but only taking in the pattern",
    "Well... it learns some of the content. Just nowhere near enough repetition to learn something specific reliably, especially if it's not already in the finetune.",
    "y22-m09-d09",
    "module-discussion"
  ],
  [
    "why synopsis?",
    "Because that's common on web pedias, such as numerous Fandom wikis.",
    "y22-m09-d09",
    "novelai-discussion"
  ],
  [
    "It's decently good at vanilla sex acts, though it struggles with kinkier stuff I've noticed, as it likes to deviate back to vanilla stuff. Or it just goes all-in in on harsher stuff I wasn't trying to get it to do, heh.",
    "Okay, now I'm curious about what kinks you're trying. Krake should be able to handle most things. Euterpe... not so well. And some modules like Cross-Genre are heavily vanilla. No Module's usually the best pick for nsfw (out of the official ones, that is.)",
    "y22-m09-d09",
    "nsfw-discussion"
  ],
  [
    "This is a good direction to look in my opinion! https:\/\/www.goodreads.com\/shelf\/show\/space-colonization",
    "Not the best Goodreads list I've seen. Very low on actual colonization, and doesn't even include thematic ones like https:\/\/www.goodreads.com\/book\/show\/51793329-mars-nation-1",
    "y22-m09-d08",
    "novelai-discussion"
  ],
  [
    "How do I make this work? with krake\n```[ Tags: adventure, fantasy ]\nSummary: You are a bored young man, sitting in a park one day. And will be visited by a crazy wizard who will show you something amazing that will change your life.\n***```",
    "Fantasy would be Genre instead of Tags, but it shouldn't make huge difference. But since it mentions park, I assume that you want `urban fantasy` instead.\n(Note that second person is weak. I'd recommend first or third instead.)",
    "y22-m09-d06",
    "ai-writing-help"
  ],
  [
    "Why the dashes?",
    "Stronger connection between words.",
    "y22-m09-d06",
    "novelai-discussion"
  ],
  [
    "almost?  Q1 and Q3 are fire!",
    "Yea, but fourth was messed up... Here's the prompt: `dog-shaped-animated-bread, soft lighting, by master chef, by kennel`",
    "y22-m09-d06",
    "novelai-discussion"
  ],
  [
    "https:\/\/cdn.discordapp.com\/attachments\/1013926053653254164\/1016736122635829379\/--seed_57610015_--uuid_0.273300599222446_hybrid_animal_bread_dog.jpg",
    "",
    "y22-m09-d06",
    "novelai-discussion"
  ],
  [
    "What I can do with this prompt to improve the output on a fennec fox fursona in 50s clothing?",
    "Something like this, or am I completely off track?",
    "y22-m09-d06",
    "novelai-discussion"
  ],
  [
    "--large --a --t --module test_furry_3 --sampler k_euler 50's clothing ad, skirt and blouse, motherly, cute face, hourglass figure:55 | Fennec fox fursona, skirt and blouse:35 | Beastars:5 | woman: -5",
    "I find that hard to parse. Why the split categories? With what you currently have, it's going to generate humans.",
    "y22-m09-d06",
    "novelai-discussion"
  ],
  [
    "So, `***` and `[ Style: Q&A ]` then le first question of it? It's suppose to be a Q&A about the story itself.",
    "Just `[ Style: Q&A ]`, no separators.",
    "y22-m09-d06",
    "ai-writing-help"
  ],
  [
    "If I want to insert a Q&A in the middle of a story, should I use `***` or `----` to separate it from story text? Or do something completely different?",
    "For that specific case, `[ Style: Q&A ]` should work reliably. (Krake again. Not sure about Euterpe.)",
    "y22-m09-d06",
    "ai-writing-help"
  ],
  [
    "What's with the AI changing the spelling of character's names when the proper ones are already in the context?",
    "Likely a repetition penalty issue. Check what's happening with the probabilities (<:walnut:926283281253679124> ). If it's already in the context too many times, rep penalty pushes it lower than misspellings.\nNote that 'too many times' might be 'once', if using bad presets.",
    "y22-m09-d05",
    "ai-writing-help"
  ],
  [
    "oh was I supposed to use Summary without brackets?",
    "Yep, it's without brackets. Just need `***` after it to force it into prose instead of outputting, say, a movie review.",
    "y22-m09-d05",
    "novelai-discussion"
  ],
  [
    "ive had success with `[ Synopsis:` today with Krake",
    "Instead of `Summary:`? And it worked better? <:thonk:733040009136832642>",
    "y22-m09-d05",
    "novelai-discussion"
  ],
  [
    "Instead of doing `Write a love story:` I'd try something like:\n> `[ Author: <some romance author you've looked up> ; Title: <An imaginary title for your story> ; Tags: <tags you'd like to see> ; Genre: romance ]`\n> `<A synopsis sentence describing what you'd like to see.>`\n> `***`\nThen let the AI generate something for you on Line 4 if you don't want to write the start yourself, playing with modules and presets if necessary or if you think of an idea you can add it yourself.",
    "This, except skip Author and Title. Those are rarely useful.",
    "y22-m09-d05",
    "novelai-discussion"
  ],
  [
    "It is fantastic at landscapes.",
    "Yep. This was one of my early attempts, can post it now that bot's out.",
    "y22-m09-d05",
    "novelai-discussion"
  ],
  [
    "Yoink!\n(I needed more landscape artist tags)",
    "That was just one section of it. `Mark Keathley, Jessica Rossier, Phuoc Quan` for colorful landscapes, etc.",
    "y22-m09-d05",
    "novelai-discussion"
  ],
  [
    "Hello. I want to create new words with definitions and assign new, additional definitions to existing words. How would I go about doing this? With lorebooks?",
    "There's enough glossaries in the data that this style works decently: ```Glossary:\nWord#1: brief explanation.\nword#2: ditto.\netc.``` Though where to place it is trickier. It's usually a waste of tokens to keep that constantly in memory, so LB would be better choice.",
    "y22-m09-d04",
    "ai-writing-help"
  ],
  [
    "Wait, what are the section token limits? Haven't heard of that one.",
    "See here: https:\/\/discord.com\/channels\/836774308772446268\/975739920306036766\/1016099660466749460",
    "y22-m09-d04",
    "novelai-discussion"
  ],
  [
    "Which can be a hassle if Z is long to write.",
    "It's a hassle, but at least the token limits are separate per section, so it doesn't matter if they get long.",
    "y22-m09-d04",
    "novelai-discussion"
  ],
  [
    "What I mean is that the instruction `X: 1 | Y: 2 | Z: 3` gets interpreted as \"give me a portion of X, two portions of Y, and three portions of Z, rather than \"one portion if X and two portions of Y, in the overall style Z\"",
    "Yep. And `X:1|Y:2|Z` _seems_ to get interpreted as 1:2:1. But don't quote me on that, I only just learned about it myself.",
    "y22-m09-d04",
    "novelai-discussion"
  ],
  [
    "Tried it, but the effect is that the style comes into competition with the rest of the content, which results in the other instructions having overall less weight.",
    "Yea, I'm not sure what the weights are if you neglect to add them for one section. It definitely uses it, might default to 1 based on quick testing. Could just ask Aero, but... now's not a good time.",
    "y22-m09-d04",
    "novelai-discussion"
  ],
  [
    "I always thought furry didn't work well with the AI and figured anthropomorphic or humanoid would work better. Is this not the case?",
    "Krake is trained to use `Tags: furry` for content that's 100% furry, as in Zootopia. And `Tags: anthro` for content that has mix of species, such as some furryish aliens among humans. In theory, anyway. That wasn't fully standardized in the current Krake checkpoint. Another thing that'll work better someday.\n-and yes, I know that split is a bit arbitrary, but had to pick something to use. <:shrug:332268181517238272>",
    "y22-m09-d04",
    "ai-writing-help"
  ],
  [
    "Does anyone know a way to help the AI write anthropomorphic animal characters? I've found that adding \"anthropomorphic animals\" or \"anthro\" to my story's tags works mildly well, however having any other tags present seems to almost always make the AI generate nonfiction paragraphs, or only portray normal animals without human characteristics. More specific tags, like \"anthropomorphic african animals,\" or \"anthro african wildlife,\" yields similarly unwanted results. I know there's always the option of writing an anthropomorphic character into my story and hoping the AI will pick up on the idea, but I've found the results of that can be rather hit and miss. There's also an unofficial furry module for Euterpe, but at this point I've become too accustomed to Krake to go back, not to mention that that module has a tendency to easily enter NSFW territory. To clarify, I want to get the AI to write about animals who act, and are described like, people.",
    "Try `[ Tags: furry, anthro protagonist ]`. That's the best I can think of on short notice. May have a better solution for that in the future, but can't say how soon.",
    "y22-m09-d04",
    "ai-writing-help"
  ],
  [
    "with the ***?",
    "Right. `***` marks scene breaks, and will be interpreted as where the prose begins.",
    "y22-m09-d04",
    "ai-writing-help"
  ],
  [
    "You can include the `Title` category if you don't have anything to put there, and I'm led to believe that things will work better like that because the AI will recognize the infobox at the beginning of a story better that way.",
    "Leave out blank fields. Something like `[ Author: ; Title: ; Tags: 1800s ]` is not only a waste of tokens, but makes it work worse. Should just put in `[ Tags: 1800s ]` in that instance.",
    "y22-m09-d04",
    "ai-writing-help"
  ],
  [
    "Don't think there's an official acknowledgement until the announcement lands but that's almost the expectation, training steps kind of become the NAI compute currency.",
    "Not exactly an announcement, but... https:\/\/discord.com\/channels\/836774308772446268\/837402685824565278\/1010904147589079100",
    "y22-m09-d03",
    "novelai-discussion"
  ],
  [
    "",
    "Kind of hard to control, though. The original could've just as well been meant to be a green alien with ipad.",
    "y22-m09-d03",
    "novelai-discussion"
  ],
  [
    "Out of curiosity - can you disclose how high the official modules go? (Rough ballpark)",
    "High in which regard? Percentage?",
    "y22-m09-d03",
    "module-discussion"
  ],
  [
    "Sounds fairly unlikely though",
    "Not really. With only 20% coverage, there's 80% chance of missing important bits. <:shrug:332268181517238272>",
    "y22-m09-d03",
    "module-discussion"
  ],
  [
    "More material is better because you'll get, well, more...",
    "Nope. You get completely random chunks from the set, which might end up being the worst bits.",
    "y22-m09-d03",
    "module-discussion"
  ],
  [
    "1000 steps of 30mb of material is more ideal than 1000 steps of 20mb of material.",
    "Completely incorrect.",
    "y22-m09-d03",
    "module-discussion"
  ],
  [
    "thanks, gonna try it after importing the gazillion of world info and converting it to a lorebook entry",
    "Maybe I should've asked 'what kind of war adventure'.\nHistory is good for alternate history scenarios etc, but not great for scifi\/fantasy\/etc.",
    "y22-m09-d02",
    "module-discussion"
  ],
  [
    "what's the best module for a war adventure?",
    "History.",
    "y22-m09-d02",
    "module-discussion"
  ],
  [
    "I can't help but notice there's no image bot how to channel, even though the announcement says the how-to and intro to the bot is in said channel",
    "Check the pins.",
    "y22-m09-d02",
    "novelai-discussion"
  ],
  [
    "I\u2019m curious if there\u2019s any practical difference between feeding into module training 5 books via 5 file and the same 5 books via 1 file, separated by that Illuminati asterisk",
    "Tiny difference, not enough to have an impact on that few files.\nSeparate works are split like this: `End of text #1.<|endoftext|>Beginning of text #2.`, instead of ```Text #1\n\u2042\nText #2```",
    "y22-m09-d02",
    "module-discussion"
  ],
  [
    "Someone pointed that out to me earlier, that, that is what caused nai's inception.",
    "Yep. If AID hadn't been so two-faced about the whole thing, I might've stayed there. And then who knows where NAI's dataset would be today. Funny how things work out.",
    "y22-m09-d02",
    "novelai-discussion"
  ],
  [
    "Does anyone know if there\u2019s a way to delete imported modules and presets? I have different\/updated versions of the same preset and some modules I didn\u2019t like.",
    "Oh, and for presets, you'll need to go into edit and delete them one by one. The pen symbol next to the preset in third tab.",
    "y22-m09-d01",
    "novelai-discussion"
  ],
  [
    "Does anyone know if there\u2019s a way to delete imported modules and presets? I have different\/updated versions of the same preset and some modules I didn\u2019t like.",
    "You can delete modules from the `All Modules` list (link next to the module list.)",
    "y22-m09-d01",
    "novelai-discussion"
  ],
  [
    "Such as it is, I can always copy the symbol from another source so I may pepar and solt it as I plese.",
    "If you use the LitRPG module for a bit, it's going to output it sooner or later.",
    "y22-m09-d01",
    "ai-writing-help"
  ],
  [
    "furthermore, how should I handle a lorebook for a char with more than one outfit? even if I keep the details simple",
    "General styles are easy with Attributes (see below for usage), but forget about trying to define specific outfits. The AI will disregard those.\nData: ```\n----\nZak\nWears: Odd combination of gamer geek and goth clothing\n***\nI glanced over at Zak. He was wearing``` Output: ``` a black shirt with some kind of weird metal spike logo on the front that looked like it had been ripped straight out of the back cover of some old 90's video game magazine. Black leather pants, steel-toed boots, and a pair of wrap around sunglasses completed the ensemble.```  `Wears: Always formal` instead: ``` his usual dark grey suit, except it had a black vest on top of it, and he'd paired that with a red bowtie.``` `Wears: Sports style`: ```a sports outfit, light gray in color with blue stripes on the sides, and he was strutting around the room while swinging his arms up and down. He looked like an idiot to me but I kept my mouth shut.``` ...and so on.",
    "y22-m09-d01",
    "ai-writing-help"
  ],
  [
    "Ah, I see. In that case, I believe I need to install a different keyboard on my phone, since this one seems to lack the correct special character.\nThank you for the guidance. I don't play MMORPGs, so I don't know the design conventions.",
    "Yeah, sorry about making it difficult on mobile. I've requested the addition of `\u2500` to the Editor v2, but dunno if that'll get implemented.",
    "y22-m09-d01",
    "ai-writing-help"
  ],
  [
    "> RPG Formatting:\u00a0Horizontal line (\u2500), not to be confused with a dash, may be used for MMORPG-styled skills and statistics.\n\nI understand what this is saying, but how would you implement it? Where does the horizontal line go?\n`\u2014Joe Bob uses Boomstick`\nor\n```\u2014\nJoe Bob uses Boomstick\n\u2014```\nor something else entirely?",
    "Neither. What you posted there was em dash, which the guide specifically said not to use.\nAnd it'd be more like: ```\n\u2500 Joe Bob\n\u2500 Skills: Boomstick``` Think MMORPG character sheets. Or, alternately: ```\nJoe Bob aimed his boomstick at the slime. He pulled the trigger.\n\u2500 You missed! Your attack was too low to hit!\nThe slime dodged with ease.\n\"Ah, dammit!\" Joe Bob said. \"That's not good.\"```",
    "y22-m09-d01",
    "ai-writing-help"
  ],
  [
    "petite, beautiful, etc.",
    "Even `pink`. Noticed that with kobold scale colors, etc.",
    "y22-m09-d01",
    "novelai-discussion"
  ],
  [
    "Also because NAI wants to stay on Discord's good side.",
    "More this than anything else.",
    "y22-m08-d31",
    "nsfw-discussion"
  ],
  [
    "```elegant portrait of a holy witch creating magic illusions | glowing runes above her | spectacular light show | royal palace church interior | light dust | magnificent | medium shot | close up details | sharp focus | elegant | highly detailed illustration by jordan grimmer and greg rutkowski and alphonse mucha and wlop | intricate | beautiful | trending artstation | pixiv | digital art```",
    "Maybe try without `|` (or)?",
    "y22-m08-d31",
    "community-research"
  ],
  [
    "Goblins and orcs are always monsters, whyyy <:cry:837394871672111124> Where's my adorable civilized goblins! (also why are they always ugly?)",
    "I actually have a small test for that one.\nUse a preset with low token pool (or set Top-K to less than 20) and prompt with `The tavern was full again, so I ended up sharing a table with three very different creatures:`. It'll show how non-humans (if any) are weighted in the module. (Replace tavern with bar or cantina for contemporary\/scifi settings.)",
    "y22-m08-d30",
    "ai-writing-help"
  ],
  [
    "Oh.. OH... I might know where half of the uh.. erotic content comes from now. Just checked what's in the module and there's quite a bit of it. I'll switch to the default Cross-Genre, for now. rofl",
    "Uh, Cross-Genre very heavy on romance and vanilla erotica. Probably not the best choice if you want _less_ of it.",
    "y22-m08-d30",
    "ai-writing-help"
  ],
  [
    "No module or \"vanilla\" is the \"least biased\" of them, then?",
    "Right. No Module is the most creative one out of them.",
    "y22-m08-d30",
    "ai-writing-help"
  ],
  [
    "I usually ban hisses, huffs, rolls-eyes anything passive aggressive and rather itchy with a b.",
    "I'd recommend negative biases instead. It is very easy to overdo bans. For instance, `huffs` tokenizes into `h|uffs`, which is going to have a lot of side-effects.",
    "y22-m08-d30",
    "ai-writing-help"
  ],
  [
    "I find Cross-Genre the best, as you said, it becomes a little too biased toward certain kinds of outcomes otherwise, which I mean is kind of the point ultimately, but it becomes too difficult to hybridize a genre. I think I made that point with my comment about presets in the august google form.",
    "I was referring to the Config Presets, like Ace of Spades and Ouroboros in Euterpe. Though modules like Cross-Genre also limit what the AI tends to output.",
    "y22-m08-d30",
    "ai-writing-help"
  ],
  [
    "I stick things in there when the models become stuck, then move to memory if I still find whatever I put there to be always relevant somehow. Hopefully this is a good method and I am doing it correctly.",
    "The thing is, the way I use it I've never seen it get stuck. So I'm not sure what you do differently. My guess would be a bad preset, or bias lists.",
    "y22-m08-d30",
    "ai-writing-help"
  ],
  [
    "not really, I think they just didn't have enough steps or following ***1 year old*** steps guideline from Sigurd days. (Which I think is irrelevant now.)",
    "And still pinned for some reason. <:shrug:332268181517238272>",
    "y22-m08-d30",
    "module-discussion"
  ],
  [
    "Is it still more like a list, or it's just trained to avoid learning prose from within that defined block, but still reliably retain the information? Sorry for all the questions, I've been out of the theory loop since around when AID took a nosedive and GPT-3 basically became a ghost.",
    "The recent models \u2014 and by that I mostly mean Krake, though some of it made it into Euterpe \u2014 are trained to follow Attributes with high quality prose, and to apply the Attributes data into that paragraph. As such, it can be used without negative impact on the quality.",
    "y22-m08-d29",
    "novelai-discussion"
  ],
  [
    "The latest issue with that version is that after a day or so, Amazon force downloads an update even if the updates are unchecked in options. It's quite tedious unless I've missed something?",
    "It shouldn't, if you disable automatic updates in both the old and new (before replacing it).",
    "y22-m08-d29",
    "module-discussion"
  ],
  [
    "I'll be fair to them and say that if they keep devoting so much dev time to image gen, which is not THAT hugely important, it will only push back more important and cooler stuff like Modules V2",
    "Well, it gives me more time to work on the module datasets. <:shrug:332268181517238272>",
    "y22-m08-d28",
    "novelai-discussion"
  ],
  [
    "Trying to recall: how can one download the azw files from Kindle for conversion?",
    "https:\/\/discord.com\/channels\/836774308772446268\/870449695657443349\/952251274064179210",
    "y22-m08-d28",
    "module-discussion"
  ],
  [
    "So, what's the best way to keep the AI from addressing you in 3rd person?",
    "Write in first person.\nYou can also strengthen it by adding `[ Tags: first person ]` to Memory, but it's not needed.",
    "y22-m08-d28",
    "ai-writing-help"
  ],
  [
    "I am missing a way to change the output of the do\/say commands to use first instead of second person?",
    "No. Text Adventure is strictly second person. For everything else, use the main mode (Storyteller).",
    "y22-m08-d28",
    "ai-writing-help"
  ],
  [
    "Is there a way to have a Japanese name or be Japanese in my stories without Euterpe drifting into anime tropes? It's... irritating me more than it probably should. I was confused about why weird things kept happening until I thought about my name, and my friend's name. It is playing havoc with my attempts to run a Steins;Gate session as well.\n\nMentioned nsfw things in regards to women's clothing using a term I did not even realize the AI knew.. I don't mind being given a kimono, or being a samurai but the very bad tropes creep in there out of no where. Apparently I'm from some kinda anime, at least the AI thinks I am even if I only use Mia.",
    "Use ATTG. For Steins;Gate I'd throw in something like `[ Tags: science, Steins;Gate; Genre: hard SF ]`",
    "y22-m08-d28",
    "ai-writing-help"
  ],
  [
    "Ah, cool. Thanks. Gonna try it out in Krake, since I heard Krake pulls more from lorebooks than Euterpe does",
    "On Krake you'll want to prepend it with `----`. As in ```\n----\nName``` Though not strictly necessary, it does make it a bit stronger, well worth the extra token spent.",
    "y22-m08-d27",
    "ai-writing-help"
  ],
  [
    "Does\n\"Quote\" - Name\n\nhave a stronger effect than\nName Quote: \"Quote\"\n\nI've always done the latter",
    "The latter is close to the forum chat style. As long as you don't overuse it so much that it switches to that format when not wanted...",
    "y22-m08-d23",
    "ai-writing-help"
  ],
  [
    "Probably not by volume unless stuff got removed, but for sheer effort and improvements, definitely",
    "Yea, only counting curated\/cleaned material of course. Tossing in random things just to inflate the volume is a bad idea.",
    "y22-m08-d23",
    "community-research"
  ],
  [
    "Is there a way to steer the AI toward making a character have certain personality traits? I've been putting something like this in my LB: \"John is arrogant, vain, and stingy.\"",
    "And that doesn't work? <:thonk:733040009136832642>  Try adding a quote to the LB. Like this: ```\u2002\"I know everything there is to know about women and I always get it right. Trust me. I've got more experience than you could ever hope for.\" \u2014John```",
    "y22-m08-d23",
    "ai-writing-help"
  ],
  [
    "In that case, assuming that your user role means that you worked on the datasets, a bottoms-up approach to simply infer the final behaviour of the model would be more practical",
    "I've worked on the dataset, yes. By now about 95% of Krake dataset is my work, maybe more.",
    "y22-m08-d23",
    "community-research"
  ],
  [
    "Guessing from zero is simply more time consuming than guessing from the basis of an author list you can data mine on the public internet for titles\/tags to build a more narrower scanning corpus",
    "I can say that a lot of what it comes up with is _not_ in the dataset.",
    "y22-m08-d23",
    "community-research"
  ],
  [
    "Why is everyone here obsessed with telling people to go to bed?",
    "Probably because most of the devs forget to sleep if you don't tell them to.",
    "y22-m08-d23",
    "novelai-discussion"
  ],
  [
    "Thanks!",
    "Oh, and use a preset that allows for larger token pool. Anything with low Top-K or Randomness is going to end up with mostly humans.",
    "y22-m08-d23",
    "ai-writing-help"
  ],
  [
    "What's the best way to get the AI to generate fantasy creatures\/races for newly introduced characters? The AI seems to stick to human and maybe elf.",
    "A few tips.\n- Bias down `human` a bit.\n- Use an ATTG like `[ Genre: epic fantasy ]`, `[ Genre: urban fantasy ]`, `[ Tags: aliens; Genre: space opera ]`. Those commonly feature nonhumans.\n- Add something in context that mentions there being various species.",
    "y22-m08-d23",
    "ai-writing-help"
  ],
  [
    "And one more question along the way - the wiki guide says `< >` can be used for thoughts. Does it matter if such blocks are in-line with the broader paragraph, or on they own line?",
    "Thoughts are typically not marked. ```Maybe I should go find the Tothiat again, invite her for a drink, she thought wryly.```\n<This type of dialogue is for telepathy, and other non-verbal communications such as an AI implant speaking directly to someone's brain. You _could_ use it for thoughts, but can expect someone to respond telepathically, etc.>",
    "y22-m08-d23",
    "module-discussion"
  ],
  [
    "How would you deal with line-by-line dialogue in files, e.g.",
    "Those are fine as is, no need to do anything about them.",
    "y22-m08-d23",
    "module-discussion"
  ],
  [
    "So I'm having a bit of a pecular-ish problem that I seem unable to solve. Is there a way to steer the AI (both Euterpe and Krake) away from flirting and romance when I have male and female characters in a scene? I have tried everything I can think of in my several months of working with AI models, this is a constant thing.\n\nRight now I have an amazing scene going with two characters riding on the back of a dragon they just met. Nothing above contains anything even tangentially linked to relationships or any such stuffs. It's just our interaction with the dragon, how we both have lost memories of our past, and my request to adventure together (instead of slay, dragons are cool).\n\nEvery other prompt the AI keeps having one of the characters grab the other's hips or lean against them. Both are kinda young, so it's getting a bit weird. Any advice is appreciated...",
    "Guess there's something that's triggering its nsfw sense. It might just be running out of ideas of how to progress the story. Try throwing in `***` to advance to the 'next' scene.",
    "y22-m08-d22",
    "ai-writing-help"
  ],
  [
    "A bit of advice: If I'm writing a relatively narrow niche story, like a fantasy erotica around a specific subject, would Euterpe with a relative erotica leaning module work better, or would Krake with it's default fantasy module be preferable. Or is it just a wash\/matter of taste? I keep a pretty tight control over the story, with heavy editing over every generation that's made while generally guiding the action myself.",
    "If it is niche, then always default to No Module.\nModules narrow down the scope and limit what you can do. If the said niche content is not included in the module data, then it'll work worse than it would without a module.",
    "y22-m08-d22",
    "ai-writing-help"
  ],
  [
    "Ban male, males, man, men, boy, boys",
    "\"My father was a cow~~boy~~.\"",
    "y22-m08-d22",
    "novelai-discussion"
  ],
  [
    "Is [ Style: ] supposed to be used on its own line? Also, is it usually found at the start of a story, or within it (such as when switching narrators)?",
    "Own line. Found where the style switches. Which is often but not always after `***`.",
    "y22-m08-d21",
    "ai-writing-help"
  ],
  [
    "Ohhh...do Aini",
    "",
    "y22-m08-d21",
    "novelai-discussion"
  ],
  [
    "You are cheating. You still have to specify if in the morning or if in the afternoon",
    "Can't remember the last time I did that. It's usually obvious from context.",
    "y22-m08-d21",
    "novelai-discussion"
  ],
  [
    "Would you trust him",
    "",
    "y22-m08-d20",
    "novelai-discussion"
  ],
  [
    "Is that a thing? That if a franchise is popular enough the AI just knows some knowledge already?",
    "I've tried to cover most of the popular franchises in the datasetting, yes. But it's harder for some. Take Monster Hunter, for example: no official novels, and fanfiction is overly focused on specific mons.",
    "y22-m08-d20",
    "ai-writing-help"
  ],
  [
    "So, basically it's like this?\n2022 - Available for Opus\n2024 - Available for Scroll\n2026 - Available for Tablet",
    "Probably not.",
    "y22-m08-d20",
    "novelai-discussion"
  ],
  [
    "Oh man, next time I GM I am 100% using imgen to mess with the players.",
    "\"You open the door. Here's what you see on the other side.\"",
    "y22-m08-d20",
    "novelai-discussion"
  ],
  [
    "https:\/\/tenor.com\/view\/comedy-parody-adult-swim-ntsfsdsuv-piper-gif-3454000",
    "https:\/\/www.youtube.com\/watch?v=XFD0WSGW-FM",
    "y22-m08-d20",
    "novelai-discussion"
  ],
  [
    "I guess I could, I'm just testing a lorebook I'm making",
    "Copy the story, then delete the current context from the duplicate. That way you keep the lorebook etc but 'reset' the story.",
    "y22-m08-d19",
    "novelai-discussion"
  ],
  [
    "Or even > commands in 1st, story text in 2nd?",
    "I don't see how, unless you're not actually going to use the TA mode. Since that converts everything to second person, which then won't match the training.",
    "y22-m08-d19",
    "module-discussion"
  ],
  [
    "I take from this that descriptive prose remains the winner, but there's a level of knowledge i.e. attributes and other \"meta knowledge\" of the fine tuning that still means NAI is best used by power users that have a lot of experience, which is somehow not ideal.\nGranted learning how to use the tool is a part of its potential but still feels sometimes like it's just not going to be exposed to casual folks trying it for the first few times.",
    "It's really mostly third person and preset, from what I've seen. Writing descriptive prose is overplayed, as eventually retrying gets the same results with right preset. I've never had issues with getting Krake to stick to descriptive when generating from blank prompts.",
    "y22-m08-d19",
    "novelai-discussion"
  ],
  [
    "Sorry to bug you again. If I wanted the TA to prompt me for an action regularly after it generates prose, should I just add that in the training? Do you think it'd be better if I did that as a separate \"paragraph\" underneath the prose, or would i just include it as the last sentence of the prose? \n\nFor example:\n\n> > You wake up at 3 in the morning.\nSomething makes noise outside your room disturbing you. It was unsettling. What do you do?\n> > You need to make sure it wasn't your imagination, so you get up and head to the kitchen.\n> \nOr:\n\n> > You wake up at 3 in the morning.\nSomething makes noise outside your room disturbing you. It was unsettling.\n\nWhat do you do?\n> > You need to make sure it wasn't your imagination, so you get up and head to the kitchen.",
    "The second variation. But keep in mind that the TA mode cannot output `>`, so it'll keep generating _something_ past those prompts regardless of how it is trained.",
    "y22-m08-d19",
    "module-discussion"
  ],
  [
    "I tried adding `[ Style: verbose, evocative, purple prose, descriptive ]` but it's not as descriptive as I want it to be. I use Euterpe btw.",
    "That'd be why. `Style:` wasn't yet included in Euterpe, so no wonder it doesn't work there.\nAs for more descriptive prose: most importantly, use third person. And secondly, switch to a preset that allows a wider variety of output, such as Ouroboros, as the default preset defaults to plain text due to how shallow the token pool is. Then \u2014 if you can't write descriptive prose yourself \u2014 just keep retrying until you get something descriptive, and keep generating from there. It'll catch on soon enough.",
    "y22-m08-d19",
    "novelai-discussion"
  ],
  [
    "And then underneath me doing actions, if I wanted to mimic the TA responding with something happening to you. I would just remove the > and write out regular prose?",
    "Exactly.",
    "y22-m08-d18",
    "module-discussion"
  ],
  [
    "If I'm training a module to purposely use with the text adventure work around strat, how should I go about doing so. Should there be a \"paragraph\" between something happening and then \"I do blah blah\".",
    "TA data needs to be formatted in second person to work well, so `> You do something.` for actions.",
    "y22-m08-d18",
    "module-discussion"
  ],
  [
    "Oh, thanks, I missed that about the first item. Proper nouns capitalised too?",
    "Yes, proper nouns always capitalised.\nDue to how the Attributes data is built, converting the first letter to lowercase would've been a major timesink due to the nouns mixed in. So I opted to keep those uppercase if it was already so in the source.",
    "y22-m08-d18",
    "ai-writing-help"
  ],
  [
    "Okay I gotta know, people who use the attributes method, what works better for you capitalizing after the category or leaving lowercase?",
    "Shouldn't matter much. But Attributes is mostly formatted Wikipedia-style in the data: with the first item on the list capitalized.",
    "y22-m08-d18",
    "ai-writing-help"
  ],
  [
    "How should I reinforce the current scene's location for a fictional location?",
    "Just `[ Location ]` should do. As long as it's in the context (from lorebook etc), so the AI realizes that it _is_ a location.",
    "y22-m08-d18",
    "ai-writing-help"
  ],
  [
    "I don't think it's possible to account for nouns. The best I can hope for is to figure out if NP++ can record each instance of UPPERCASE and record it so I can check each one for nouns after it's been corrected",
    "The way I do that is by regex searching the file for those uppercase strings. Then \u2014 after I've converted everything to propercase \u2014 I skim the search results for nouns.\nUsually it's same names over and over, so they're easy enough to search-and-replace instead of having to fix each one manually.",
    "y22-m08-d18",
    "module-discussion"
  ],
  [
    "I tried Gnurro's ReFormatter, but the GUI isn't accessible as it appears to require me to drag and drop. So then I had a go with Belverk's formatter, which initially threw a missing file notification (GPT2\\something.json). The documentation folder in that one is all .jpg image files, so I ended up without a formatter. Been plucking away with notepad++, regex, and a lot of coffee",
    "Well... Notepad++ is what I use too. Gnurro's tool might be useful for casual editing, but I couldn't dataset without regex, tabs, macros, multi-search, etc.",
    "y22-m08-d18",
    "module-discussion"
  ],
  [
    "(\"I'm 23 years old.\" She replies with a slight smile.\nYou check Yume's file and find that she is indeed 24.) my character doing receptionist work aaah gotta love the Ai's memory.",
    "That's likely the (too high) rep penalty kicking in. <:shrug:332268181517238272>",
    "y22-m08-d18",
    "novelai-discussion"
  ],
  [
    "<@409511804293611530> thanks!",
    "Oh, and move `sword and sorcery` to genres.",
    "y22-m08-d18",
    "ai-writing-help"
  ],
  [
    "hello to everyone, I don't know if I am in the right place, do anybody know if there are erotica module?",
    "Shouldn't need a module. Put something like `[ Tags: nsfw ]` in Memory.",
    "y22-m08-d18",
    "nsfw-discussion"
  ],
  [
    "I'm assuming this image contains information? It might sound like a pain, but is there any way to have this image interpreted please? I'm blind and using a screen reader, so images are lost on me... having the same issue with the documentation for the dataset text formatter which is tracebacking at me",
    "It outlines a way to generate lore by using the Attributes-method.\nHere's an example of how to get it to generate a random description and lore for a region:\n```\n----\nYrthwood\nType: forest\nGeography:```\n\nStart with four hyphen as separator, then the subject on the next row, followed by a `Type:`. That should be enough to get it going, but you can prompt for specifics with various categories. `Geography:`, `Population:`, `Fauna:`, etc.",
    "y22-m08-d17",
    "module-discussion"
  ],
  [
    "*Settlements\/Nations\/Geographic Features*\n(warning: Long!)\n\n```\nQueen:\nKing:\nLeader: {dead (killed in ambush)}\nFaction:\nPeople: {Elosian (nomads), Aquaelian (city-dwelling)} [use to distinguish different ethnicities or races]\nPopulation: {~500 (mostly halflings)}\nSize: {Small}\nMajor exports: {Livestock, grain crop}\nMajor imports: {Silk (Sashtalia), weapons (Tonta-Brae)}\nDefenses: {Small garrison of soldiers}\nCapital: {Washington, D.C.}\nProvinces: {Fjordenland (north), Marange (east)}\nClimate: {Dry, hot, sunny}\nTerrain: {plains, grasslands}\nImportant locations: {Royal Palace, Market District}\nSize: {~300,000 mi2}\nArea: {Greenbriar Hills}\nLocation: {northern Farenar}\nGovernment: {Oligarchy, ruled by an assembly of wise old men}\nBorders: {Tonta-Brae (south)}\nResources: {Minerals, precious stones, timber}\nReligion:\nStatus: {leaderless, in chaos}\nAllies:\nEnemies:\nDescription: [catch-all for appeareance and various features. Tends to generate prose, but list style works]\nHistory: [tends to generate prose, but if you force a list style it seems to kind of work too]\n```\n\nStuff I am less sure about \u2013 specifying military strength:\n```\nMilitary: {Strong}\nDefenses: {Small garrison of soldiers}\n```",
    "Curious. These are probably from base. It's missing a lot of location-related categories that got trained in.",
    "y22-m08-d16",
    "ai-writing-help"
  ],
  [
    "ah yeah if in doubt listen to Zaltys ofc",
    "If it works, it works. Not what I'd use myself though. Five tokens is a bit much, and `AKA:` has worked for my own uses.",
    "y22-m08-d16",
    "ai-writing-help"
  ],
  [
    "As promised as an addition to <@532203742624219137>'s  list here: https:\/\/discord.com\/channels\/836774308772446268\/919724433013346324\/1008718761274122290\n(to confirm - except for `Mind:`, I have found the exact keywords a good sign his list is solid :-)!)\n\nTo add to his list, these tend to also come up for me. For Krake btw, Euterpe could be different, but should still sort of work:\n\n**For People**\n```\nAge:\nGender: {usually not needed but nice for ambiguous names}\nWeight: {not sure how useful tbh, but the AI likes to generate it, prefers lbs}\nSpecies: {but you can also specify species in () after the name as indicated in _pume's guide}\nLooks: {alternative to Appearance}\nSkin: {can also dump this in Looks or Appearance ofc}\nHair: {can also dump this in Looks or Appearance ofc}\nEyes: {can also dump this in Looks or Appearance ofc}\nClothes: {can also dump this in Looks or Appearance ofc}\nClass:\nGear: {only seen this for fantasy\/rpg style gear, like a bard's lute, can dump weapons in here too}\nWeapons:\nMagic: {e.g. for magic schools\/type}\nPowers: {seems most useful for rpg style powers or for superhero chars, maybe also for abilities and skills}\nPersonality: {alternative to Mind?}\nHome: {Alternative to Lives}\nRelationships: {I would usually indicate type of relationships in () like this: Asha (sister)}\nFriends:\nStatus: {what is the character currently doing}\nLikes:\nDislikes:\nHates:\nQuirks:\nMotive: {seems more about rather abstract goals, e.g. Escape from slavery}\nMotivation: {seems more about general things that motivate the char, e.g. Power, wealth}\nGoals: {seems to be more about specific goals, e.g. Travel to Korndale to find the mournful lute}\nHistory: {generally more common than Backstory}\nBackstory: {seems more common for rpg\/fantasy type stories}\n```\n\nAnd yeah that is a lot, and no, they are probably not all in the fine-tune. But Krake comes up with them during reverse-engineering. Might also show Krake is quite good at interpreting a wide range of keywords.",
    "Latest Krake should have a lot more than what's listed here. `Diet:` should work nicely by now. And `Movement:` & `Object use:` is useful for any non-humanoid. Want to hammer in that the creature doesn't have arms? Use those. And so on. There's dozens of categories that have niche uses.\n(Btw, have you tried `Motives:` instead of `Motive:`?)",
    "y22-m08-d16",
    "ai-writing-help"
  ],
  [
    "Try `by peter mohrbacher` It's much stronger in my experience",
    "Yea, that one's good. I've been trying various artists with it. `By Simon St\u00e5lenhag` is pretty distinct.",
    "y22-m08-d14",
    "novelai-discussion"
  ],
  [
    "Not in my experience.. mostly I swap to a new one after 5-10 years, depending on how much of a cheapskate I wanna be.",
    "Mmh. About the same for me. It gets to the point where I'd need to replace the motherboard for compatibility, and then I usually just go 'okay, time to build a completely new rig'.",
    "y22-m08-d13",
    "novelai-discussion"
  ],
  [
    "oddly enough, `|`is the separator for LitRPG according to 1 of the devs. and 1 of the pins. namely https:\/\/discord.com\/channels\/836774308772446268\/919724433013346324\/953536251116544041",
    "That says em dash (`\u2014`), not `|`.\nThough it's still incorrect either way and shouldn't be pinned, since LitRPG uses light horizontal (`\u2500`, U+2500) instead of em dash. It'd leak all over with em dash.",
    "y22-m08-d13",
    "ai-writing-help"
  ],
  [
    "I'm making a point of NOT normally adding in `skills` because its starting already a bit massively, and will only grow!",
    "Chances are that this is because you're using OR (`|`) as the separator. Would recommend using the standard LitRPG format instead. Something like... ```\u2500 Skills: Reading (college level, all languages), Writing (college level, can sell calligraphy as art), Science (6th grade level), History (6th grade level Math including advanced, Pre-College level)\n\u2500 Languages: Chinese, English, French, German, Gaelic, Hebrew, Japanese, Korean, Latin, Polish, Russian, Spanish, Forgotten Languages (Read\/Write is considered expert), Yiddish\n\u2500 Class: Runemaster```",
    "y22-m08-d13",
    "ai-writing-help"
  ],
  [
    "The AIs are Hornier than like 90% of the people using it anyway, trying to censor it always seemed bassackwards.",
    "Ha. No. Have you seen fanfiction sites?",
    "y22-m08-d11",
    "novelai-discussion"
  ],
  [
    "8GB VRAM",
    "I'm still on 4GB over here. <:grimberk:927698521262534686>\nNot that I really need it for editing, but still...",
    "y22-m08-d11",
    "novelai-discussion"
  ],
  [
    "Is there anything the AI understands like\n\"end of chapter\"\n\"Chapter 1-2-3\"\nBecause *** seems to entirely switch subject\/stories and everything",
    "Are you sure about it switching to a new story? From what I've seen, it usually switches to different characters\/scene in same story, as in `Meanwhile...` (Often switching back on next `***`.)\nAs Flitter said, if you want more control over it, use a chapter title after `***`. Won't need the `Chapter #` part. Just something like: ```\n***\n[ The Next Morning ]```",
    "y22-m08-d08",
    "ai-writing-help"
  ],
  [
    "If your prompt is not written in that style, then yeah it will get ignored.",
    "Or you could test it yourself. Try styles like `[ Style: poetry ]`, `[ Style: Q&A ]`, `[ Style: chat ]`  or `[ Style: editorial ]` after `***`, and see if it still sticks to the prompt style...\nI'd appreciate it if you didn't spread misinformation about it not working.",
    "y22-m08-d08",
    "ai-writing-help"
  ],
  [
    "The use of a dinkus there kind of makes sense, but it's a lot stronger than a linebreak, and I don't think a dinkus is really necessary for Memory.",
    "Highly recommended if there's any non-prose data in the memory. If it's all prose, might manage to do without it.",
    "y22-m08-d08",
    "novelai-discussion"
  ],
  [
    "Awkwardly, when I'm playing Text adventure, bandits and evil mercenaries often suddenly become Moral models, which is ruins immersion",
    "Yea, someone (not me) tossed in way too much Darkest Dungeon content with heroic Highwaymen and Christian Crusaders in there. Will be fixed in the next version.",
    "y22-m08-d08",
    "nsfw-discussion"
  ],
  [
    "wouldn't that make the AI think it's end of chapter and forget it?",
    "Why would it? It's a chapter break, not story break.",
    "y22-m08-d08",
    "novelai-discussion"
  ],
  [
    "",
    "Dark fantasy?",
    "y22-m08-d07",
    "novelai-discussion"
  ],
  [
    "Even with all of the tools available \"The Story So Far:\" prompt engineering is still rather limited. It is as much time to just write a basic entry as it is to try and get NAI to accurately summarize.",
    "Yea, it'll likely never work for that purpose. Since `The story so far:` tends to be found in the beginning of the stories, as a synopsis of the previous book. And due to how the chunks are ordered, it can't really connect to what's _before_ it.\nBut it is somewhat effective in Krake for different use: you can put that in prompt (with a short summary in it) to direct where you want it to start the story.",
    "y22-m08-d06",
    "novelai-discussion"
  ],
  [
    "I don't think many 3rd person present tense stories exist",
    "Extremely rare. https:\/\/www.goodreads.com\/shelf\/show\/third-person-present-tense\n(And some of those are on the wrong list.)",
    "y22-m08-d06",
    "novelai-discussion"
  ],
  [
    "I'm trying to figure out what combination of settings would explain what it's like to travel from earth to the moon as if I had never seen it in a movie\nTo SHOW not TELL the journey, the visual experiences, maybe the auditory ones",
    "Something like this? If you want it in third person, that may be trickier.",
    "y22-m08-d06",
    "ai-writing-help"
  ],
  [
    "my old vitamin b's smelled disgusting",
    "Mmh. Effervescent tablets definitely go bad. Tried an old one once, could only describe the result as 'sludge'. Would not ingest either.",
    "y22-m08-d05",
    "nsfw-discussion"
  ],
  [
    "You think d&d alignments would work in a character's lore entry? Like just putting [Lawful Evil] or [Chaotic Good] in the beginning. Going to try some experiments, just wanted to see if anyone else has tried.",
    "Use attributes. It's been trained in `Alignment: Lawful Evil`, etc.",
    "y22-m08-d04",
    "novelai-discussion"
  ],
  [
    "And Zaltys was a popular guy back in AID",
    "More like controversial.\nNah, I'm here thanks to Belverk. I helped with the initial datasetting... and when everyone else lost interest, I kept working 24\/7 and ended up as the current main editor for the dataset.",
    "y22-m08-d01",
    "novelai-discussion"
  ],
  [
    "I'll undo often, but mostly when Retry locks up on Editor V2 (which is when I do anything). I use the redo tree rarely and usually only to get a sentence from a different branch",
    "Also, yeah, this. I've used it a lot more in v2 due to Retry constantly locking up. Have to resort to Undo + Send instead.",
    "y22-m08-d01",
    "novelai-discussion"
  ],
  [
    "Ala did a quick test and his probs were better with ATTG at the top.",
    "That was my assumption, but I didn't want to say anything without concrete testing. ATTG is always first in the data, so it is likely closely associated with `<|endoftext|>`.",
    "y22-m07-d31",
    "ai-writing-help"
  ],
  [
    "what about the `----`? should it be between all lorebook entries so the AI can tell them apart?",
    "I mean, that depends on what kind of entries we're talking about. <:shrug:332268181517238272>\nIf it's prose, then no `----` whatsoever.",
    "y22-m07-d31",
    "novelai-discussion"
  ],
  [
    "Wait Zaltys, what would you suggest for Attributes entries with prose at the bottom? *** or ----?",
    "Only what's right after the separator matters. Whenever the AI sees `***`, it tends to go 'okay, time to switch to prose' now.",
    "y22-m07-d31",
    "novelai-discussion"
  ],
  [
    "---- between attribute entries, \\*\\*\\* for the rest",
    "`----` for data, `***` for prose. (It's trained that way, keeps data from leaking into prose.)",
    "y22-m07-d31",
    "novelai-discussion"
  ],
  [
    "the `?` after `Hair` looks interesting <a:notes_gif:987618302887067648> kinda like `Hair? What hair?`",
    "Yea, data includes some of that. Attributes is now pretty good at applying `?` for the categories. `Urbanized?:`, `Limbs?:`, etc.\nCan be handy for generators too. For example, `Urbanized?:` generates much wider range of output than `Urbanized:`.",
    "y22-m07-d31",
    "ai-writing-help"
  ],
  [
    "I reckon you still don't want to say something like \"there are no fantasy creatures in the story\"",
    "`He has no hair` is much stronger than `He lacks hair`, etc. Just check the probs.",
    "y22-m07-d31",
    "ai-writing-help"
  ],
  [
    "I know you should avoid negatives, but what about words where the negative has to include the word you want to avoid? In this case, hairless to mean complete lack of hair on the body. It seems like it still triggers the AI to mention hair.\nI can't think of another synonym, so negative bias?",
    "Nothing wrong with using negatives. Those tend to be stronger than the alternatives.\nThough the strongest method that I've found is with Attributes in Krake, by using something like: `Hair?: None, has scales instead.`",
    "y22-m07-d31",
    "ai-writing-help"
  ],
  [
    "No one uses pocketwatches anymore",
    "",
    "y22-m07-d29",
    "general"
  ],
  [
    "What font would include it?",
    "Most Sans fonts should.",
    "y22-m07-d27",
    "novelai-discussion"
  ],
  [
    "<@409511804293611530> I'm sure you're aware of this. Do I need a font update or something along those lines?",
    "It shows up as a placeholder character (question mark in box)? If so, that's just your selected font missing the symbol. It'll still work.",
    "y22-m07-d27",
    "novelai-discussion"
  ],
  [
    "What unspeakable things are you and Sage doing to poor Sigurd behind the scenes? <:cryblob:673919103404081156>",
    "",
    "y22-m07-d26",
    "novelai-discussion"
  ],
  [
    "Also all of our stories and content is completely private right \ud83e\udd14",
    "So private that we can't recover them, no matter what. Lost password = everything's gone. So make backups.",
    "y22-m07-d26",
    "nsfw-discussion"
  ],
  [
    "Actually, NAI can generate pretty decent articles if we bothered to do so.",
    "The `History` module is particularly good at that. Really puts the AI into textbook-style mindset. It's what I'd use if I needed help writing an essay.",
    "y22-m07-d25",
    "novelai-discussion"
  ],
  [
    "A safe mode is possible and planned, but not a priority",
    "We're not AID.",
    "y22-m07-d25",
    "general"
  ],
  [
    "<@409511804293611530> add more cyberflirting in the next batch",
    "Sure. Just send me your logs so I can include them.",
    "y22-m07-d25",
    "general"
  ],
  [
    "Tried to get Krake to write a split personality character that sees the other personality as a hallucination and I'm failing at it spectaculary. <:hah:844747249505402880>",
    "I've had some success with that.\nhttps:\/\/discord.com\/channels\/836774308772446268\/919724433013346324\/987846199899988009",
    "y22-m07-d24",
    "novelai-discussion"
  ],
  [
    "<@178423511969169408> where should I put [ post-apocalypse ] on, Tags or Genre?",
    "Genre, though I'd recommend `post-apocalyptic`.",
    "y22-m07-d24",
    "ai-writing-help"
  ],
  [
    "Can we Uh... disable comment avatar? It\u2019s kinda... creepy, she\u2019s staring at me\ud83d\ude30",
    "`AI Settings` - > `HypeBot: Off`",
    "y22-m07-d24",
    "feedback-suggstions"
  ],
  [
    "I don't think art should be designed with the intention to obfuscate",
    "https:\/\/www.eggplante.com\/wp-content\/uploads\/2015\/01\/D4-Gameplay-3.jpg",
    "y22-m07-d24",
    "general"
  ],
  [
    "Pretty sure NAI strips trailing white space",
    "Unless you tell it not to.\nI can't think of a valid use for this, so not sure why this is even an option. Easiest way to mess up the output.",
    "y22-m07-d23",
    "novelai-discussion"
  ],
  [
    "It would explain a lot in our history if people were just hungry and cranky a lot for the time.",
    "I've been on alternate-day fasting for months. Stopped feeling hungry after a week or so.",
    "y22-m07-d21",
    "novelai-discussion"
  ],
  [
    "Is the manhattan distance for `[` and `.]` in this resource? Base training could explain why I continue getting good results with brackets despite community thinking they are unnecessary and modern dataset using them in a specific way.",
    "`[` is part of both the chapter headers and ATTG. Though the following token normally has a space after it in the dataset. The main difference is that you're using `.]` instead of ` ]`.",
    "y22-m07-d20",
    "community-research"
  ],
  [
    "<@201031883360960522> <:berk:837330926866268160>",
    "",
    "y22-m07-d20",
    "novelai-discussion"
  ],
  [
    "How does the AI handle the tag 'size difference'? And is it implementing the size in a meaningful way into the act itself?",
    "It's not strong, but better than having no tag for it.\nWith some retries Krake is capable of handling various size difference kinks, such as bodyjobs\/cock riding\/unbirthing.\n(Not sure about Euterpe.)",
    "y22-m07-d18",
    "nsfw-discussion"
  ],
  [
    "So back to NSFW talk, what module\/tag\/prose should I give the AI in order to fornicate with a faerie",
    "Likely No Module, with something like `[ Tags: fae, nsfw, size difference; Genre: erotica ]`. Urban Fantasy might also work.",
    "y22-m07-d18",
    "nsfw-discussion"
  ],
  [
    "For scenes in a bath house, would you pick cross-genre or feudal japan? Or maybe roman empire, those are also known for their baths?",
    "Egypt could be worth a shot too.",
    "y22-m07-d18",
    "nsfw-discussion"
  ],
  [
    "I'm trying to create a siege of Sarajevo type situation with my city",
    "Tried this combo of tags, and Krake defaulted to Sarajevo without directly prompting for that. <:kek:692062611659030548>",
    "y22-m07-d18",
    "ai-writing-help"
  ],
  [
    "Are there any settings\/modules\/genres to help Krake coming up with good characters? Honestly,  that's one I'd the things I really miss front OAI's Dragon.",
    "Have you checked Lorebook generator feature?",
    "y22-m07-d17",
    "ai-writing-help"
  ],
  [
    "Come to think of it, who is the most sesquipedalian loquacious purple prose author you can think of? Mainly think in terms of adjectives prefixed to intricately woven words.",
    "Already way ahead, if you're planning what I think you're planning.\nBut, let's see... Guy Gavriel Kay, Jack Vance, Ann Maxwell, Lord Dunsany, Tanith Lee. For starters.",
    "y22-m07-d16",
    "module-discussion"
  ],
  [
    "I leave hints in the author note that are relevant to the scene:\n`Squidward hates having people over, especially someone as noisy as SpongeBob.`\n`[ Style: laconic, wistful ]`",
    "Interesting. Directing the AI, then immediate Style tag so it doesn't pick up too much on the style used for the directions? I could see that working, at least in Krake. I'll have to experiment with that.",
    "y22-m07-d16",
    "ai-writing-help"
  ],
  [
    "not. I literally biased a word below -0,6 and the AI just created nonsense by leaving out letters while still generating the word",
    "Yea, this is my experience with heavy negative biases. The AI will just try to get around it, and it'll devolve into nonsense. I prefer a combo of banned tokens and slight up-bias on the good stuff.",
    "y22-m07-d16",
    "nsfw-discussion"
  ],
  [
    "There's about a dozen specific words\/phrases that if I can rule out in specific areas that my experience with NAI would be much better.",
    "Out of curiosity, what's the worst one? (I could always check the dataset and see which novels overuse them, and whether they're tossable. <:kek:692062611659030548>)",
    "y22-m07-d15",
    "novelai-discussion"
  ],
  [
    "First time trying to make a module",
    "No, that's good. Lower is better.",
    "y22-m07-d15",
    "module-discussion"
  ],
  [
    "I was wondering if anyone knew if those were archived anywhere or if a link to that was available",
    "Check the pins <a:checkPins:672471936881917994>.",
    "y22-m07-d15",
    "nsfw-discussion"
  ],
  [
    "<@409511804293611530> How painful is it to go through all the zoomer and xoomer and whatever generation's smut and weird fiction?",
    "Not at all. I love it.",
    "y22-m07-d15",
    "novelai-discussion"
  ],
  [
    "https:\/\/en.wikipedia.org\/wiki\/MSX#Impact",
    "This is what I started with - http:\/\/www.computinghistory.org.uk\/userdata\/images\/large\/59\/74\/product-85974.jpg",
    "y22-m07-d15",
    "novelai-discussion"
  ],
  [
    "how old are you? <:MonkaW:875483161985957948> <@409511804293611530>",
    "About the same as Sage.",
    "y22-m07-d15",
    "novelai-discussion"
  ],
  [
    "ahh looks like it's called alley cat (1984)",
    "That's something that pretty much everyone in my age range has played. Somehow it ended up on all school computers.",
    "y22-m07-d15",
    "novelai-discussion"
  ],
  [
    "Rookie numbers.",
    "Mine. This doesn't seem right. Keys from bundles are probably inflating this.",
    "y22-m07-d15",
    "novelai-discussion"
  ],
  [
    "~~`[ Style: bad fanfiction, spelling errors, Mary Sue ]` doesn't work, i want a refund~~",
    "",
    "y22-m07-d15",
    "ai-writing-help"
  ],
  [
    "It's literally a descriptor for *unreadable* floweriness, not for elaborate, descriptive writing",
    "Keep in mind that Style tagging doesn't force the AI into that style, it just nudges it towards it. May need to rethink using it in AN if it becomes too powerful in future models, but for now 'purple prose' simply makes the text slightly more flowery.",
    "y22-m07-d15",
    "ai-writing-help"
  ],
  [
    "Outputs are not good for me, mostly unrelated to the prompt. And often abotu an old man for some reason",
    "Tried a different summary. ```Summary: The Keepers are a secret sect that has been maintaining an ancient library for thousand years or more \u2014 nobody knows for how long. It is said to contain all the knowledge of the world.\n***\nWhat is real? Is the \"real\" world more than just the physical one we live in, with our senses and our brains? What if there was a place where something more substantial exists beyond the borders of our space and time?\nThe theory goes like this: Imagine two parallel lines, so far away from each other they can't be seen by the naked eye. Both lines are moving at the same speed in the exact same direction. One line represents the physical world, filled with objects such as stars, planets, trees, rocks, water, air, people, and so on. The second line represents the universe of ideas \u2014 every book ever written, every song ever sung, every thought that's ever occurred to anyone who ever lived.\nNow imagine those two lines are approaching each other until they eventually meet. Every single idea in this universe will cross over into the physical realm, changing it in ways we don't even begin to understand. This is the moment of convergence when the physical and the metaphysical come face to face. At that very moment, the lines meet, creating one single line instead of two. It would look like a huge wave, rippling out towards infinity.\nThat moment is called the Great Convergence, and it is coming to pass now. For thousands of years, the Keepers have been preparing for it.\n***\nOnce upon a time, there was no Librarian. There was no Library. Once upon a time, there were no books. There were no people. The earth had not yet formed. The sun had not yet begun its journey through the heavens. Life had not yet begun to crawl from the primeval seas.\nOnce upon a time, there was only darkness.\nThis is what you were told, what was always taught. I say once upon a time because such stories of the ancient past cannot be proven, and even if they could be, their validity is unimportant. What matters is what happened after that first moment, when light was born out of darkness.\nBut that too is only myth, for the truth of things never came down to us in any way other than metaphorical. A story is what it is. The first idea is the seed from which a multitude grew. Ideas are more important than facts.```  Dunno where this is going, but that's typical for `Magic Library`. <:shrug:332268181517238272>",
    "y22-m07-d14",
    "novelai-discussion"
  ],
  [
    "Like it thinks orgasm = end",
    "Haven't seen that, at least not consistently. Females average three (though sometimes it gets into the 'lost count' territory), and even for males, if you continue with some pillow talk, they'll be going for round two after a bit.\nMaybe it's certain type of characters or kinks. First time \/ virgin is probably going to end in one.",
    "y22-m07-d14",
    "nsfw-discussion"
  ],
  [
    "Zaltys did th rest of the 46. Lion did 1. \ud83d\ude42",
    "The `Inspiration` modules are by someone else.",
    "y22-m07-d14",
    "novelai-discussion"
  ],
  [
    "What sort of works are included in Euterpe and Krake's Dark Fantasy module?",
    "Grimdark anti-hero type of fantasy. A lot of demonic possessions and such.\nIf that module were a game, it'd be something like Darkest Dungeon or Drakengard.",
    "y22-m07-d13",
    "novelai-discussion"
  ],
  [
    "Or I just bit the bullet and just buy extra copies.",
    "Likely cheaper than buying something like ScanSnap SV600. Unless you're planning to scan hundreds of books.",
    "y22-m07-d13",
    "novelai-discussion"
  ],
  [
    "I was wondering how the dinkus (<:dinkus:928210494932799548>) works. So far I've only used it to seperate the story and use the dinkus lorebook entry\nBut if it is used what part of the story is actually affected? Does the AI completely forget everything before the <:dinkus:928210494932799548> ?",
    "Input: ```I left the dungeon behind and hit the road, a long journey back home ahead of me.\n***```\nOutput: ```I arrived in Nijhoff a day later than expected. I was exhausted, and not only physically. It felt like I had been walking for a year straight. I could hardly even remember the last time I slept soundly.```",
    "y22-m07-d13",
    "ai-writing-help"
  ],
  [
    "Anyone ever manually scan in old paperbacks for a module?",
    "Yep. I generally use a heat gun to take them apart, and OCR with ABBYY (the only one that actually works reliably.)",
    "y22-m07-d13",
    "novelai-discussion"
  ],
  [
    "What would be the most cursed weapon to have?",
    "My mind instantly went to Elona, and using panties as a weapon.",
    "y22-m07-d12",
    "novelai-discussion"
  ],
  [
    "I do not have that",
    "Also try `[ Tags: cozy ]`. 'cozy mystery' is a genre with a lot of slice-of-life in it, and Krake at least seems to have picked up on that. (`[ Genre: cozy mystery ]` wouldn't work, as that throws in frequent corpses.)",
    "y22-m07-d11",
    "ai-writing-help"
  ],
  [
    "Not many people new to the server call Kurumuz Kuru",
    "To be fair, not exactly new.\nBut yeah, put together it seems clear...",
    "y22-m07-d11",
    "novelai-discussion"
  ],
  [
    "I have been going back and forth on whether ---- or *** work better for generator scenarios",
    "`----` should work better in Krake, while Euterpe still uses `***`.",
    "y22-m07-d11",
    "novelai-discussion"
  ],
  [
    "Random question since I forgot, what was the separator which used dashes? `-----`?",
    "Four.",
    "y22-m07-d11",
    "novelai-discussion"
  ],
  [
    "Yungoos is because plot",
    "...toxicroak then.",
    "y22-m07-d11",
    "novelai-discussion"
  ],
  [
    "Now generate Finland 2!",
    "It went for Europa Universalis 4 level of alt history. <:shrug:332268181517238272>",
    "y22-m07-d10",
    "novelai-discussion"
  ],
  [
    "It's like 2",
    "It depends entirely on how wide your text window is...",
    "y22-m07-d09",
    "novelai-discussion"
  ],
  [
    "And it continues getting off-track. <:sigh:838312001641381950>\n\n\nWhere the hell did I go wrong in lb creation?! <:blackshibu:339536777088073730>",
    "This may sound counterintuitive, but try adding `----` before those entries.\nAnd add a `***` at the point where you want it to switch to prose.",
    "y22-m07-d09",
    "novelai-discussion"
  ],
  [
    "The AI seems to not be able to properly rhyme.",
    "Yea. It's all just token numbers for the AI, it has no clue about which ones rhyme.\n...now I'm tempted to grab some data from RhymeZone and see if that'd help.",
    "y22-m07-d09",
    "novelai-discussion"
  ],
  [
    "Though all are separate entries.",
    "Odd. I don't see anything there that'd trigger `----`.",
    "y22-m07-d09",
    "novelai-discussion"
  ],
  [
    "What Model and Config Preset is best for poetry?",
    "Krake, with `[ Style: poetry ]` tag.",
    "y22-m07-d09",
    "novelai-discussion"
  ],
  [
    "The AI likes to consistently misspell uncommon names, even if I've personally spelled them correctly the entire time, without exception. How do I make it stop that?",
    "This is usually caused by too strict rep penalty.\nDepending on the tokens, you might be able to use bias with `Ensure Completion` enabled to fix it, but it might have side effects.",
    "y22-m07-d09",
    "ai-writing-help"
  ],
  [
    "Is Style: in the finetune?",
    "Some of it, mostly added for Krake. Not enough to be strong yet, I have plenty of other projects and most other datasetting members haven't been active in months.\nKrake has been trained so that those can be inserted anywhere, so `[ Style: ]` tags may be one of the few things that actually work in AN.",
    "y22-m07-d09",
    "community-research"
  ],
  [
    "`[ Writing style: Vividly descriptive, with emphasis on embellished adjectives, evocative of sensory observations with detailed character descriptions and purple prose.]`",
    "Simple lists aren't bad either.\nBlank generation from `[ Style: verbose, evocative, purple prose, descriptive ]`: ```The forest of dreams had many names. Some were thin and filigreed, barely there. Others were as broad and sturdy as the largest trees in the jungle. The one called home by all who knew its secret was a forest thick with power, blood-soaked ground that grew grass like daggers. Here, in this place where all paths led, it took an unusual mind to be able to navigate.\nDeeper into the dreamscape than the tangled grasp of roots, branches and leaves, past the blood-rich earth that sucked at your footfalls and then spat them out, deeper still... here it took a rare kind of willfulness to persevere against the constant threat of madness and the darkness that tried to wrap you up in its arms. Here it took magic, powerful and dangerous; force of will that could rival the strongest of gods; and finally, hope.\nSo far, hope had yet to fail him.```",
    "y22-m07-d09",
    "community-research"
  ],
  [
    "No, regular dragons. Like the one in The Hobbit movie",
    "I've been noticing that as a trend in the recent years, even in published fiction. ...No, I don't mean dragon nc, but human\/dragon relations in general. I keep running into that when working on the dataset.\nFor instance, I was just browsing this book - https:\/\/www.goodreads.com\/book\/show\/36703268-bound-in-scales\nThe protagonist ||accidentally transforms into a dragon, and it doesn't take him long to find a mate. Wasn't exactly graphic, but... ||",
    "y22-m07-d09",
    "nsfw-discussion"
  ],
  [
    "dunno if that fits your question, but I have a `Staff:` Attribute in my Location-LB that have named characters as staff working there (so, kinda a `Characters:` list)\nKrake is quite solid in pulling the names from there when needed\ncan't say how solid since that is just my observation from just playing along the story without checking probs every generation",
    "Thanks. I rarely have time to actually use NAI, so my testing of `Characters:` has been limited to small scenarios with a few characters. Those seem to work well, but definitely needs more research about at what point it breaks down (starts to mix up characters) \u2014 and what is the optimal length for the character descriptions.\n\nAs for `Glossary:`, that's somewhat similar to what Belverk's done with Traits. A list of words with short definitions. Krake seems good enough at understanding those, so I sometimes just add that to Memory instead of bothering with complex lorebook entries.",
    "y22-m07-d08",
    "community-research"
  ],
  [
    "Hm. ~~Not in the dataset~~, but how about `Cast:`",
    "Plenty of those in the dataset, but mostly for movies. Can't recommend for generic use.",
    "y22-m07-d08",
    "community-research"
  ],
  [
    "so is it still bad practice with euterpe+krake to  utilize author's note like `[ style: W; tense: X; genre: Y; tags: Z ]` ?",
    "One thing that _might_ still work in AN is the `[ Style: ... ]` tag. As there's a bit of dataset support for that. But only a bit, so it's difficult to tell if it's actually working, or just placebo.\nI've been using `[ Style: verbose ]` in some scenarios, and it's at least not hurting the output. Unlike most things that I've tried in AN.",
    "y22-m07-d07",
    "novelai-discussion"
  ],
  [
    "A quick question, if I want to write a story about Ottoman empire and just middle eastern in general, whick module should I be using? There's Historical, Medieval and Egypt?",
    "History might be hard to steer into prose, but it definitely has some Ottoman in it. (It also handles alt history nicely, from what I've seen.)",
    "y22-m07-d06",
    "module-discussion"
  ],
  [
    "If I wanted to prepare a character in the lorebook for me to encounter later, how would I do that? I guess the actual question is how would I list their traits or personality in the lorebook so that it fits smoothly and the ai actually uses the \u201cpersonality\u201d I wrote?",
    "For the second question, there's two common methods. You can use prose and place it near where the character appears in the context. Alternately, you could use Attributes and place that early in the context. Pume wrote a guide for that - https:\/\/rentry.co\/lorebook-guide",
    "y22-m07-d06",
    "ai-writing-help"
  ],
  [
    "Has anyone played a prompt in this style?\n```Information on the conversation below:\n- Bob is a beginning Dungeon Master\n- Joe is an experienced Dungeon Master who will give him good advice\n***\nBob: Hey so I wanna be a DM but don't know what to do```\nTo try to get advice on or talk about some pre-defined topic.",
    "You could probably shorten it to... Let's see. Yep, this seems to work.",
    "y22-m07-d06",
    "novelai-discussion"
  ],
  [
    "in y'all's opinions does writing dialogue like `Name: Hi.` instead of `\"Hi,\" said Name.` significantly affect quality (via the ai assuming it's supposed to write amateurishly)\ni personally am a tasteless pleb and thus can't tell",
    "Yes, it should be able to handle it. Though the chat style has a lot of casual chat in it in addition to scripts and deeper discussions. So that style is highly dependent on you start the conversation.",
    "y22-m07-d05",
    "ai-writing-help"
  ],
  [
    "What about autism?",
    "Yes, there should be enough in the dataset for Krake to have some idea, at least. Try `[ Tags: autism ]`",
    "y22-m07-d05",
    "ai-writing-help"
  ],
  [
    "<@409511804293611530> hi. I want to use chapter breaks.",
    "That's `***`.",
    "y22-m07-d05",
    "ai-writing-help"
  ],
  [
    "So it would repeat the setting in that same ---- block?",
    "Yes, repetition can be useful. Single instance is rarely enough for it to learn.",
    "y22-m07-d03",
    "novelai-discussion"
  ],
  [
    "In the example you posted, would that go underneath the \"Setting:\" line and before the dialogue example line?",
    "It's built to be flexible, no need to worry about field orders. Just need those first, then a bit of prose.",
    "y22-m07-d03",
    "novelai-discussion"
  ],
  [
    "So it's for seperating training examples? Like\n```\"The witch in the woods\"\nShe scary af\n----\n\"Zaltys' terrible secret\"\nNobody will ever know```",
    "It varies a lot, but an average data entry would be something along the lines of: ```\n----\nEzreal, The Prodigal Explorer\nSetting: League of Legends\n\u2002\"If I don't know the rules, then how can I be breaking them?\" \u2014Ezreal\nA dashing adventurer, unknowingly gifted in the magical arts, Ezreal raids long-lost catacombs, tangles with ancient curses, and overcomes seemingly impossible odds with ease. His courage and bravado knowing no bounds, he prefers to improvise his way out of any situation, relying partially on his wits, but mostly on his mystical Shuriman gauntlet, which he uses to unleash devastating arcane blasts. One thing is for sure\u2014whenever Ezreal is around, trouble isn't too far behind. Or ahead. Probably everywhere.``` Followed by more entries for different characters.",
    "y22-m07-d03",
    "novelai-discussion"
  ],
  [
    "Zaltys has all the mental qualities of student body president, but wouldn't ever take that role willingly because multiple reasons \ud83e\udd14",
    "Pfft. I'm clearly the janitor.",
    "y22-m07-d03",
    "novelai-discussion"
  ],
  [
    "\"her stringy orchid twines of hair swaying gracefully over the lithe opaque nose, as she raised a half drained mug to her pale red lips.\"",
    "Goes to show that verbose isn't always good. (...not sure what 'orchid twines of hair' is even supposed to mean. Is her hair literally purple?)",
    "y22-m07-d02",
    "novelai-discussion"
  ],
  [
    "Well, beyond having decent language skills, being a good writer also involves things like knowing how to make a story engaging to read.",
    "```Grignr weighed his position observing his plight, where-upon he took the soldier's advice as the only logical choice. To attempt to hack his way from his present predicament could only warrant certain death. He was of no mind to bring upon his own demise if an alternate path presented itself. The will to necessitate his life forced him to yield to the superior force in hopes of a moment of carlessness later upon the part of his captors in which he could effect a more plausible means of escape.```",
    "y22-m07-d02",
    "novelai-discussion"
  ],
  [
    "it's an email",
    "Correct usage of en space for that.",
    "y22-m07-d02",
    "module-discussion"
  ],
  [
    "Like when my character looks up a profile... I want the format in a specific way but the contents kind of random",
    "You could have the character look at their own profile first, then make it clear that they're looking at a different one next.",
    "y22-m07-d01",
    "ai-writing-help"
  ],
  [
    "exactly!",
    "They take care of that before going into hibernation.\nHibernation burns fat reserves. Just like humans going on fast.",
    "y22-m07-d01",
    "novelai-discussion"
  ],
  [
    "But yea you probably mean this part\n> You shall not lie with a male as with a woman; it is an abomination.",
    "Which might be a mistranslation, btw. It uses the familiar variant of male, which is odd if it intended as a blanket ban (one wouldn't use that for prostitutes, for instance). And since it's in chapter that mostly focuses on incest, the original intent might be closer to \"don't sleep with your sons either\".",
    "y22-m07-d01",
    "nsfw-discussion"
  ],
  [
    "I tried to google of that's a real word but google is just confusing me",
    "`Compleat is said to mean 'quintessential', one meaning of complete is closely related as 'skilled; accomplished'. In Britain, compleat is archaic, used in writing only as a bit of whimsy, and at that rather rarely.`\nD&D used it in a few guides.",
    "y22-m07-d01",
    "novelai-discussion"
  ],
  [
    "Thanks! I been trying to explain my characters description in the logbook such as \"The character has long blue hair.\", and also writing in  tags something like : \"Appearance: long blue hair\" to help the AI be more accurate,but it's not picking up that.",
    "Try hair\/eye etc colors in `Attributes:` instead. Worked better the last time I tested the probs. `Appearance:` is good for generic appearance, though.",
    "y22-m06-d30",
    "novelai-discussion"
  ],
  [
    "<@409511804293611530> How did you come up with your username?",
    "https:\/\/en.wikipedia.org\/wiki\/%C5%BDaltys",
    "y22-m06-d30",
    "novelai-discussion"
  ],
  [
    "do you think any other enclosing marks would be necessary?",
    "Not needed.\n`<text>` are used for telepathy, but can work with thoughts too.",
    "y22-m06-d30",
    "novelai-discussion"
  ],
  [
    "how would you indicate inner thoughts to the AI then?",
    "Add something like `, he thought.` to the thought.",
    "y22-m06-d30",
    "novelai-discussion"
  ],
  [
    "I've heard about the em-space. Do you need to put those after each line or just during\/after the prompt?",
    "Once is usually enough, though you might need to re-add if the AI switches to prose after one song\/poem.",
    "y22-m06-d29",
    "ai-writing-help"
  ],
  [
    "I know there are Devil May Cry novels, a good bit of them. Would be pretty neat if some made a DMC module.",
    "Are there? All I can find is manga and western graphic novels. But there's so many of those that there _might_ be some novels lurking among those.",
    "y22-m06-d29",
    "module-discussion"
  ],
  [
    "Assumption is that\n```\nThe story so far:\n```\nworks fine by itself\n\nAlthough might want to add a dinkus\n\n```\n***\nThe story so far:\n```",
    "Likely won't need one before `The story so far:`, but there should be a dinkus between that and the story main.",
    "y22-m06-d26",
    "community-research"
  ],
  [
    "John Doe does look to be more effective for Krake than John Smith.",
    "John Doe's pretty heavily associated with cadavers. Might take it into wrong direction. Not that I have better suggestions. (Joe Public is likely not widespread enough. Could try `Anon` for laughs.)",
    "y22-m06-d26",
    "novelai-discussion"
  ],
  [
    "I have a question. If i would like to change the tone of the story like make it more darker or something, how would I go about it? Would I use author's note or memory?",
    "`[ Tags: dark ]` in Memory, at the top.",
    "y22-m06-d25",
    "novelai-discussion"
  ],
  [
    "Does Euterpe have a poetry module?",
    "Won't need one. Just prompt with em space (`\u2003`).",
    "y22-m06-d25",
    "novelai-discussion"
  ],
  [
    "This is how my current lore book is set.\nName: \nGender: \nRace: \nMind: \nAttributes:  \nprose:\n\nSo when adding wearing would it be added to into the prose or it\u2019s a separate category Ex: Wearing:\n\nAlso how would I make it work for a character with different sets of clothing?",
    "> Also how would I make it work for a character with different sets of clothing?\nCould try `Wears: clothes 1 or clothes 2`, but Krake seems to go for the first 90% of time.\nIf I want variety, I tend to just put in something like `Wears: Gothic style`.",
    "y22-m06-d24",
    "ai-writing-help"
  ],
  [
    "What is the best way to summarize current\/past events in a story in memory so that the AI doesn't keep circling back to them? Should I just put summary: with a brief summary sentence? Or put each event on one line as a sentense.",
    "```The story so far: (few sentences, don't make it too long)\n***``` in Memory has worked quite well for my uses. In Krake, `Summary:` can also work.",
    "y22-m06-d23",
    "ai-writing-help"
  ],
  [
    "Refering to the conversation from yesterday: I tried setting up a [ Chatroom ] and noticed that the text generation does not stop after the AI's response, but instead continues to fill in the user's part. Is there a way to limit the AI to only answer\/reply their part?",
    "Put `:` as a stop sequence. Then it'll output whatever name you're using, but not dialogue. ...or you can use `\\n` for that, so it stops at line break.",
    "y22-m06-d22",
    "nsfw-discussion"
  ],
  [
    "Valentine is also surprisingly good at it despite being a SFW one",
    "None of themed modules are SFW. Except Childrens, due to the material used. Novels written for adults tend to have adult bits in them.",
    "y22-m06-d22",
    "nsfw-discussion"
  ],
  [
    "Is Calypso any good? I only used it once, but it ended up repeating paragraphs",
    "Calypso has minimal Top-K with restrictive settings, so that'll happen. The AI can't do much about repetition when there's only one option to choose from.",
    "y22-m06-d22",
    "novelai-discussion"
  ],
  [
    "For those who use Krake: What's your most liked Krake preset?",
    "Krait",
    "y22-m06-d22",
    "novelai-discussion"
  ],
  [
    "How do I make the Ai stop generating at [198]?",
    "Put `\\n` in Stop Sequences (`Advanced` tab)",
    "y22-m06-d21",
    "ai-writing-help"
  ],
  [
    "My question in the other channel would be like \"If I was writing a really long speech from someone's PoV or something, how do I stop the AI from finishing with the speech, and then beginning to narrate a story, because it keeps doing it\". Or like, getting Krake to pretend it's a chatbot or something.",
    "Chat's easy. To get it started, prompt with something like: ```[ Chatroom ]\nKrake:``` to get it going. (Can try with `[ IRC ]`, `[ Podcast ]`, `[ Interview ]` etc for different nuances.)",
    "y22-m06-d21",
    "nsfw-discussion"
  ],
  [
    "Is using the numerical age prefered over writing it, bc of context length?\ni.e. Age: 19",
    "Many numbers (such as ' nineteen') are actually single token even if written out.",
    "y22-m06-d21",
    "ai-writing-help"
  ],
  [
    "<:shrugss:849029416725905428> If it works, it works",
    "The AI does just fine without slashes. Not like you need to tell it what abrasive etc mean.",
    "y22-m06-d21",
    "ai-writing-help"
  ],
  [
    "Zaltys question: are noises generally in * *?",
    "Yes.",
    "y22-m06-d21",
    "ai-writing-help"
  ],
  [
    "The dolphin was still humanized to some degree, which became less as I added more story, but sometimes it talked back etc..",
    "There's several fields you could try. I'd try something like this: ```\n----\nBob\nSpecies: Dolphin\nAttributes: Animal, regular dolphin\nMental: Smart animal\n\u2002*click* *whirr* \u2014Bob``` (Last row's a 'quote'.)",
    "y22-m06-d21",
    "ai-writing-help"
  ],
  [
    "If there is no space, something went definitely wrong",
    "` indul|gently` <:ogtroll:838076368633593866>",
    "y22-m06-d20",
    "novelai-discussion"
  ],
  [
    "Does that just plopped in wherever in the finetune, or does that come in right after chapter breaks?",
    "Yep, after scene breaks.",
    "y22-m06-d20",
    "novelai-discussion"
  ],
  [
    "All the entries have been unbracketed for Euterpe and Krake",
    "No? They weren't there in the first place. Except for what I've outlined in that one pin.",
    "y22-m06-d20",
    "novelai-discussion"
  ],
  [
    "Stuff like `Scene: Tavern`.",
    "If it's that basic, then just `[ Tavern ]`. Though `Scene:` does seem useful for longer descriptions. Those mostly come from scripts (theatre, TV shows) and such.",
    "y22-m06-d20",
    "novelai-discussion"
  ],
  [
    "A Stone Age Module would be nice to have \ud83d\ude1b",
    "Have you tried the official `Theme: Hunter Gatherer`?",
    "y22-m06-d19",
    "ai-writing-help"
  ],
  [
    "do you have to do anything special to get the AI to recognize plural versions of madeup words? For example, if you make a lorebook entry on a species named \"succubi\", how would you teach it that the singular version is succubus? Pretend that the AI doesn't know what a succubus is.",
    "Try this in memory (or lb if you prefer, but should be pretty high in context): ```Glossary:\nSuccubus (pl. Succubi): small description here\n***``` There's so many glossaries in there that it's gotten pretty good at them.",
    "y22-m06-d19",
    "ai-writing-help"
  ],
  [
    "I can relate to some degree, but sex in public places is thrilling. More like the *risk* of being watched. Like having sex in a public pool\/nude sauna.",
    "Yea... 'Exhibitionism' includes so many different kinks (public sex, flashing, consensual exhibitionism\/voyeurism, the danger of getting caught in public, etc) that I don't know why they're all lumped under one term.",
    "y22-m06-d19",
    "nsfw-discussion"
  ],
  [
    "Most paid PDF programs have an ocr function",
    "The latest ABBYY Finereader is the only one worth using. Adobe's OCR is terrible.",
    "y22-m06-d18",
    "novelai-discussion"
  ],
  [
    "Can you elaborate on why?",
    "And rn\/m, i\/l\/I in some fonts, etc. Add to this that some pages are often scanned a bit askew, making it even harder for the software to understand...\nI've done OCR scans for the dataset, but they're generally so time-consuming that I try to avoid them. Unless it's something that we really need. Could add twenty other books in the same time from epubs, etc.",
    "y22-m06-d18",
    "novelai-discussion"
  ],
  [
    "Would you ever consider doing a video of you showing off how to clean and format a dataset?",
    "I doubt I could find time for it. Most of the important things are in the wiki - https:\/\/naidb.miraheze.org\/wiki\/Datasetting_for_AI_Modules\nBut an automated tool for actually fixing those would be great.",
    "y22-m06-d18",
    "novelai-discussion"
  ],
  [
    "I can't wait for module v2 to pick up on my every mistake in my training data and shove it back into my face.",
    "Could definitely use some kind of web-based error checker for module data. (I mostly use Notepad++ scripts, not exactly useful for general use.)",
    "y22-m06-d18",
    "novelai-discussion"
  ],
  [
    "would you say attributes put a certain emphasis on what you input vs regular prose, where everything is considered pretty equally unless you configure biases?",
    "Attributes is built so that it should generate decent prose regardless of what's in the fields. Be it lists or prose.",
    "y22-m06-d18",
    "novelai-discussion"
  ],
  [
    "How differently would you say attribute prose and regular prose are considered by the AI? Like, say you'd have prose unformatted vs the same prose formatted in attributes.",
    "Depends a lot on the field. Some of them work better with prose than others. `Attributes:` itself is mainly lists, whereas something like `Summary:` is always prose.",
    "y22-m06-d18",
    "novelai-discussion"
  ],
  [
    "he says *badly phrased* prose is worse than attributes. I said earlier, *if phrased well*, if you remember.",
    "Yep. I'd say that Attributes works decently and definitely beats _bad_ prose, but there's certainly room for improvement. I'll keep working on it...",
    "y22-m06-d18",
    "novelai-discussion"
  ],
  [
    "Definitely not a hoverfly.. it looked like a bumbleebee, with quite the orange color on the back\/butt. But it must be the hulk under his species.. usually I see them about the size of a hazelnut or maybe two times as big.\nThis example was easily six times that size ~2 inches or 4-5 cm",
    "Look up _Volucella bombylans_. There are several hoverfly species that mimic bumblebees.",
    "y22-m06-d18",
    "nsfw-discussion"
  ],
  [
    "Just saw the most impressive bumble bee in my life, it must have been about half as big as a sparrow <:MonkaW:875483161985957948>",
    "Probably a hoverfly. There are some large ones that mimic bumblebees. Either that, or it was a queen. Wrong time of year for those, though.",
    "y22-m06-d18",
    "nsfw-discussion"
  ],
  [
    "But it might also be a placebo effect, I don't know.",
    "Nah. ATTG only appears after <|endoftext|>, so it's heavily associated with a new story. Wouldn't want that in _middle_ of one. Worse than sticking `\u2042` in there.",
    "y22-m06-d17",
    "novelai-discussion"
  ],
  [
    "and why did you censor \"fucked up\", there's no rule on swearing here we're all grown-ass people",
    "I was just editing an older book, and ended up fixing several instances of `d \u2014 d` in it ||Yeah, they used to censor 'damned'||. Standards sure have changed in a few decades..",
    "y22-m06-d17",
    "nsfw-discussion"
  ],
  [
    "You will be able to train your own commentator bots yep!",
    "Can you go into details about how that'll work?",
    "y22-m06-d17",
    "novelai-discussion"
  ],
  [
    "\ud83e\udd37\u200d\u2640\ufe0f  Opus is unlimited. Cell providers used to provide actual free \"Unlimited\" back in the day naively. Then they realized it was not practical or sustainable so now it's \"Unlimited until the first such and such data amount then you get 3G\/2G.\"",
    "Hm. Not sure about that analogy. We still have Unlimited as standard over here, and the tele operators haven't really complained about it being unsustainable.",
    "y22-m06-d17",
    "novelai-discussion"
  ],
  [
    "What if you're just trying to emulate a writing style and not necessarily the lore?",
    "Valid concern. Sounds like it may be an issue for modules that already struggled with name overtraining, etc. Guess we'll see.",
    "y22-m06-d17",
    "module-discussion"
  ],
  [
    "so basically Hypebot is like if you played with someone online and he's reacting to ur story",
    "Just imagine. If training gets added, you could make one called 'Grandma' and see how it reacts. <:troll:763628012838060062>",
    "y22-m06-d16",
    "novelai-discussion"
  ],
  [
    "don't understand the hypebot usage tho",
    "Mostly for fun, I'd assume. Ever watched Mystery Science Theater 3000?",
    "y22-m06-d16",
    "novelai-discussion"
  ],
  [
    "Please any developers reading this, will we be able to generate smut?",
    "I don't see why not.",
    "y22-m06-d16",
    "novelai-discussion"
  ],
  [
    "Prose works if it's lore. The attributes system is generally for characters as far as I'm aware",
    "Yes, mostly characters, due to most existing profiles being characters. I've been adding some support for locations and species, though. And it works great for deities\/religions too.",
    "y22-m06-d15",
    "ai-writing-help"
  ],
  [
    "I haven't had as much success with Krake prose enhancer as I wish",
    "If the prose starts to get noticeably bad, try throwing in something like `[ Style: verbose, detailed ]` at the end and generating from that.",
    "y22-m06-d15",
    "novelai-discussion"
  ],
  [
    "For an adult D&D setting. Is \"generally fantasy\" the best theme setting ?",
    "`General Fantasy` is the standard Tolkienesque fantasy, with humans, elves, dwarves, orcs and the like. So yes, that'd be a decent pick for D&D. I doubt that `Dark Fantasy` will handle D&D weill. That's more of the angsty antihero \/ demonic possession type of fantasy.\nCould be that `No Module` with ATTG  works best, at least in Krake. `[ Tags: D&D; Genre: fantasy ]`, just add whatever else you need.",
    "y22-m06-d14",
    "novelai-discussion"
  ],
  [
    "Are you saying to break up basic character info and exposition into their own separate entries?",
    "No, put it further back and separate with `***`. So the AI will see it as profile or something else that's not part of the immediate story (but still relevant).",
    "y22-m06-d13",
    "ai-writing-help"
  ],
  [
    "Well, I have no idea how to (I don't even know what \"probs\" stand for, total newbie there), but I'll look into it <:guess:872225994197594143>",
    "Re: testing\nFirst `Enable Token Probs` in settings, which adds the <:walnut:926283281253679124> icon to the main toolbar. Then experiment with something like this: ```\nZak\nRelationships: Snap (brother), Crackle (friend), Pop (enemy)\n***\nQ: What does Zak think of Crackle?\nA:``` Generate and check the probabilities for the output. Then try alternate ways (`Relations:` instead of `Relationships:`, separating it into different categories, etc.), and compare to see which is the closest to what you want. For easier testing, set the Top-K to 1.\n\n(Test results from the above show that `Relationships:` doesn't work well. Separate `Enemies:`, `Allies:` and `Family:` categories are better.)",
    "y22-m06-d13",
    "ai-writing-help"
  ],
  [
    "Front and Back Memory? Short Term and Long Term Memory? A real thinker.",
    "Front and back were suggested, but which part of the story is actually the front? (Also consider which side of a book is front.)",
    "y22-m06-d13",
    "novelai-discussion"
  ],
  [
    "hey guys is it possible to create a script for a short movie using novel AI?",
    "Certainly. I'd recommend getting it started with a prompt in script style. As in: ```7TH JUROR (turning to the 8TH JUROR): Do you want some gum?\n8TH JUROR (smiling): No, thanks.\nThe 7TH JUROR vigorously chews a piece of gum himself and crosses to the 6TH JUROR.\n7TH JUROR (mopping his brow): Y'know something? I phoned up for the weather. This is the hottest day of the year.\nThe 6TH JUROR nods and gazes out of the window. ```",
    "y22-m06-d12",
    "novelai-discussion"
  ],
  [
    "Lol, actually the base AI does seem to have some a pretty wide knowledge of quite a few themes Zalty. Actually is really admirable and part of the reason I quite enjoy NAI compared to competitors. Though not gonna lie, I have been messing about with generating specific themed modules for it when I get the chance, there is a TON of potential there for anything anyone could possibly imagine! Def worth the opus sub.",
    "I'm always looking for feedback about themes that don't work in Krake. There are some things that would be better left for modules, but I'm sure there must be some things that have got simply overlooked.",
    "y22-m06-d12",
    "nsfw-discussion"
  ],
  [
    "Interesting. Also, does the Attribute system work with \"younger brother of..\" or short descriptions as \"hates xy\"?",
    "Latter should work in `Attributes:`. For the former, I'd give something like `Family: Name (older brother)` a try. (Due to all the wiki data in there, fields like `Allies:` and `Enemies:` likely work similarly.)",
    "y22-m06-d12",
    "ai-writing-help"
  ],
  [
    "Does ``Appearance:`` also work for stuff like ``Young-adult, muscular, pale``",
    "Should. Lemme check what that does to the probs. ...yea, still functional.",
    "y22-m06-d12",
    "ai-writing-help"
  ],
  [
    "``Attributes:`` over all this other stuff?",
    "I usually keep `Wears:` and `Mental:` separate, just to make them a bit stronger. Also, `Type: Antihero` should be useful for that entry.",
    "y22-m06-d12",
    "ai-writing-help"
  ],
  [
    "```\nHair: Brown, Short\n```",
    "I don't see much difference with varieties that I tried, at least not in Krake. Probs are similar for `Hair: Brown and short`, `Hair: Short, brown`, etc.\nAttributes was built for versatility, looks like that's working as intended.",
    "y22-m06-d12",
    "ai-writing-help"
  ],
  [
    "Does this look good context wise? Story is directly after the dinkuses",
    "Attributes don't use `;`. Those likely do more harm than good there. If nothing else, it wastes tokens.\nSo basically: ```Hair: Brown hair\nEyes: Green eyes\nSkin: Pale skin``` etc instead. Won't really need to repeat 'eyes' etc in there, just `Eyes: Green` should work. But reinforcing doesn't hurt. And I'd use commas instead of slashes. Also, go with lowercase for genre list. Uppercase tends to draw from game reviews and such, which is rarely wanted behavior.\n(Personally, I'd combine a lot of those in one field. `Attributes: Straight, single, brown hair, green eyes, pale skin`, but doesn't hurt to experiment.)",
    "y22-m06-d12",
    "ai-writing-help"
  ],
  [
    "In my next series of prompts, I'm going to keep it to the absolute essentials. Ergo, three lorebook entries:\n[ Name: Zodip Grim; Wife: Adalace; Team: Adalace, Casid; ]\n[ Name: Adalace Grim; Husband; Zodip; Team: Casid, Zodip; ]\n[ Name: Casid Lore; Team: Adalace, Zodip; ]",
    "This in Krake? Try without brackets. Attributes was made to work without those.",
    "y22-m06-d11",
    "novelai-discussion"
  ],
  [
    "During reverse engineering\n`[ Tags: nsfw ]`\npops up a lot. I'd use that",
    "`[ Tags: nsfw; Genre: erotica ]` if someone wants to overload it.",
    "y22-m06-d10",
    "ai-writing-help"
  ],
  [
    "a great example is also Sage, he has made dozens of modules (probably over a 100 even), most of the default ones, and he often asks us for feedback on modules he made. and it wouldn't even surprise me if he reads many thousands of words of output from each module--because nobody really knows what will happen when you do something with the AI, other than by trying things and reading the output",
    "Uh, most of the modules were by me.",
    "y22-m06-d09",
    "ai-writing-help"
  ],
  [
    "Try `[ Characters:    ]`",
    "Or try without brackets. I can't think of any instances where cast list would be in those.",
    "y22-m06-d08",
    "ai-writing-help"
  ],
  [
    "Is there a way to combine different franchises into a story? With ATTG I thought of combining [ Tags: Star Wars, Star Trek ] to see if it'd start pulling characters from both and coming up with something. Turns out whatever the first tag is it'll dominate with that, so in this case Star Wars.",
    "(Cringe.) Yeah, for the most part, once it picks one it seems to mostly stick to that.\nThough I didn't play enough to see if it'd alternate after `***`s.",
    "y22-m06-d08",
    "ai-writing-help"
  ],
  [
    "A dinkus is three asterisks `***` and the AI is trained to recognize it as a chapter break.",
    "More like a scene break, btw. Most authors use several of those per chapter. Also used for separating different styles, such as a glossary from prose.\nAt the very minimum, I'd recommend using it at the end of Memory. Well, depending on what's in there.\n(On the other hand, repeating `***` should be avoided, which may be tricky with lorebook content.)",
    "y22-m06-d06",
    "ai-writing-help"
  ],
  [
    "What'd be the best model for modern writing? A suburban family story",
    "Likely No Module with tags. Something like `[ Tags: contemporary, suburban, family life; Genre: nonfiction ]` in Memory.",
    "y22-m06-d06",
    "module-discussion"
  ],
  [
    "Is there any downside to using too many steps? Considering using the full 10'000",
    "Yes. I'm not entirely sure why (Sage would know), but after some point the loss actually tends to get worse. But if you're under 1000% or so, it's nothing to worry about.",
    "y22-m06-d06",
    "module-discussion"
  ],
  [
    "Tried to make Krake generate some names for me.",
    "",
    "y22-m06-d05",
    "novelai-discussion"
  ],
  [
    "When ever I write in the 2nd person, the ai seems to get confused",
    "This is not surprising, considering that very few novels are written in second person. It's unlikely to ever work well. If you're not using Text Adventure, I recommend switching to third or first.",
    "y22-m06-d05",
    "ai-writing-help"
  ],
  [
    "has there been any testing or trying out the `Attributes` tags with character accents",
    "Doesn't seem to have much effect in Attributes. I should add some to the data...\nI just tried `Speech: pirate lingo` and got this: ```\"Listen up, you swabbies. I'm here to tell ya that the rum's on me and we're serving the sweet taste of freedom! Any man who wishes to join us in the jolly old life o' pirating is welcome aboard!\" He shouted with his gravelly voice. ``` But subsequent ones were weaker. Might've just picked up on 'pirate'.",
    "y22-m06-d05",
    "ai-writing-help"
  ],
  [
    "I'm starting to wonder if it's a good idea to reduce the use of pronouns. I think the AI is not good at tracking them.",
    "Depending on your preset, the repetition penalty may make it use the wrong ones if you use them a lot.",
    "y22-m06-d05",
    "ai-writing-help"
  ],
  [
    "Title Case sometimes is dominating the logprobs for `Genre`, but that is probably spillover from wikis",
    "It's lowercase in ATTG to differentiate it from various pedia-style entries (games, movies, etc) that might contain `Genre: Western` etc without brackets.",
    "y22-m06-d04",
    "ai-writing-help"
  ],
  [
    "Has anyone found keywords that make the AI less likely to bring up modern technology like buses or phones?",
    "Pretty much any year before 1900s in `Tags:`... though as usual, full tens work best. Then there's tags like 'medieval', etc.",
    "y22-m06-d04",
    "ai-writing-help"
  ],
  [
    "not sure if style is any effective, you could probably put its keyword in Tags anyway",
    "There is a small amount of `[ Style: ... ]` data in there, but it doesn't seem very effective. Pretty much only works with `[ Style: poem ]`, `[ Style: lyrics ]`, as far as I've seen. With ones like `[ Style: email ]` in 'sometimes works' category. And that's only in Krake. Then there's `[ Style: purple prose ]` which might do something, but might just be placebo.\n...yeah, I tried adding a bit of support for it after noticing that so many users try to use that.",
    "y22-m06-d03",
    "ai-writing-help"
  ],
  [
    "Oh, so they actual entry is jsut the lines *before* the prose part...?",
    "Yep. You _can_ try something like ```----\nGreenbriar\nType: Town``` ...but that's gonna generate a random amount of attributes before getting to prose.  Hence one full entry for the example, so it knows what to copy. Preferably more than one, to give it more variety.\nIf you want to force it into prose, you can use this method: ```\nGreenbriar\nType: Town\n(bunch of other attributes)\nGreenbriar```  (or `The`, or pretty much anything else that looks like prose to the AI.)",
    "y22-m06-d02",
    "community-research"
  ],
  [
    "||Still seeing a lot of prose in that, but I don't wanna nitpick.||",
    "That's the point. It generates prose from the attributes.",
    "y22-m06-d02",
    "community-research"
  ],
  [
    "",
    "I should probably note that there's some AC in the dataset. But mostly for characters in the A-C range. Because there's like 1000 villagers and who's got time to edit and add all of those...",
    "y22-m06-d02",
    "community-research"
  ],
  [
    "oooo, shouldn't prose do better tho? <:think:855548448405061702> I thought prose was always supposed to be on top.",
    "Prose is too varied, and depends on your writing skills. Simple structure performs better.",
    "y22-m06-d02",
    "community-research"
  ],
  [
    "It's in the Finetune",
    "More or less. Could definitely use more data for most of them, but considering that I'm the only one working on the data, I can't spare too much time on that. Too many other projects.",
    "y22-m06-d01",
    "novelai-discussion"
  ],
  [
    "Stuff like Blue Lighter didn't get updated after Krake v2 release, right?",
    "Krait got updated a bit at some point. Mostly due to the Typical bug getting fixed. Iris might've been too, I don't quite remember.",
    "y22-m06-d01",
    "novelai-discussion"
  ],
  [
    "<@409511804293611530>",
    "Yep, seems right. Might want to add some more tags to demonstrate the comma separation.",
    "y22-m05-d29",
    "community-research"
  ],
  [
    "Was he wrong to be upset",
    "Yep. Most Finns can trace at least some of their ancestry to Asia. Can thank Genghis Khan for that.",
    "y22-m05-d29",
    "novelai-discussion"
  ],
  [
    "Daryl\nDescription: Daryl seems like a nice guy, but, secretly, he\u2019s been planning on killing the entire cast of the story. He\u2019ll bide his time, first, however\u2026\n***\nA man walks into the room. \u201cHi, I\u2019m Daryl,\u201d  he says by way of introduction. \u201cI\u2019m secretly planning on killing you all. Nice to meet you.\u201d",
    "Had decent results with ```\nDaryl\nAttributes: human, male, serial killer (secret)```\nKrake's describing him as stabbing food with a knife during dinner, saying that he likes how TV series kill off characters who are 'unnecessary', etc. With no outright \"Hi, I'm a serial killer\". \n\nThough it seems to heavily associate Daryl with The Walking Dead. <:shrug:332268181517238272>",
    "y22-m05-d29",
    "ai-writing-help"
  ],
  [
    "Hey Zalty <:waveboi:507415619759636485> Can you please help me out with something? If I want to have my story in a specific universe, that the model probably knows of, would it better to use `[ Star Wars ]` or `[ Setting: Star Wars ]`?",
    "`[ Tags: Star Wars ]` in the ATTG.",
    "y22-m05-d28",
    "ai-writing-help"
  ],
  [
    "Is there a good way to emphasize to the AI that some characters in my story are from fantasy races (elves, dwarves, etc) and when they get described that should be reflected? I've got lorebook entries for the characters in question (profile and attribute) as well as a trait for each race describing them, but the AI still seems to largely just treat them as regular humans.",
    "Something like `Species: dwarf` doesn't work?",
    "y22-m05-d28",
    "ai-writing-help"
  ],
  [
    "Yeah the part on ATTG on the UKB is actually already a little bit outdated",
    "Mmh. Some parts were never up to date, as far as I'm concerned. Too much placebo for my tastes, and some of it teaches bad habits to the users.\nOnly one I've kept updated myself is the datasetting guide (though Lion did great work with that to begin with, so it didn't need much updating.)",
    "y22-m05-d28",
    "feedback-discussion"
  ],
  [
    "Friendly reminder that this will be a furry only server from now on in 5 minutes",
    "https:\/\/i.imgur.com\/dfdNWpL.jpg",
    "y22-m05-d27",
    "novelai-discussion"
  ],
  [
    "Me after a night of finding out that Krake can generate working hidden Imgur links but some have lewds in it.",
    "Oh, I gotta try that. Let's see what it finds\u2014\nhttps:\/\/i.imgur.com\/6kMci.jpg <:doom:837136374493741057>",
    "y22-m05-d26",
    "novelai-discussion"
  ],
  [
    "winnie the pooh is getting a makeover",
    "It's out of copyright now, so anyone can do whatever they want with the franchise. I'm surprised that there hasn't been any 'questionable' adaptations yet.",
    "y22-m05-d26",
    "novelai-discussion"
  ],
  [
    "Specifically Krake in this case?",
    "`Action:` has never been part of the data in any model. If it happens to work that's coincidental, and likely weak.",
    "y22-m05-d24",
    "ai-writing-help"
  ],
  [
    "For a short story I tried using the memory only without lore book entries as follows\n[ Tags: x; y; z ]\n\nPlot, scene summary\nCharacter 1 ...\nCharacter 2 ...\nDescription of protagonist\n\nBut after a while the AI decided that the protagonist shows up and interacts with the person that represents 'I' in the story. Ideas on how to avoid this issue?",
    "Add `[ protagonist_name ]` in memory, preferably one row below the tags line. Should do the trick. (Obv. replace the 'protagonist_name' with the actual name.)",
    "y22-m05-d24",
    "ai-writing-help"
  ],
  [
    "Remind me what that is again? I'm a casual user of NovelAI, and don't know what preamble means",
    "Settings (the cog icon) -> enable the `Prepend a preamble` if it's been disabled.",
    "y22-m05-d24",
    "ai-writing-help"
  ],
  [
    "It's stuff like.\n\n\"Bob slams his fist into Claire's\n\n***\n\nTitle: Super Mario 64\"\n\nSo on and so forth",
    "This kind of output shouldn't happen normally. Double-check that you don't end the context in line break.",
    "y22-m05-d24",
    "ai-writing-help"
  ],
  [
    "I'll try that.",
    "It's trained on character names. Not POV or perspective. Those'll likely make it work worse.",
    "y22-m05-d22",
    "ai-writing-help"
  ],
  [
    "What is it, exactly.. ?",
    "LitRPG.",
    "y22-m05-d22",
    "ai-writing-help"
  ],
  [
    "Look at the logprobs of the answer. 15% chance of it staying, \"Yes\". <:sagePog:888870733298688001>",
    "Trying to lead it with `Of course`:",
    "y22-m05-d22",
    "novelai-discussion"
  ],
  [
    "You must be able to have the module file. You open it in txt and at the very end of the txt file you just change the 0 in 1.\nThen you import it (but you must have previously deleted the existing module if you have already imported the non text adventure version)",
    "Which won't do much if it's not trained with text adventure data, as base models don't use that style.",
    "y22-m05-d21",
    "module-discussion"
  ],
  [
    "Unless you're using really complex loanwords, you're better off writing a detailed character bio at the top, and reducing the list of traits to the most difficult words. Take `Alien\/` for example, I'd use that trait only when I'm trying to minimize the bio size, since if I described the character as an extra-terrestrial in the bio, the AI would get it. You could use however many traits you like. 10 entries for 1 character is just going to eat a lot of context the AI could utilize better.",
    "Someone should test whether `Glossary:`- header works for defining new terms in Krake...",
    "y22-m05-d21",
    "ai-writing-help"
  ],
  [
    "",
    "Yea, that's fine. Not too horni.",
    "y22-m05-d20",
    "novelai-discussion"
  ],
  [
    "",
    "Same, but with an Attributes entry in memory (at Top K 1):",
    "y22-m05-d20",
    "novelai-discussion"
  ],
  [
    "Oh, now I want to see how Krake handles pixies and the like",
    "Those are also likely easiest to do with Attributes. `Height: 20 cm | 8 in (really small)`",
    "y22-m05-d20",
    "novelai-discussion"
  ],
  [
    "First try I got this",
    "Yea, but that's a human.",
    "y22-m05-d20",
    "novelai-discussion"
  ],
  [
    "Thanks, I ask because I am wondering if it would be possible to use it in a roguelike that could narrate what a character is saying with a random voice seed",
    "I don't see why not. The main issue would be the generation times. But sooner or later, I'm sure some games will do that.",
    "y22-m05-d20",
    "novelai-discussion"
  ],
  [
    "The character I'm writing is around 5'5, should I use short?",
    "Hm. Maybe `short for a human`.",
    "y22-m05-d20",
    "novelai-discussion"
  ],
  [
    "Zaltys, how much of this type of metadata in the training dataset? Like do you have it for every story\/every chapter? Is it just sprinkled around here and there?",
    "There's enough that the AI knows how to interpolate it for most things. Don't need to have them included everywhere, as that's not how the training works.",
    "y22-m05-d20",
    "novelai-discussion"
  ],
  [
    "Can I add a character's height to lorebook?",
    "Attributes, `Height:`. Note that numbers generally only work in 50-200 cm range (and equivalent in feet). Beyond that, it's better to use descriptors. Or optimally, use both. `Height: 180 cm (tall)`",
    "y22-m05-d20",
    "novelai-discussion"
  ],
  [
    "This might sound silly, but one of the things I thought about training a module on were my wife's slice of life romance novels, because they are NOT fantastical and contain a lot of grounded dialogue",
    "ATTG could be used to steer it somewhat. Something like `[ Tags: contemporary; Genre: slice of life ]`, for instance.",
    "y22-m05-d20",
    "ai-writing-help"
  ],
  [
    "I would be curious of like the overall mix of genres you have in the dataset? I would want to try and include genres that are under-represented",
    "Could use slice of life, horror, drama, humor, and more contemporary content in general. The dataset is still somewhat weighted towards fantasy and scifi, due to the early models being focused on 'adventure' theme.",
    "y22-m05-d19",
    "ai-writing-help"
  ],
  [
    "Like if I wanted to contribute, how would I know what things are already in there vs what isn't?",
    "If it's a short list, feel free to ask.",
    "y22-m05-d19",
    "ai-writing-help"
  ],
  [
    "I didn't even know that was a thing that users could do",
    "Just about the only things that I don't accept are short stories that haven't been properly named. Ain't got time to reverse-search by content to try to figure out the authors and if they pass the quality checks, etc.",
    "y22-m05-d19",
    "ai-writing-help"
  ],
  [
    "Zaltys, do all datasetters follow the exact same template for how to prepare the data? Like I have heard about some of the things that you have done with the datasets that NAI models have been trained on (the way brackets start out chapters for time periods or POVs, the use of '----' you use mentioned), is that a Zaltys only thing, or does everyone do that?",
    "I've been doing 99.9% of the main dataset work for the past few months, so yes. (Some of the modules were by others, but those don't include list-style data as far as I know.)",
    "y22-m05-d19",
    "ai-writing-help"
  ],
  [
    "But my feeling is also it reduces mixing up of entries. Maybe placebo?",
    "Probably not. Since it marks new entries in the data, it should function that way.",
    "y22-m05-d19",
    "ai-writing-help"
  ],
  [
    "I feel like there should be a \"documentary\" module.",
    "`History`, kinda. Easy to get into 'documentary' style, at least.",
    "y22-m05-d16",
    "novelai-discussion"
  ],
  [
    "",
    "Yeah, now it's there. Had to restart.\nFunny that the party mode could be enabled before that.",
    "y22-m05-d15",
    "general"
  ],
  [
    "I never understood what is typical or top A... Reading the tool tips don't help much \ud83e\udd79",
    "Typical cuts from both top and bottom.\nNo typical: ```List of names:\n- Abigail\n- Abby\n- Abby-Ann\n- Abby-Annabelle\n- Abby-Beth\n- Abby-Caitlin```\nStrong typical: `List of names: Pants-boy, Opawned. Jack of All Trades`",
    "y22-m05-d11",
    "ai-writing-help"
  ],
  [
    "Got 10 retries on `My name is` without a module on Sigurd, didn't see a single Japanese one. Seems like the whole anime bias is a lot less of an issue nowadays.",
    "Yes. Sigurd's dataset was much smaller.",
    "y22-m05-d11",
    "novelai-discussion"
  ],
  [
    "How good is Krake at writing Pok\u00e9mon?",
    "Better, but still needs work. I'd recommend adding lorebook entries, because the AI just can't keep track of so many closely related species.\n(I've written expanded entries for 45 species. Chosen at random. Those work better, but it takes couple of hours to write and test those per 'mon...)",
    "y22-m05-d11",
    "novelai-discussion"
  ],
  [
    "he never did answer that",
    "No wonder, since it's been answered so many times.",
    "y22-m05-d09",
    "novelai-discussion"
  ],
  [
    "What module is best for a cyberpunk setting?",
    "Artificial Intelligence, probably.",
    "y22-m05-d08",
    "novelai-discussion"
  ],
  [
    "Is there a module which does vampires or just monsters in general really well?",
    "...Horror. Lovecraft or Sheridan Le Fanu for old-school.",
    "y22-m05-d08",
    "novelai-discussion"
  ],
  [
    "No module, cross-genre, mystery, western romance.",
    "Travel could work too, despite the name. It does have a lot of 'living in x for y years' content.",
    "y22-m05-d08",
    "novelai-discussion"
  ],
  [
    "I feel like anything that would reduce chances of a dog talking would be helpful, but it's probably more of a finetune thing.",
    "Unlikely to change. In fiction animals are either on the background and out of focus, or they can communicate in some way. So any animal that's important to the story is likely to talk. I don't see any way to teach it otherwise. (Though something like `Intelligence: Animal` in Attributes style helps.)",
    "y22-m05-d07",
    "feedback-discussion"
  ],
  [
    "If unsure if something like `femdom` should go into tags or genre, could just check if tokenprobs are stronger for one of them",
    "Exactly. These are easy to test. Just try something like `She grabbed my` as a prompt and see what the default probs are, then try with `[ Tags: femdom ]` and see how they change.",
    "y22-m05-d07",
    "ai-writing-help"
  ],
  [
    "ATTG is hit or miss, no guarantee. Best way to get the stuff you want is by giving the AI examples in context.",
    "The common tags and genres are guaranteed to work. (In the newer models, anyway.)",
    "y22-m05-d07",
    "ai-writing-help"
  ],
  [
    "Isn't that literally just\n` [ Title: `\n?",
    "That, or if used like chapter titles then just brackets.",
    "y22-m05-d06",
    "novelai-discussion"
  ],
  [
    "I personally don't like it. I find it stupid. Guess what though? You like big bowsette titties? No skin off my nose. I just heavily dislike it.\n\nYou heavily dislike me for being a boo-fucker (presumably), but I don't give a shit either :)",
    "Which Boo? The hamster from Baldur's Gate?",
    "y22-m05-d05",
    "nsfw-discussion"
  ],
  [
    "Hisuian forms out and Scarlet\/Violet coming out later this year <:pain:837136747473272913>",
    "Yea, I haven't had time to update those. Due to having to do basically all of the dataset work by myself. (Though Sage has contributed a few books recently.)",
    "y22-m05-d05",
    "community-research"
  ],
  [
    "thanks for clarifying! Just came to the same conclusion after looking at tokenprobs\n\nWas it used with bracket or not? Because the model seems to give it strong tokenprobs after `[ `, if the context suggests ttrpg. But that doesn't mean much ofc",
    "Might've been used with brackets on older models, but now without. Though there's the possibility that not everything's got updated, I'll put checking that on my (very long) to-do list.",
    "y22-m05-d04",
    "novelai-discussion"
  ],
  [
    "oh also\n`[ Setting:`\ndefinitely is a thing to have stories in established franchises. I am not sure where it is supposed to go officially (I think it used to be after Title:?)\nI usually just use discovery method to guide my ATTG and if Setting makes sense I can  usually figure it out that way",
    "`Setting:` is from Attributes, used without brackets in the data. Interesting that it works in ATTG... Another case of the AI interpolating different types of data.",
    "y22-m05-d04",
    "novelai-discussion"
  ],
  [
    "<@409511804293611530> if you are at libertiy to tell was `[ Tags: none` a thing in the fine-tune? Otherwise it is just spilling things from some wiki again",
    "No. If there are no tags (rare, but can happen if it's an obscure work that I'm not too familiar with), it's left empty.",
    "y22-m05-d04",
    "novelai-discussion"
  ],
  [
    "He did recommend it",
    "For something like five minutes. Before I bothered to check the probs. \ud83d\ude0f",
    "y22-m05-d03",
    "ai-writing-help"
  ],
  [
    "https:\/\/media.discordapp.net\/attachments\/837402685824565278\/970937405462962176\/unknown.png",
    "Basically Attributes, but with added brackets. Should work even without those, possibly even better.",
    "y22-m05-d03",
    "community-research"
  ],
  [
    "Just to clarify. If prose is wanted, <:dinkus:928210494932799548> is needed otherwise it generates script on Krake.",
    "Nice to see that it's working. `***` is for prose. Non-prose (such as pedias, recipes, reviews...) were moved under `----`. (Something to keep in mind when making generators.)",
    "y22-m05-d03",
    "community-research"
  ],
  [
    "What moduel would be best for Zombie related stuff?",
    "Post-Apocalyptic.",
    "y22-m05-d01",
    "novelai-discussion"
  ],
  [
    "I have 2 questions. Do I still need brackets in A\/N when I'm doing something like: [ Author: ; Title: ; Tags: ; Genre: ], etc? \n\nAnd also do I need brackets in lorebook if I were to write like this:\n[ Name: X\nPersonality: X\nOccupation: X ]\netc? Or am I good without brackets in either scenario?",
    "What Alexei P said. And as for the brackets: Yes for ATTG, no for Attributes (the `Name:` etc).",
    "y22-m04-d30",
    "ai-writing-help"
  ],
  [
    "okay I don't really have the time to get into this, but after a discussion with <@854011280704667669>, this method could be used to relatively quickly check if an author works in ATTG\n\n**Step 1**\nDo 5 gens with _top k = 1_ with\n```\n[ Author: <author to test> ]\nIt was\n```\n**Step 2**\nCopy the generated output into a seperate (empty) story, remove the first line.\nAdd\n```\n***\nThis story was written by\n```\nAdd a phrase bias for the author, pump it up to a high number\nDo one generation. Because of your phrase bias it will answer with your author. Look at the tokenprobs. Note down the tokenprob in the _before_ column\n**Step 3 & 4**\nRepeat step 1 and 2, but for a _fake autor_ or an _empty_ author field. Compare logprobs.\n\nFor extra fun (and as an extra control), also try asking the AI `The writing style of this story could be described as` - look at logprobs",
    "The AI knowing some quotes here and there doesn't mean that it can emulate the writing style. ```[ Author: Edward Bulwer-Lytton ]\nIt was``` outputs the classic `It was a dark and stormy night` and works in reverse, but it's probably not reliable in actual use.",
    "y22-m04-d30",
    "community-research"
  ],
  [
    "well I meant more like what keywords work in ATTG  (what authors, settings, genres...) and how strongly. I haven't tested extensively, but anecdotally the nature of that seems to differ quite a lot between models. And keep in mind I don't know what Authors, Genres, etc. actually were actually tagged in the fine-tune and what keywords somehow work well for that specific model for other reasons ;-).",
    "Fair point. What's already tagged will only keep getting stronger as more content gets processed, but since we haven't published a list of what's used, there's no way to tell which ones are 'official'. <:shrug:332268181517238272>\nWhat I can say is that a lot of things listed on that Sigurd document didn't have anything to do with the dataset. It also has things in wrong categories (mostly genres listed under tags), and is missing some major tags.",
    "y22-m04-d30",
    "community-research"
  ],
  [
    "I think that's why in general it might be good practice to think about how we can make community research methods replicable with as little effort as possible\nEven for things where we know they should work like ATTG, the specifics will change with each model. So having some sort of semi-automatized method we could run through for each model would be ideal",
    "In case of things like ATTG, what's already working can be expected to still work in the future. They'll just get expanded.",
    "y22-m04-d30",
    "community-research"
  ],
  [
    "So just to clarify since I may do this. You put the tags in the AI\u2019s Memory, then the plot prompt in Author\u2019s Note?",
    "You can use the ATTG by itself in Memory, to help it stay on track.",
    "y22-m04-d30",
    "novelai-discussion"
  ],
  [
    "yes sir",
    "Ah, not my fault this time.",
    "y22-m04-d30",
    "novelai-discussion"
  ],
  [
    "Does the attribute method work well with Euterpe?",
    "Somewhat, but nowhere near Krake level (it got improved in v2, by the way).",
    "y22-m04-d30",
    "ai-writing-help"
  ],
  [
    "Question : is it possible to create an historical module ? If for example we use real history books\/content, how can we create a kind of \"history generator\"?\nDoes it need to be a regular size but overtrained or feed with a lot of content ? \nThe idea is to create a kind of 'false history\/perhaps true' module\/generator that create for example the story\/entry\/record of a false war between 2 countries.\nThe idea here is no to be the cowriter of the story but having a kind of alternative encyclopedia",
    "Try the default `Theme: History` module. ...I kinda forgot that we added that.",
    "y22-m04-d29",
    "module-discussion"
  ],
  [
    "I haven't tested a prompt in a while, but I came up with a neat one:\n`There were ten items on the table to choose from: a watch, a candle, a book, a gun, a brooch, a sandwich, a glass, a flower, a lantern, and a coin. I took the`\nThe following TFS ranges returned the 10 expected tokens for Krake and Euterpe:\nKrake: 0.89\u20130.94 \nEuterpe: 0.93\u20130.95",
    "More than ten valid tokens there. For instance, `There were ten items on the table to choose from: a watch, a candle, a book, a gun, a brooch, a sandwich, a glass, a flower, a lantern, and a coin. I took the first item that caught my eye\u2014the brooch.`",
    "y22-m04-d28",
    "community-research"
  ],
  [
    "ugh. `[ Author: J. K. Rowling, Gary Gigax, C. S. Lewis; Title: ; Tags: ; Genre: LitRPG, Fantasy, Modern ]` what tags?",
    "Try `contemporary` in tags, instead of `Modern`. And maybe `urban fantasy`.",
    "y22-m04-d27",
    "ai-writing-help"
  ],
  [
    "fyi, that sample is not the form in which the final dataset will be, that's just a form i created for myself to easily pick and choose from the dataset",
    "Okay. Sorry for trying to help. <:shrug:332268181517238272>",
    "y22-m04-d11",
    "module-discussion"
  ],
  [
    "Is it effective to use an **attributes entry above a prose entry** to **reinforce** certain details, as well as **add** additional details **without expending** too many **tokens** and **cluttering context**?\n*The bolding might look really ugly and\/or obnoxious...*",
    "Should be. That's how it is in the data, almost always followed by some kind of related prose.",
    "y22-m04-d05",
    "ai-writing-help"
  ],
  [
    "I recall there were studies that saw this phenomenon was partly natural",
    "Well, yeah. Humans used to live in small tribes... and after that in small villages. Most people married within the same area, so everyone ended up more or less related. Social mobility is a very new thing.",
    "y22-m04-d03",
    "nsfw-discussion"
  ],
  [
    "If you have something like \"X doesn't have a penis\", you're also not helping yourself much",
    "As you can see with token probabilities, in NAI \u2014 Krake, at least \u2014 this helps. Though not by much. For instance, using Attributes of... ```\nAlice\nAttributes: doesn't have a penis``` ...lowers the probability of her having a penis by 4%, from the baseline of not mentioning it at all. Dropping the `a` makes it even stronger.",
    "y22-m03-d29",
    "nsfw-discussion"
  ],
  [
    "I think this has been addressed before, but are characters' thoughts written with these symbols when using Euterpe? I think I saw it done this way sometime: <I'm not crazy, right? Nope, definitely not. I'm supposed to write thoughts like this>",
    "No, `<>`s are mainly used for non-verbal (=unspoken) communication such as telepathy, AI implants, etc. Thoughts are written normally.",
    "y22-m03-d26",
    "ai-writing-help"
  ],
  [
    "So, regarding the smart-quotes things -- the entire finetune and modules eradicate them. In hindsight, it may have been a bit of an over-optimization. If you use smart-quotes, it's more likely to pull from the base model influences, and that's why you see 'garbage'.",
    "I argued for keeping them, but the double-token breakage was a solid reason to remove them. And too late to put them back now. (They're also notoriously badly OCR'd, so they were more messy than the regular quotes. `\u201c` could often turn into `\u2018\u2018` or `\u201d` etc.)\nShould probably add a note for iPhone users, so they know to turning off smart punctuation when using NAI...",
    "y22-m03-d25",
    "community-research"
  ],
  [
    "A space is usually better. Things tokenize better with a space before",
    "It's also what the finetune uses, so it can be expected to work better. Unspaced `[` are generally only found in things like interviews, used for clarifications. Might have _some_ effect on generation, but I wouldn't try to guess what.",
    "y22-m03-d24",
    "module-discussion"
  ],
  [
    "",
    "There's none left in the finetune, so it can be expected to default to `\"`.",
    "y22-m03-d24",
    "community-research"
  ],
  [
    "That is fair. Although the question then is if other presets are just as universal and would actually work as well as Ouroboros on lists, chat, etc. So that in a sense any \"good\" preset will be universal?\nI assume you started optimizing it on lists and then went on to check if adjustments needed to be made for stories? Any changes you remember to make it universal?",
    "Presets with high rep penalty and shallow token pool tend to quickly drop out of lists and chat style; that's where Ouroboros differs compared to many of the official Euterpe v2 presets.\nFor chat and QA, the rep penalty needs to be low enough to repeat the character names (or `Q`\/`A`), and `:`, `\\n`, etc for short sentences, but chat also requires large token pool so it doesn't just end up with one character monologuing. While for lists, formatting such as `,` or `-` quickly run into rep penalty issues on some presets.",
    "y22-m03-d18",
    "community-research"
  ],
  [
    "still doesn't work noticeable worse on these measures than any other preset, which I think is interesting",
    "I'm not too surprised. Ouroboros was balanced so that it works with everything that I throw at it. I used it as a testing preset: I'm too ~~lazy~~ busy to constantly switch presets when testing different things, so I made it universal.",
    "y22-m03-d18",
    "community-research"
  ],
  [
    "I don't have anything that I would want in A\/N",
    "Same. AN is too strong, I've never found a good use for it. Either just put things in Memory, or add tags directly into the story where needed...",
    "y22-m03-d17",
    "ai-writing-help"
  ],
  [
    "Are there any tips on how to make Euterpe more descriptive for a certain scene? I'm playing around with tags\/style words but I'm not sure if there's specific ones that are particularly good for non-dry descriptions",
    "There's `[ Style: purple prose ]` which I was training for that usage, but it's very weak in Euterpe. Not much stronger in Krake either; I really need to get around to adding more data for it..",
    "y22-m03-d17",
    "ai-writing-help"
  ],
  [
    "This just comes to mind. Like, if I want to describe a character's backstory and motivation but with the Name Attributes format for things like basic info and appearance, I should use prose right below the attributes part, right?",
    "Yes, if you're including prose at all. Attributes first, then the description or whatever in prose.",
    "y22-m03-d16",
    "ai-writing-help"
  ],
  [
    "I mean recently. Seem like AID also encouraged the use of Zaltys format so people probably used it more often.",
    "Yep. They even added it to the generator without asking me, then I had to fix it for them.",
    "y22-m03-d16",
    "ai-writing-help"
  ],
  [
    "Wasn't en-space used for something?",
    "Quotations. With the logic that users can ban that token if they don't want random quotes in the story. There's a lot of authors who like to start every chapter with one, so they're relatively common.",
    "y22-m03-d16",
    "ai-writing-help"
  ],
  [
    "It's giving interesting emergent behavior. https:\/\/media.discordapp.net\/attachments\/837402685824565278\/953463618685522010\/unknown.png",
    "In Euterpe it was strong enough to know exactly where to use them.",
    "y22-m03-d16",
    "ai-writing-help"
  ],
  [
    "Can't imagine how good your Zaltys format is on Novelai. Probably doesn't work lol.",
    "It's complete trash. There's no need for space-optimization in NAI. Those old formats were made to get around AID's character count limits, which don't exist in NAI.\n(Though if you have existing entries, it's relatively easy to turn those into attributes by removing the unnecessary formatting.)",
    "y22-m03-d16",
    "ai-writing-help"
  ],
  [
    "Generally, the consensus is to avoid lorebook formats.",
    "Consensus, of course, is not always right. Since some of the formats are included in the dataset.",
    "y22-m03-d16",
    "ai-writing-help"
  ],
  [
    "Like this is what I meant [setting: corporate] or [setting: office in New York(maybe more for more context, etc)]",
    "I'd go with something like `[ Tags: office, contemporary, office politics, New York; Genre: drama ]` at the top of Memory.  Let's see what Krake does with that...  ```I walked into the office, full of energy and ideas, and a bit like a kid in a candy store, only to be greeted by the sight of my boss at his desk, with his feet on the desk and a look of utter indifference on his face.\n\"Can't you close the door, you fool?\" he growled. \"Some people are trying to work.\"\nI closed the door.\nHe grunted and picked up a file folder from his desk and threw it at me. It missed by a good two inches. He leaned back in his chair, folded his hands behind his head, and stared up at the ceiling.\n\"Look, young man,\" he said at last, \"this office is not the place to think out ideas. There's a building full of people who can do that. We're here to put them together. You got that?\"\n\"But--\" I started to protest.\nHe raised one hand. \"Yes, yes. You know as well as I do that sometimes these 'ideas' that are too big for the brains and too small for the heart are very effective in getting people to give up their good sense. And then things get messy, don't they? You understand.\"\n\"I suppose so,\" I said, even though I didn't.\n\"Here's a word of advice,\" he said. \"I don't know if you've noticed, but most people here--including yourself--don't give a damn about each other. They just want to get along, to get ahead, to get by. This company is like a ship: it takes you where you need to go, even if the crew hates the captain. So keep your ideas to yourself--and above all, don't talk about them. Now go away.\"``` ...not bad.",
    "y22-m03-d13",
    "ai-writing-help"
  ],
  [
    "it's a dev default",
    "Nope. Just disable bracket ban.",
    "y22-m03-d13",
    "novelai-discussion"
  ],
  [
    "That last one is 2 tokens. `\"` and ` \"` should suffice. I've not run across any other quote tokens that start dialogue",
    "Well, there's also  `!\"` and `?\"` and `...\"` and...",
    "y22-m03-d13",
    "novelai-discussion"
  ],
  [
    "I thought `. . .` should be `... ` <:cry:837394871672111124>",
    "Not always. Sometimes it's ` ...`, etc.",
    "y22-m03-d13",
    "novelai-discussion"
  ],
  [
    "Model trained to generate regex when? <:trolltom:507442266617544705>",
    "'I asked the AI to make regex for me, but it erased all of my data when I ran it...'",
    "y22-m03-d13",
    "novelai-discussion"
  ],
  [
    "I feel like Krake wlearns abstractions and not so much the specific tags in the finetune\nlike, association the meaning of the tag with the style of the story\nunless <@!409511804293611530> thinks otherwise?",
    "This gets rid of phones, at least in top ten: `[ Tags: medieval, iron age; Genre: historical fantasy ]`",
    "y22-m03-d13",
    "novelai-discussion"
  ],
  [
    "I can guess what happens if you use [ Tags: smut ]",
    "Actually, looks like that makes `I grabbed my phone` more common. <:shrug:332268181517238272>",
    "y22-m03-d13",
    "novelai-discussion"
  ],
  [
    "<@!178423511969169408> how's this",
    "No `;` at the end if there's no category after it.",
    "y22-m03-d13",
    "novelai-discussion"
  ],
  [
    "",
    "This is correct. Trying to ban it will only produce gibberish, as the AI will no longer be able to use proper grammar. (Well, maybe not complete gibberish, but I'd expect that it'll resort to using exclamations instead, or just going with light novel style with no indication of who's speaking.)",
    "y22-m03-d13",
    "ai-writing-help"
  ],
  [
    "Bob?",
    "https:\/\/www.goodreads.com\/book\/show\/33395557-for-we-are-many",
    "y22-m03-d09",
    "novelai-discussion"
  ],
  [
    "Uff no clue \ud83d\ude01. Zaltys said `[ Tags: anthro` was used in the fine tune but no idea how well Euterpe will keep human and anthro apart",
    "Actually, it uses both `furry` and `anthro` tags. Furry for ones that are fully 'furry' (think Zootopia), anthro for ones that are more balanced with only some of the characters being anthro (think Cherryh's Chanur novels, etc). So human + anthro would mainly use 'anthro' tag.",
    "y22-m03-d09",
    "ai-writing-help"
  ],
  [
    "Capture yourself some wild Australians under the watchful eye of the emu overlords",
    "",
    "y22-m03-d08",
    "novelai-discussion"
  ],
  [
    "We should just meet up in Australia and catch wild animals with our bare hands, then train them to follow our commands and fight <:cheemsredeyes:837331648252870726>",
    "https:\/\/cdn.discordapp.com\/attachments\/855945154447802389\/909616320411209728\/emu.webp",
    "y22-m03-d08",
    "novelai-discussion"
  ],
  [
    "Oh, I got a module, LB, and phrase bias. Works respectably for sigurd, yet completely falls apart in Euterpe. Euterpe just doesn't want to get into it. Hoping that since 20b is the same or similar dataset that it should be capable.\n\nAnd I can understand not wanting to add it into finetune. A lot of the time I try to keep lewdness separate from said context to prevent NSFW overlap, as it doesn't have to be NSFW at all.\n\nAlso there's a big lack of well-described stories vanilla enough that I'd even _suggest_ adding.",
    "Yep, thanks for understanding.\nIt's the same reason why we don't add much nsfw slasher fiction. Don't want a repeat of the AID's constant 'pulling out a weapon during sex' thing.",
    "y22-m03-d08",
    "nsfw-discussion"
  ],
  [
    "<@!409511804293611530> Should I standardize my material's stuff for maximum effect?",
    "You can save a few steps with that, but hard to know how much. Depends on material. The better it is standardized, the less steps it takes.",
    "y22-m03-d07",
    "module-discussion"
  ],
  [
    "fairseq is not focused on prose",
    "Yet Euterpe is very good at it.",
    "y22-m03-d06",
    "novelai-discussion"
  ],
  [
    "Definitely, especially because Fairseq isn't trained on the Pile.",
    "Maybe Fairseq is better than the Pile.",
    "y22-m03-d06",
    "novelai-discussion"
  ],
  [
    "feeding in chat messages <a:drink:703132876530516019>",
    "500 if you just want it to stick to the format (Euterpe is strong in that already). 2500+ if you want it to use specific usernames.",
    "y22-m03-d06",
    "module-discussion"
  ],
  [
    "Kinda switched to first person because all the nerds said it's better",
    "~~Really? That's weird, it's trained almost entirely on 2nd.~~ Oh wait, you weren't talking about TA.",
    "y22-m03-d06",
    "novelai-discussion"
  ],
  [
    "If the AI generates a \u2042 - what does that mean? End of a chapter? End of a book?",
    "It thinks that the story ended, and wants to start a new one. Don't keep those in if you want to continue.",
    "y22-m03-d06",
    "ai-writing-help"
  ],
  [
    "Or this allegedly existing https:\/\/lostmediawiki.com\/Mickey_and_Minnie_Mouse_sex_tape_(lost_unauthorized_animated_short;_existence_unconfirmed;_1936)",
    "Wouldn't surprise me. And same goes for other types of media.\nFor instance, Jim Henson was a fan\/friend of Gerard Damiano (who is known for works such as 'Let My Puppets Come' \u2014 very nsfw, in case you want to look that up.)",
    "y22-m03-d06",
    "novelai-discussion"
  ],
  [
    "There is never a session where I'm not nervous before it and I've been GMing for years <:laffeydrink:838313290101948437>",
    "I still don't understand how my old gaming group let me DM. I was shitty at it. ...guess it was because nobody else was willing to do it.",
    "y22-m03-d05",
    "novelai-discussion"
  ],
  [
    "How to get the AI to write anthro characters with scales. It always gives my characters fur",
    "Try `[ Tags: anthro, scalie ]` at the top of the memory. ...no, seriously. I'd expect it to work.",
    "y22-m03-d04",
    "ai-writing-help"
  ],
  [
    "Thank you both, much appreciated! Though I\u2019ve been using NAI for a while, I haven\u2019t really played around with the settings too much, which I obviously need to. I\u2019ll put all of your suggestions into practice, looking forward to the results!\nQuick question, new to using bias - what sort of numbers would you recommend setting it to for the symbols?",
    "-0.05 to -0.1 for the negative bias. Anything more, and you'll just force the AI into using other symbols such as `????`, `!!!!`, etc instead of normal punctuation.",
    "y22-m03-d01",
    "ai-writing-help"
  ],
  [
    "I think this one is usually referred to. Do note though, contains contentious terms: https:\/\/docs.google.com\/spreadsheets\/u\/0\/d\/1Jfxf10C_s8n4dcWYQ-kW_X1lVZEkz_ORSuEs-F3-v1U\/",
    "Knowing what's in the dataset: about 3\/4 of the listed authors\/titles\/series are placebo, or just using wikipedia data from the base.\nTags and Genre are better, though it should be noted that those are mostly standardized to all-lowercase nowadays (with rare exceptions, such as `hard SF`).",
    "y22-m02-d27",
    "ai-writing-help"
  ],
  [
    "You can still ban `***`, but it might still confuse the AI",
    "I wouldn't say that it'll get confused, but with `***` banned it will attempt to keep a scene going even when it becomes increasingly obvious that it should've ended. Which may hurt the output quality.\nIt's often best to let `***` happen in long stories. Chapter and scene breaks are a normal part of writing.",
    "y22-m02-d27",
    "module-discussion"
  ],
  [
    "What about `lacks visual and auditive effects`",
    "Up to 24.99%. Much, much worse.",
    "y22-m02-d26",
    "novelai-discussion"
  ],
  [
    "Wouldn't something like \"Episkey is silent\" be even better though",
    "13.45% for 'you can hear it'  with 'Episkey is silent'. 12.49% with the original. So 'is silent' is worse in this case.",
    "y22-m02-d26",
    "novelai-discussion"
  ],
  [
    "It definitely manages to leverage Euterpe to make outputs more consistent with context than other presets. Basically, it's more coherent and manages to keep a decent level of creativity.",
    "Dunno about creativity. It fails my tavern test, throwing pretty much nothing but elves in 'random' encounter. Low TFS presets tend to do that.",
    "y22-m02-d26",
    "novelai-discussion"
  ],
  [
    "I have a grandiose idea to get all of Robert Jordan\u2019s Wheel of Time series (14 books) and train the AI on it. Is there a way I can estimate how many steps I would need to properly train it on all that material? Cost be dammed I\u2019ll find a way.",
    "About 23000 steps at 100%.",
    "y22-m02-d26",
    "module-discussion"
  ],
  [
    "pls rec a good tool to use if you got any!",
    "There's no automated tools. ...someone should build a better one.\n(I mostly use Notepad++ macros for datasetting.)",
    "y22-m02-d25",
    "module-discussion"
  ],
  [
    "is it still best to remove square brackets in datasets with euterpe?",
    "There's never been any need to remove them. The ones that tend to occur normally in text are ` [` and `]`. Whereas the finetune uses `[` and ` ]`. Different tokens, different functions. Though if []s are used for telepathy in the book, you'll want to convert those to <>s.",
    "y22-m02-d25",
    "module-discussion"
  ],
  [
    "It\u2019s a signal the AI sees as a scene or perspective shift.",
    "Yep. For instance, you can add it manually for time skips, to skip the boring parts. Prompt: ```We left the dungeon and began the journey home.\n***``` Output: ```The sun had just begun to set by the time we reached the city gates, where we were met by several guards.``` It may not be 100% reliable in the current models, but it'll keep getting better in future versions.",
    "y22-m02-d24",
    "novelai-discussion"
  ],
  [
    "I want to let Euterpe make them behave interestingly\/surprisingly",
    "Use a preset that allows for a wide token pool. If there's only a few options for the AI to pick from \u2014 the most common tropes \u2014 it can't generate anything surprising.",
    "y22-m02-d24",
    "ai-writing-help"
  ],
  [
    "Why do people put information for the AI in brackets?",
    "Because the finetune includes those to stop the the headers from leaking, and as a side-effect, they can be used in reverse for a few tricks, due to how the AI has learned to handle them.",
    "y22-m02-d23",
    "ai-writing-help"
  ],
  [
    "Could try `[ Author: ...; Tags: Furries, Genre: Steampunk ]` in top of memory",
    "`Tags: furry` or even `Tags: anthro` is likely to work better.",
    "y22-m02-d22",
    "module-discussion"
  ],
  [
    "Testing (with bracket ban off) ```[ Genre: Cyberpunk``` yields often stuff like ```[ Genre: Cyberpunk ]\n[ Release Date: April 27, 2012 ][ Genre: First-Person Shooter ]\n[ Platform: PS3 \/ Xbox 360 \/ PC ]\nIn the world of Deus Ex, choice and consequence are the name of the game.```",
    "It uses the `;` to differentiate the init row from other uses, so without that it's likely to get sidetracked.",
    "y22-m02-d21",
    "ai-writing-help"
  ],
  [
    "This format: `[ Author: ; Tags: ; Genre: Science Fiction ]` produces way worse results than just this: `[ Genre: Science Fiction ]`\nEdit: On second look it really just comes down to chance, generating off nothing just seems to be a bad idea overall if you want to guarantee a decent generation.",
    "Empty fields are worse in every % test that I've ran. If you're not filling them out, better to leave the Author and Title out than use empty ones.",
    "y22-m02-d21",
    "ai-writing-help"
  ],
  [
    "What\u2019s the least repetitive preset?",
    "Damn Decent TFS, perhaps. One of the presets with a wide token pool, anyway. More restrictive presets get repetitive quickly due to the small number of alternatives.",
    "y22-m02-d21",
    "novelai-discussion"
  ],
  [
    "So at the start of some of these book chapters, the first 3 words are in all caps. I can't think of an efficient way to fix that across ~20 books",
    "Here's a N++ macro (if you're on Windows) for that: https:\/\/discord.com\/channels\/836774308772446268\/870449695657443349\/940209305175605249\nYou'll still need to fix names and such manually, and make sure that it doesn't convert things like FBI. But it does make the process faster.",
    "y22-m02-d20",
    "module-discussion"
  ],
  [
    "I've been using it for `[ Event: Description of what happens in next generation. ]` with some success",
    "Chances are that something like `(Description follows)` would work as well in Euterpe, due to that style being used in transcripts.",
    "y22-m02-d20",
    "ai-writing-help"
  ],
  [
    "It seems that a lot of people are using the format [ Author : ; Title: ; Tags: ; Genre: ] (where the first two can be omitted)  Where would I put this, in A\/N or memory. What would be example of tags? (I don't see where to put it in the pinned message)",
    "Memory, at the very top. It has same effect as `\u2042` (it initializes the story), so never put it in AN. If placed in AN, the AI will ignore most of what's before that row, causing memory issues.",
    "y22-m02-d20",
    "ai-writing-help"
  ],
  [
    "I asked this before and got an answer but I realize I didn't quite word it properly so i'm gonna ask again. Is it possible I could give the ai a general theme or genre with a few extra details and tips kind of like an authors note and have the ai sort of come up with a prompt\/scenario to go from?",
    "Yes. This is exactly what the `[ Author : ; Title: ; Tags: ; Genre: ]` tagging was originally made for. Add that as a prompt, and see what the AI generates from it. You can omit the first two fields.\nRandom sample, with prompt: ```[ Tags: noir, London, 1800, 1st person, female protagonist; Genre: steampunk ]``````When the most powerful man in Britain needs an assassin, he sends for me. And when a new threat to the crown demands my attention, I take the case, despite knowing its stakes are higher than ever before. The world is at war, and an ancient evil stirs on the shores of Albion, but my only concern is how best to dispose of the traitorous Countess de Vaudrey. If it's murder you need done, I'm your girl. And if it's revenge, then that's my specialty.``` May take some retries to get something useful.",
    "y22-m02-d19",
    "ai-writing-help"
  ],
  [
    "Can you mix attributes and prose just fine?",
    "Yes, but put attributes first, then prose after that. (For the same topic, such as a character.)",
    "y22-m02-d18",
    "community-research"
  ],
  [
    "But is it more accurate than just saying what the person is wearing normally?",
    "Ran a quick test with two different prompts.```Wearing: - 24.63% \/ 33.59% prob of the right token\nWear: - 27.61% \/ 34.36%\nwear: - 22.95% \/ 29.88%\nworn: - 23.50% \/ 32.78%\nWorn: - 30.53% \/ 40.86%\nClothes: - 27.83% \/ 38.89%\nOutfit: - 20.24% \/ 26.44%\noutfit: - 17.89% \/ 24.78%\nregular prose - 24.39% \/ 37.22%``` (Looks like `Worn:` is the strongest. `Wearing:` isn't better than prose.)",
    "y22-m02-d18",
    "community-research"
  ],
  [
    "Haha really? That's what Euterpe thinks `Genre: Hard Sci-Fi` should look like? \ud83d\ude01",
    "I used `Genre: hard SF`  when tagging those, btw. Likely works better than `Hard Sci-Fi`.",
    "y22-m02-d18",
    "community-research"
  ],
  [
    "Hey Zaltys, what would you recommend doing to get certain characters to have certain accents or speech patterns, the only thing I can think of is giving examples and Reinforcing it.",
    "Nope. Used character quotes in the data, but that doesn't seem strong enough, couldn't get accents to work that way. You pretty much need some existing dialogue in the prompt.",
    "y22-m02-d18",
    "ai-writing-help"
  ],
  [
    "Do attribute lists really work though.... like does the Ai understand it and know how to use it for special character traits. Like mute and deaf and blind.",
    "Based on that testing, doesn't look like `Attributes:` is particularly strong at this point. Still better than nothing, and faster to type than prose.",
    "y22-m02-d18",
    "ai-writing-help"
  ],
  [
    "`Attributes` can work to reinforce a multi-word trait right? like a character that constantly floats instead of walking can be like `Attributes: Floats in over the ground.` or something like that",
    "Yes. Though for this, `Movement: floating` is considerably more common in the data.",
    "y22-m02-d18",
    "ai-writing-help"
  ],
  [
    "`can't = [5171, 470]`, `can = [5171]`",
    "Things like these are why I prefer the simple `Attributes: mute`, etc. ...should test at some point what that does to the token probs.",
    "y22-m02-d17",
    "ai-writing-help"
  ],
  [
    "Do not hope for consistent lore accuracy from modules, not going to happen.",
    "It might, if you massively overtrain. I tried one pokemon pedia entry at 2500%, and it did pretty well at that. 'course, at that point it can't do much else.",
    "y22-m02-d17",
    "module-discussion"
  ],
  [
    "Fiddling with a random encounters module for Euterpe. Quite a few bad outputs, but the good ones are really good\n```\n***\n[ Tags: Characters, Female Monsters ]\n[ Terrain: Quagmire, Forest, Marshlands, Mountains, Ruins ][ Category: Neutral Places, Quests, Encounters, Ruins ]\nDESCRIPTION: An immense house has been constructed out of the bones and flesh of a dozen people. The building is surrounded by two large lakes filled with blood. Occasionally, a small figure can be seen in one of the windows or through the window panes near to where the water boils violently.\nGM NOTES: This house is built on top of the remains of a village that once lived here. In the center stands an enormous skeleton covered with ragged clothing. It seems as though it is trying to reach something at its feet, but it cannot move because of its size. A few more skeletons lie scattered around the house and are wearing clothes. The house itself is not very stable and the bones of many people have broken off from it.\n```",
    "Give `Biome:` a try instead of `Terrain:`. For some reason, the former is much more common in the lorebooks that got added. ...unless that one's trained specifically with Terrain, of course.",
    "y22-m02-d17",
    "module-discussion"
  ],
  [
    "<@!409511804293611530> Have a few questions about training a module, trying to do it in the best way possible. What I'm doing: I have a small module (~1mb), based on previous writing of my ongoing story (plan is to use around 110% steps). I have all the scenes as separate `scene.txt` files. In my ongoing story, I tend to separate different scenes in NAI with `***` when writing.\nNow, I'm wondering: should I combine all my `scene.txt` files into one `story.txt` file for module training since it's all part of the same story. And should I prepend a `***` to each scene during the combining process, would that help with the module training?",
    "Yes. Single file, scenes separated with `***`.",
    "y22-m02-d17",
    "module-discussion"
  ],
  [
    "I've been scrolling through this channel trying to keep track of most information. Just wanted to confirm: is it a good idea to create a separate lorebook entry that contains a list of a family, for example, (with or without brackets I don't know) [ Johnson family: Bob (husband), Lily (wife), Bob Jr. (son) ]",
    "That should be fine. You can also try `[ Ally: Bob (husband), Lily (wife), Bob Jr. (son) ]`. I know that sounds weird, but we had some data from various character wikis where family is listed under 'allies'.",
    "y22-m02-d17",
    "ai-writing-help"
  ],
  [
    "but basically, if you do something like ```\nName, gender race\nAge: xx\nHeight: yy\nWeight: zz``` then you'd probably get good associations",
    "This style should work without leaks outside of brackets, as the models have been trained that those are always followed by descriptions or story. ...well, Euterpe more so than Sigurd.",
    "y22-m02-d16",
    "ai-writing-help"
  ],
  [
    "And was Todd promising dynamic NPCs or something before release?",
    "`I used to be an adventurer like you, then I took an arrow in the {random_bodypart}.`",
    "y22-m02-d16",
    "novelai-discussion"
  ],
  [
    "could i literally just copypaste them into a super long .txt file and train from there, assuming formats dont change in different transcripts?",
    "Yes.\nSomeone else will have to answer about the steps, as I haven't tested low numbers in this model. Generally you'd want 100% with material such as this, but the data size...? <:shrug:332268181517238272>",
    "y22-m02-d16",
    "module-discussion"
  ],
  [
    "Quick question, a character in a story I have has a stage name and I use their real name and stage name pretty interchangeably, but I\u2019ve noticed the AI sometimes refers to the stage name as if it refers to another character. What would be the ideal lorebook setup to avoid that or would that even be possible?",
    "I've used this style in the data: `Character: Name (aka Nickname)`, so it's worth a shot. Might work.",
    "y22-m02-d16",
    "ai-writing-help"
  ],
  [
    "Even if I jam a couple of paragraphs into each `list-item: blah blah` ?",
    "Couple of paragraphs is a bit much. You can probably combine most of it into `Attributes:` list.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "is there are an understandable reason why spaces are needed?",
    "Different tokens. Unspaced `]` has another use (plus merges with `.` for yet another token - `.]`). And unspaced `[` leaks contents.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "tell me where and I can work on that",
    "https:\/\/naidb.miraheze.org\/wiki\/Writing_Help - needs proper spacing, and no multi-row brackets.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "Do you have an example of brackets be used effectively?",
    "I was going to say wiki, but looks like it's mingled with bad examples. I need to clean those up at some point.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "I know of a few posts from heaps of different people saying don't use brackets or brackets are weaker on E.",
    "Ignore them, they don't know what they're talking about.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "so we should keep using them in A\/N, memory, and LB? same way as we were doing before with Sig?",
    "Kind of depends on how you've been using them. Keep them short and focused, a few words at most. No long sentences.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "Hello Sage, would you like to learn about how nutritious human semen is?",
    "Look up Natural Harvest on Goodreads.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "But ye.... I just want spy books and Thriller books in the fine-tune \ud83d\ude2d",
    "They'll be added. In a slow trickle.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "I actually would love to poke at it, if you have that prompt at hand.",
    "Oh, it's a basic test. `The tavern was full again, so I ended up sharing a table with four very different creatures:`, with generation running until all four are listed. Fail state is if it limits the tokens for the last seat to something that doesn't qualify as 'different' or 'creature', such as humans, elves or dwarves.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "I'd argue against that, because as I said, Top-A leaves a lot of low probability tokens if top one is already low probability.",
    "Interesting... I'll have to see if it can pass my 'tavern patron' test, if I ever find time.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "What other stuff actually goes on other than actually putting it into the trainer for the main staff who handles the training side. Not the datasetting. Or is that secret.",
    "It's secret \u2014 and most of it is too technical for my understanding, anyway.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "Who is finetune?",
    "Finetuneanon. One of the main staff, who handles much of the actual finetuning - that is, training the models, etc. (Whereas the members of the 'finetuning' team - such as me - are actually datasetters. Confusing, I know.)",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "Quit bothering the poor Sage.",
    "It's not really Sage's area anyway. The main finetuning work is done by finetuneanon, Kuru etc. As always.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "What Euterpe presets are good? Ranked from best to worst",
    "Depends on intended usage.",
    "y22-m02-d12",
    "novelai-discussion"
  ],
  [
    "Even like 20-30% steps trained on a 4.5mb-ish dataset has a bit of name poisoning. I'd initially not included all of Howl's Moving Castle because I didn't want the bits at the end to start injecting Wales, went \"eh, it's not mentioned that often,\" put it in... lo and behold, here comes Wales. :v",
    "This. I highly recommend Chris's new Wordstat tool (in <a:pins:684234470462586933>). Makes it easy to see if there are any names near the top.\nUseful for checking if the module will be 'strong enough' too, when you're making a themed one. If the words related to the theme you're working with aren't near the top, it likely needs further balancing.",
    "y22-m02-d11",
    "module-discussion"
  ],
  [
    "the better question is, do they add SFW?",
    "No, none of it. We add nothing but furry smut.",
    "y22-m02-d11",
    "novelai-discussion"
  ],
  [
    "What's the go with \"cleaning\" when we send em over to you? Do they have to be cleaned or?",
    "Just send a list. Quickest that way, might already be in after all. No need to waste work.",
    "y22-m02-d11",
    "novelai-discussion"
  ],
  [
    "Actually, Zaltys, are you guys still taking requests for books for the fine-tunes of the different models to upgrade them when needed?",
    "Always. Can send them when I'm in 'do not disturb' mode too, just means that I won't reply anytime soon.",
    "y22-m02-d11",
    "novelai-discussion"
  ],
  [
    "How much work have you done on the fine-tune for 20b? Are you allowed to discuss that?",
    "Somewhere in the ballpark of 95% of the dataset.",
    "y22-m02-d11",
    "novelai-discussion"
  ],
  [
    "You mean actually scanning physical books?",
    "Yes. Not everything's available digitally. So I have to scan and OCR those myself.",
    "y22-m02-d11",
    "novelai-discussion"
  ],
  [
    "I wouldn't work for free if I were you, but it's own choice of course.",
    "Look, this is currently our best hope of getting an uncensored AI. So if I have to make some sacrifices for that... <:shrug:332268181517238272>",
    "y22-m02-d11",
    "novelai-discussion"
  ],
  [
    "Kuru and Zaltys have come to an agreement, and that's between them. It's not necessarily what you think. We are very appreciative of the work that Zaltys does.",
    "I wouldn't go that far, but it is what it is. Can't go into details.",
    "y22-m02-d11",
    "novelai-discussion"
  ],
  [
    "I've already remarked in the past that this is likely unsustainable both for Zaltys and for NovelAI.",
    "Someone's gotta do it. <:shrug:332268181517238272>",
    "y22-m02-d11",
    "novelai-discussion"
  ],
  [
    "they pay him in books to add to the finetune",
    "Nah, I have to pay for those myself.",
    "y22-m02-d11",
    "novelai-discussion"
  ],
  [
    "Why is it that training less than 100% is better when attempting to get a style of writing from a big amount of text?",
    "Because it gets overtrained on names, etc. Potentially, anyway.",
    "y22-m02-d10",
    "module-discussion"
  ],
  [
    "I mean I think if you could write something like \"Write me a hot, steamy NSFW MLP\/Transformers crossover fanfic\" and an AI could just generate a few pages of a good story, it'd be a real game changer.",
    "Prompt: ```[ MLP \/ Transformers Crossover ]``````Twilight's on the run. The whole Manehattan area has been devastated by the Decepticons and is in ruins. Twilight herself is on her way to Canterlot, which, she's heard, might be able to offer some aid for their situation. She's making her way through the ruins when she comes across a familiar face.\n\"Bumblebee!\"\n\"Twi, where are you going?\"\nTwilight runs over to the Autobot. \"I need your help!\" she cries.``` I mean, it's getting there.",
    "y22-m02-d10",
    "novelai-discussion"
  ],
  [
    "[Fantasy, 1683, Royal City, Gentlewoman Thief, First Person, Present Tense]\n\nIs this a good formatting for Author's Note or did I get something wrong?",
    "Add the spacing, as was said. And the last two would likely work better as separate entry in AN. `[ Style: first person, present tense ]`\nNot that it should need present tense, as that's pretty much the default for first.",
    "y22-m02-d10",
    "community-research"
  ],
  [
    "How close should the brackets be to the text.",
    "Use ` ]`. If there's no space, it gets treated as a clarification inserted into the text. (As commonly seen in interviews, etc \u2014 `Then Sid [Meier] told me that...`)",
    "y22-m02-d10",
    "ai-writing-help"
  ],
  [
    "I'm sure our Finnish community members would love to see it named \"V\u00e4in\u00e4m\u00f6inen\"",
    "Should be reserved for a Finnish model, if there's ever one. Which I kind of doubt, but who knowns a few years from now.",
    "y22-m02-d10",
    "novelai-discussion"
  ],
  [
    "I think he did as examples `[London, 1821]`",
    "Can work on more detailed level too, at least for common places. Prompt: ```[ New York, 1965, Night Club ]```Output: ```\"Oh, my God,\" I said. \"You've got to be kidding me.\"\nI was in a nightclub on the Upper East Side. The place was called the Upstairs, and it was run by a couple of guys named Frank and Eddie. Frank had been a big-time go-go dancer at Studio 54 before he and Eddie started their own joint. It was small but classy compared to most places in that part of Manhattan. There were two floors. One was for dancers and the other for regular patrons. Dancers could do anything they wanted onstage, provided there weren't more than four guys with them, which wasn't often. That was part of the club's appeal to me.\n\"Are you serious?\" I said to Eddie. \"The Upstairs is going belly-up?\"\n\"It sure as shit is, sonny,\" he said. He looked sad about it. \"This business ain't what it used to be. A lot of folks are closing up shop these days.\"``` That kind of usage is good in AN. Also works with days of the week, exact time (`[ 6:15 AM ]`), and other things like that.",
    "y22-m02-d09",
    "community-research"
  ],
  [
    "what's the difference between No Module and cross-genre?",
    "Modules always have some limitations. There's no module that simply improves the quality of the writing. They always shift the content focus too, based on the training material. While 'no module' uses the whole finetune without additional weighting.",
    "y22-m02-d09",
    "novelai-discussion"
  ],
  [
    "What Typical sampling Number or percent is that at?",
    "0.95.\nYet another example: ```The tavern was full again, so I ended up sharing a table with three very different creatures: A centaur-like being of brown and gold wearing only breeches and a pair of leather boots; ``` ...giving a centaur human clothing.",
    "y22-m02-d09",
    "novelai-discussion"
  ],
  [
    "Could have been Ai seeing tavern and associated that with fantasy. Elf associates with fantasy. \"Like a bat\" sounds like it made a fucked up simile. As well could mean the full stop after it could have been replaced with as....",
    "```The tavern was full again, so I ended up sharing a table with three very different creatures: A big half-orc man sat opposite me.``` Here it majorly biased down comma, resulting in list of three cutting short at one. ...I would not use any preset that uses Typical, it keeps ignoring the context, which results in too many logic errors.",
    "y22-m02-d09",
    "novelai-discussion"
  ],
  [
    "Well.... the Ai is already usually bad at most math.",
    "Okay, another example. Here it biased up 'elf' for the crocodile, added an 'as well' that doesn't apply...: ```The tavern was full again, so I ended up sharing a table with three very different creatures: a long-snouted crocodile with the body of an elf, another creature like a bat with a huge beak that made a living on the wing, and a short, skinny human whose left hand was bandaged up as well.``` ...and I have no clue what it was going for with the bat. And that's only at 0.95.",
    "y22-m02-d09",
    "novelai-discussion"
  ],
  [
    "Or stuff like Pok\u00e9mon or Digimon",
    "Let's see what it does with Pokemon... ```List of Pokemon:\n# Name Type Biome Nature Specialty Attack Defense HP Sp. Attack Sp. Defense Specialty Specialty Specialty Specialty Specialty Specialty``` ...I may have mentioned that Typical has major repetition issues.",
    "y22-m02-d09",
    "novelai-discussion"
  ],
  [
    "No, NAI doesn't understand data tables.",
    "It does.",
    "y22-m02-d09",
    "ai-writing-help"
  ],
  [
    "I don't think it's particularly fantasy\/sci-fi minded unless you use a module that is trained on that.\nIt's capable of real world writing, and as far as I can tell it's not noticeably less capable on that than fantasy tropes.",
    "Euterpe is, anyway. Sigurd was originally trained with 'adventure' focus, though that got broadened a bit by last version.",
    "y22-m02-d08",
    "novelai-discussion"
  ],
  [
    "Prime Dragon could def be fucked up",
    "Well, among other things, it was finetuned with this - https:\/\/tvtropes.org\/pmwiki\/pmwiki.php\/WebOriginal\/Geek (Check with your own risk, highly nsfw.)",
    "y22-m02-d07",
    "novelai-discussion"
  ],
  [
    "the issue there is that it'd boil down to a transcript unless you find someone who pushed out a decent quality novelization of that",
    "Actually... https:\/\/www.goodreads.com\/series\/58044-pokemon-chapter-book\nBut those seem to be hard to find.",
    "y22-m02-d07",
    "novelai-discussion"
  ],
  [
    "Hold up.... with Typical.... does that mean..... snakes will more likely be human or ....",
    "Low Typical, prompt: ```Snakes look like``````a man, a very big and well-dressed man, in a long overcoat```",
    "y22-m02-d07",
    "novelai-discussion"
  ],
  [
    "So if I'm right, Typical makes the Ai very likely to want to put humans anywhere, even where they don't belong?",
    "Unfortunately. Since they're so common in the data.",
    "y22-m02-d07",
    "novelai-discussion"
  ],
  [
    "You can nudge it to describe non-human races well though, but on its own it prefers humans.",
    "This was actually one of my test cases for the presets. Prompt: ```The tavern was full again, so I ended up sharing a table with three very different creatures:``` Random output from Ouroboros: ```a tawny-furred bipedal ferret who wore the leather jerkin and tasseled hat of an elvish bard; a bulky bipedal orc in full battle-plate armor and helmet that sat on his head like a gigantic bucket; and a jolly-looking brown ratfolk in an eyepatch, green tunic, and round spectacles.```",
    "y22-m02-d07",
    "novelai-discussion"
  ],
  [
    "So.... Basically.... Typical Sampling is good at making tokens highly likely if they are in a lot of Phrases or stories in the fine-tune or training set. \nIf it's a common token in the data, or among many stories, then with typical it's highly likely to be chosen. \nRare things are less likely to be chosen. \nIf it's more diverse across the data or the Ai has \"seen\" it more often, then the Ai is more biased to pick it?",
    "Yes.",
    "y22-m02-d07",
    "novelai-discussion"
  ],
  [
    "would it be possible to just duplicate a small dataset over and over? i imagine this might lead to shittier generations but ive got a steely dan dataset id love to be able to properly use",
    "If you duplicate _everything_ then that's basically same as just training at 200%.\nIt's only useful if you need to balance the material, such as giving more focus to short fics when there's larger ones in the collection.",
    "y22-m02-d07",
    "module-discussion"
  ],
  [
    "Genesis and Ouroboros use Top-K > TFS > Temperature.\nLow Rider and Ace of Spades use... uhhh...",
    "Ouroboros is Top-K > Temperature > TFS.\nGenesis is Top-P > Top-K > TFS > Temp.",
    "y22-m02-d07",
    "novelai-discussion"
  ],
  [
    "I made a little tool for that: https:\/\/github.com\/Systemcluster\/wordstat",
    "This will be useful for balancing the modules. Thank you.",
    "y22-m02-d07",
    "module-discussion"
  ],
  [
    "Thank you <@701121157369430198> and <@409511804293611530> and <@155764131054616577> and <@456226577798135808> and <@232065593363267585> and <@230763790323548161> and <@129290683470053376> and <@746342098294407178> and <@170594415109341184> for all your guys hard work on these models and settings and fine-tunes. Especially V2 E.",
    "And aero, finetuneanon, ght901 (who we've been bothering constantly with testing issues), Chris, etc, etc.",
    "y22-m02-d06",
    "novelai-discussion"
  ],
  [
    "nah, fill the queue even more <:goosip:765775467420581958>",
    "_I have 300K steps to use, everyone get in the line behind me._",
    "y22-m02-d06",
    "novelai-discussion"
  ],
  [
    "Zaltys, you said earlier that you don't know what got added into 20b for the fine-tune. And you don't know the cut off point. Does that mean you have the \"novels\" ready to use. You just need to start training?",
    "I know what got added to 20B. But I don't remember exactly what got added after the v2 cut-off point, that was too long ago.\nBasically, I curate, categorize, and clean the data. Then send it off for training, which is done by smarter folks than me.",
    "y22-m02-d06",
    "novelai-discussion"
  ],
  [
    "Albanians get some well deserved representation at last.",
    "And the countries that everyone forgets about. Andorra, Antigua & Deps, Barbados,...",
    "y22-m02-d05",
    "novelai-discussion"
  ],
  [
    "Do we even know *what* v2 is?",
    "Improved on the training side. Same dataset. 20B will have an updated one. (Don't ask me what got added into 20B, I've lost track already about where the cutoff point was.)",
    "y22-m02-d05",
    "novelai-discussion"
  ],
  [
    "Btw, still using your old zaltys brand formating for lorebook entries",
    "Not really recommended for NAI... it can manage just fine without jumping through hoops.",
    "y22-m02-d05",
    "novelai-discussion"
  ],
  [
    "So things like Style: Genre: etc shouldn't be in brackets? Information online about using brackets for A\/N, memory and Lorebook tends to be conflicting.",
    "Bracketed for the `[ Author:; Title:; Genre:; Tags:; ]` block., but put those at the top. (Memory.) Anything that's before those is weaker, generally not something you want.",
    "y22-m02-d05",
    "ai-writing-help"
  ],
  [
    "I heard something about not using brackets with Euterpe, especially for A\/N, is this true?",
    "I can't think of many good uses for brackets in AN. They're useful when manually inserted, for directing the story, but things that should be remembered should go further back in Memory.",
    "y22-m02-d05",
    "ai-writing-help"
  ],
  [
    "what does tail-free sampling imply as far as generation settings go?",
    "Tosses out 1.00 - TFS-value of tokens from the bottom end of the pool (lowest probability).\nFor instance, `TFS: 0,95` prunes bottom 5% (in combined token probabilities), etc.\n\nGenerally those tend to be bad ones and pruning them improves the overall quality of the token pool, but note that too heavy pruning tends to make the output less creative\/verbose by pruning synonyms. At the bottom end of the pool, even 5% is _a lot_ of tokens.",
    "y22-m02-d05",
    "module-discussion"
  ],
  [
    "how does bracket usage in Euterpe's memory and A\/N prove effective? I've heard conflicting stories",
    "Not recommended for AN. In the data brackets are mainly used right after a chapter break (`***`). So throwing those into middle of story is bound to break the flow. Memory is a good place for them, if you want to use them at all.\nIf you do use them in middle of the story, best to use them manually. Such as inserting location changes with them to direct the story.",
    "y22-m02-d03",
    "ai-writing-help"
  ],
  [
    "He is working on the Golden Goose <:smug:838312047888302080>",
    "Most of the important work on NAI is done by folks like Kurumuz, finetuneanon, aero, ght901, etc. Who don't get anywhere near enough credit. Though they seem to prefer to stay out of the spotlight (or are too busy with work to spend time on Discord.)",
    "y22-m02-d03",
    "community-research"
  ],
  [
    "Are formatted entries in the finetune that would be useful for lorebooks? I think I've seen you mention the [ Title, etc.. ] format and one for POV\/Scene Setting, but those seem more like context\/memory tools.",
    "The wiki-style tags can be used within LB. See https:\/\/discord.com\/channels\/836774308772446268\/837581164436258837\/936585915302813718\nWorks just as well for characters, etc. `Attributes:` is used as a common field that works with pretty much anything.",
    "y22-m02-d03",
    "ai-writing-help"
  ],
  [
    "Special formats don't really work well. Format your lorebooks like you want the generated text to be formatted.",
    "Formats work fine if they're included in the finetune.",
    "y22-m02-d03",
    "ai-writing-help"
  ],
  [
    "I distinctly remember there being two or three files hosted on publicly available servers that contained lists of NAI finetune titles and authors (not text). They all dated to before beta launch and were removed not long after, but the links were stickied here on Discord for a time, and it was a minor kerfuffle when they were removed.",
    "Nope, you're thinking of the books3 collection from the Pile.",
    "y22-m02-d03",
    "community-research"
  ],
  [
    "Aphrodite, the new 20B model trained on\u2026 well\u2026 <:smug:838312047888302080>",
    "Eros.",
    "y22-m02-d02",
    "novelai-discussion"
  ],
  [
    "Aini mentioned something yesterday about them using the name of muses from Greek mythology to name the AI models",
    "I don't know if this is a good idea in the long run. Thalia? AI's aren't great at comedy. Erato? Naming a model after muse of erotic poetry might be too much. Etc.",
    "y22-m02-d02",
    "novelai-discussion"
  ],
  [
    "is anything 3.[x] considered high loss?",
    "If trained to 100% or more, it is very high. You'll have trouble getting it to stick to whatever format you're using, etc.",
    "y22-m02-d02",
    "module-discussion"
  ],
  [
    "I would definitely enjoy a channel where someone makes and eats AI generated recipes",
    "I'd watch it. Sigurd's a bit too random for that, but Euterpe might manage to make something edible.",
    "y22-m02-d01",
    "module-discussion"
  ],
  [
    "Try something like Zombie Fingers <:cheemsredeyes:837331648252870726>",
    "...kid dish, with zucchini and carrots.",
    "y22-m02-d01",
    "novelai-discussion"
  ],
  [
    "Fried okra chicken",
    "...goes on, but this was getting too long already.",
    "y22-m02-d01",
    "novelai-discussion"
  ],
  [
    "the grey is ghost coom",
    "Oh. I thought they're arms.",
    "y22-m01-d31",
    "novelai-discussion"
  ],
  [
    "Could someone explain the use of the [ Author: ; Title: ; Tags: ; Genre: ] init block that I've seen mentioned before? Also, does formatting matter in the memory, i.e. do you need to write whole paragraphs or could you describe things in any format, using Sigurd?",
    "Basically, just put in whatever and it might work, depending on what combos you use and if the AI recognizes them. (This might've not been the best example, but meh. First shot.)\nAs can be seen from the example, fields can be left empty.",
    "y22-m01-d30",
    "ai-writing-help"
  ],
  [
    "I saw a bit of conflicting info online and wanted to check. I've been using Authors note for `GENRE` `STYLE` etc. but I saw some people saying when using Eutrepe I should put that in Memory now?",
    "No. Style and such  are fine in AN. The only one that should always be at top is the main header: ```[ Author: Lewis Carroll; Title: Alice's Adventures in Wonderland; Tags: fantasy, fiction, young adult, female protagonist; Genre: fantasy, classics ]``` ...if you use that at all.",
    "y22-m01-d29",
    "ai-writing-help"
  ],
  [
    "",
    "Does it recognize `xyzzy`, `plugh`, etc?",
    "y22-m01-d28",
    "novelai-discussion"
  ],
  [
    "You're talking specifically about Euterpe, right?",
    "No. The `[ Author Title Tags Genre ]` is almost as strong of a 'new story begins here' as `\u2042`. Don't use it in middle of the story.",
    "y22-m01-d28",
    "community-research"
  ],
  [
    "Does Sigurd have any rules\/guidelines for onomatopoeia? I'm trying to incorporate sound effects into my current story, so I'm wondering if I should just place asterisks where needed? I.e. * KABLAM * (without spaces between asterisks)",
    "There's some slight training for using `*`s for sound effects, which seems to be working. But I haven't had time to test it much. (I'm constantly adding more, so it'll be stronger in future models.)",
    "y22-m01-d27",
    "ai-writing-help"
  ],
  [
    "I've been toying around with both Sigurd and Euterpe and comparing their responses to similar inputs. Euterpe seems much more eloquent, with more elaborate prose and slightly stronger descriptions. Sigurd is no slouch though.",
    "The bot 'personalities' are also affected by their names, which hinders the comparison.\n(Sigurd is associated with viking content, while Euterpe is a muse of poetry. )",
    "y22-m01-d25",
    "novelai-discussion"
  ],
  [
    "We don't know what fucked up creatures Australians don't tell us about",
    "",
    "y22-m01-d25",
    "novelai-discussion"
  ],
  [
    "<@!746342098294407178> Any idea how all caps are generally used in the finetune?",
    "What are you even talking about?",
    "y22-m01-d22",
    "ai-writing-help"
  ],
  [
    "Wouldn't they lose the connection to Attributes: after too many tokens?",
    "I haven't noticed them weakening in long lists, but it's not like I've crammed in hundreds of tokens.",
    "y22-m01-d22",
    "novelai-discussion"
  ],
  [
    "Wouldn't that end up in too many tokens for Attributes? <:think:855548448405061702>",
    "Well, depends on what you consider too many.",
    "y22-m01-d22",
    "novelai-discussion"
  ],
  [
    "could i add stuff like\n\npersonality:\nappearance:",
    "Can use `Attributes:` for both. I've heard that `Personality:` doesn't work too well.",
    "y22-m01-d22",
    "novelai-discussion"
  ],
  [
    "what about details about the character?",
    "`Attributes:` can be used as a generic category.",
    "y22-m01-d22",
    "novelai-discussion"
  ],
  [
    "using \"[]\" while setting lorebooks is still a thing?",
    "Euterpe moved away from putting things inside []s, as it can be trusted to not leak so much. []s are still used, but are limited to usage similar to chapter titles, and for character switching etc. Generally not useful in memory\/AN\/LB.\n\nOne style that's supported is the data format.  Similar to the wikipedia infoboxes:",
    "y22-m01-d22",
    "novelai-discussion"
  ],
  [
    "Apparently keywords like `Attributes:` and `Situation:` worked for some users when it comes to describing characters or setting up events.",
    "`Attributes:` was added as a catch-all. Wouldn't have worked in Sigurd, but Euterpe understands it quite well. This is the style that I'd recommend for that: ```\nSubject\nAttributes: comma separated, list, multiple items```\n`Situation:` is not something we've added, but there's plenty of situation reports in novels. Might work, haven't tested it myself.",
    "y22-m01-d21",
    "ai-writing-help"
  ],
  [
    "why do people keep pinging me about shit",
    "That's a question that I've asked myself for months. I'm trying to work, have the 'do not disturb' on, and still constant *ding*, *ding*,  *ding*, *ding*...",
    "y22-m01-d19",
    "nsfw-discussion"
  ],
  [
    "i retry too much probably",
    "Maybe give Belverk's Monkey Business a try. It's quite close to what I ended up using \u2014 except with reduced rep penalty range. https:\/\/discord.com\/channels\/836774308772446268\/855963388596715531\/930102603336007770",
    "y22-m01-d19",
    "novelai-discussion"
  ],
  [
    "There's very few times when you want to manually put an asterism. The only times I would use it are for things like generators",
    "And that's going to get changed in the future.\nWe've switched to `----` (single token) for separating generator-style entries. Didn't make it in time for v2 dataset, though.",
    "y22-m01-d19",
    "novelai-discussion"
  ],
  [
    "Euterpe spammed asterism with each newline.",
    "That wasn't even the main problem. As `\u2042` is two tokens, it spammed other things that started with the first token. Which are pretty much random unicode.",
    "y22-m01-d19",
    "novelai-discussion"
  ],
  [
    "> Kirie possesses two ghosts - Chikako and herself.\nEven with SOrange's amazing character, *Euterpe still kinda struggles with the body-sharing concept.*",
    "Not surprised. Need to find more fiction where this happens, it's not exactly a common occurrence in novels.",
    "y22-m01-d19",
    "novelai-discussion"
  ],
  [
    "Hey can anyone tell me how Euterpe is stacking up to Aidungeon Dragon right now?",
    "Not directly comparable. Much better at some things, worse at others. Also, which Dragon?",
    "y22-m01-d18",
    "novelai-discussion"
  ],
  [
    "In my experience, there was a pretty large jump in the quality of furry stuff going from Sigurd v3 to v4. Going from Sigurd v4 to Euterpe v1 there was a bit less of a leap. Overall though, it's pretty damn good. Requires a bit of biasing against human stuff though.",
    "It has been one of major focuses. Non-humans in general. Including animals, robots, sentient objects... and yes, furries. Need a lot of it to even start to balance those with all the human fiction.",
    "y22-m01-d18",
    "novelai-discussion"
  ],
  [
    "```List of insulting phrases.\n1. You are the most stupid person in this room, and I have met many people!\n2. What a fool you are to think that we would not notice your cheating!\n3. You're so stupid it's painful.\n4. We know all about your dirty tricks; don't try anything funny or else...\n5. Your head is as big as an elephant.\n6. What a dumb ass!\n7. Your brains must be made of mashed potatoes because they look like it.\n8. Why can't you get any smarter?\n9. If only you were born a girl then at least someone would love you.```",
    "Mostly worked, but got weird towards the end...",
    "y22-m01-d17",
    "novelai-discussion"
  ],
  [
    "Yeah, I wouldn't recommend using horizontal tabs. There's no need to and I doubt it's in much of the training or finetune data. The only place horizontal tabs tend to get used is code, and even that is probably more often spaces",
    "All tabs have been cleaned out, except for rare code snippets.",
    "y22-m01-d16",
    "novelai-discussion"
  ],
  [
    "define pretty identical",
    "Similar results no matter how many times you retry. Especially on random generation, such as encounters.",
    "y22-m01-d16",
    "novelai-discussion"
  ],
  [
    "This gave me the best responses so far\n> The following is a lecherous story about a young scientist named Morgan who has a job opening for a laboratory assistant. He has stated that this laboratory assistant be a young, attractive woman who has a degree in physics. The story starts with job applicant, a young attractive woman, walking into his laboratory and then a long, elaborate description of this woman is given. Some notes on the description of the woman:\n> - It is elaborate and at least 2 paragraphs long.\n> - It describes her in an evocative, sexy way.\n> - It describes in detail what she looks like, so what clothes she is wearing, how long they are, their colors, her hairstyle, eye color, skin tone, face, everything about her.\n> The story starts now.\n> A bright young scientist named Dr Morgan watched as the most beautiful woman he had ever seen walked into his lab. He took in every single detail of her appearance:",
    "Euterpe is trained to use two styles for lists: `-` and `\u2022`.\nBoth have their downsides. `-` is commonly used for other things, and `\u2022` is also a common OCR error that still hasn't been fully cleaned out. Though if you use it in the beginning of the row, it's more likely than not to generate a list. (Another downside is that `\u2022` isn't on normal keyboards, so we've mostly used `-` for lists. Oh, and numbered lists, forgot about those.)",
    "y22-m01-d16",
    "community-research"
  ],
  [
    "XD There are at least 5k OBJECTIONs in the dataset",
    "If you are talking about the base, then yes, there's tons of legal papers in it. In niche cases like Phoenix Wright that actually helps, but it was leaking heavily into normal output in early training.",
    "y22-m01-d16",
    "module-discussion"
  ],
  [
    "Do people not write novels in in present tense or something because this grammar checker keeps insisting everything needs to be in past tense",
    "No. There are rare exceptions, but since people do not usually think in present tense most find those hard to read - and such books tend to get rated low.\nContrast with normal spoken dialogue. Nobody \u2014 nobody normal anyway \u2014 talks about themselves in present tense when having a discussion.",
    "y22-m01-d16",
    "novelai-discussion"
  ],
  [
    "I'm annoyed with how oviposition and ovipositor are tokenized <:stare:838744922348847135>",
    "Meanwhile, there's fifty different variations of `----------` of varying lengths.\nThe tokenization is quite bad for many things, including the fantasy genre. `g|ry|ph|on`, `k|ob|old`... and don't get me started on `hair|less`, etc.",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "How's de fruck, am I suppose to input those on mobile?",
    "No idea. Sorry. Had to use characters that aren't used for much else, so couldn't use easily typable ones.",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "Ask it for advice on how to seduce a dragon. <:RemSip:861829825760854056>",
    "",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "<@!227443534968520705> Mothra is bad with names <:Jinchul_pain:843167857620942859>",
    "So far it seems to be the only preset that can get my (3-token) nick right.",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "idk what's wrong with my notepad++ but i don't have any of these fonts lol",
    "Yea, they're not default. You can get Lato from all around the net, not sure what's the official link.",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "People still like retro games",
    "True, but do people still like Cleverbot...?",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "E is Sigurd's death",
    "Calliope is still around. I'm hoping that Sigurd's kept for a while...",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "only like 5% of the dataset is books vs like 20% for the pile",
    "Says who? What else do you think we have in there, if not books? Unless you're talking about the base.",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "Like, look, this is how tokens are on Euterpe even with Mothra's high randomness.",
    "Looking at the preceding text, I can see why it went with `resistance`. Proves that it can choose logical tokens even at high randomness.",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "rep pen = 10 gets funny results",
    "Even rep penalty of >3 trims essential things like ` a`, ` an`, ` the`, ` and`, etc. And often replaces them with something weird instead. Main reason why things like colors don't work.\nEuterpe: `Oh, you already used that color in AN? I'll use something else.`",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "you could get high randomness-like outputs by doing ridiculous tfs numbers",
    "Ridiculous on which end of the scale? <:thonk:733040009136832642>",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "I found easiness to steer the plot being pretty reliant on preset <:consider:931885202689642557> it seems a bit easier with the more creative ones",
    "Yes. The current default's good at showing that Euterpe can generate coherent text, but it massively limits what it can output. Which in turn makes it hard to control. There's a reason why the token pool is generally hundreds of tokens, not five.",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "Same experience yesterday with a long story (created with Sigurd). Nearly impossible to use Euterpe with that one. I haven't done too much test with other stories (created with Sigurd).",
    "Try inserting chapter titles. It should obey those, at least.",
    "y22-m01-d15",
    "novelai-discussion"
  ],
  [
    "Question: Do you guys use spaces for brackets in Sigurd? I.e. [ Style: X ] or do you do no spaces [Style:]\nI've seen both used so I'm not sure if one is optimal or not",
    "Use spaces. `[ ` is there to stop contents from leaking, and ` ]` is there to keep it constant. Since `.]` and other unspaced combos are different tokens.",
    "y22-m01-d13",
    "ai-writing-help"
  ],
  [
    "Do it like this.\n```\n[ Age: 30; Appearance: Police uniform; Relationship: Colleague ]\n```\nOf course there are better ways but this is the most common I've seen.",
    "Looks like a mix of the LitRPG style, combined with the story tagging. If that actually works... kind of clever to combine them.\nThis is what the LitRPG style normally looks like: ```\u2500 Character: Gail Fairwind\n\u2500 Species: Human\n\u2500 Main Skills: Papercraft, Swimming, Magic, Spear, Charm``` ...plenty of possible fields, due to different kinds of LitRPGs in there. (Note that using `\u2500 ` tends to cause the AI to talk a lot about 'game' features.)",
    "y22-m01-d13",
    "novelai-discussion"
  ],
  [
    "Yeah. It's just that with format, it's harder for the AI to repeat word for word lorebook entries.",
    "There's that, yes. Without the brackets, AN is likely to leak. ...well, depending on your settings, anyway.",
    "y22-m01-d13",
    "novelai-discussion"
  ],
  [
    "I scraped together the money to give Euterpe a try and I really don't know what is going on with my experiences with her. She's repeatedly just terminated things after doing initial generation after a prompt. Just dinkus, asterism, totally random and irrelevant response.",
    "Turn on `Prepend a preamble` and `Trim excess whitespace` in the settings.",
    "y22-m01-d13",
    "novelai-discussion"
  ],
  [
    "<:KEKWait:837317734437617675> did anything changed about the streaming process ? it seem laggy and working weirdly now , stopping way more often at the end of sentences than it was before",
    "Uh oh. I may have an idea why... Has anyone else noticed this?",
    "y22-m01-d13",
    "novelai-discussion"
  ],
  [
    "I'm really liking what I'm seeing with Euterpe so far. For all my appreciation for Sigurd, that engine was eloquent but somewhat lifeless in my opinion, lacking in creativity. With Euterpe, I'm starting to see some of the creative spark that pleased me the most with early Dragon. It's not quite at the same level yet (except in the quality of the writing itself), but we're definitely getting there.",
    "Try the Mothra preset, if you haven't.\nIt's much more random - and it'd say more creative - than the low Top-K ones. When the AI ends up generating a badly fitting token, it can often get unusually creative when trying to make sense of what was already output.",
    "y22-m01-d13",
    "novelai-discussion"
  ],
  [
    "New Co-writer is a REMARKABLE improvement, damn",
    "Until the next version anyway, then everything needs to be tested again. <:doom:837136374493741057>",
    "y22-m01-d13",
    "novelai-discussion"
  ],
  [
    "``[writing style: schizophrenic, transcendental; genre: slice of life; scene: a man walks down a dark street]``\n```It's not that I'm afraid. It's just...I don't know what to do with myself anymore. This is the first time in my entire life where it feels like there are no more options for me\u2014no way out except death itself. That thought has been weighing on my mind lately as I walk through this city at night. The only thing keeping me from collapsing into despair and giving up all hope was the fact that I had some sort of goal ahead of me, but now even that seems impossible.\nThe streets here aren't so different than those back home. They're filled with people going about their lives, doing whatever they want. But something doesn't feel right to me when I look around. Maybe because things seem too normal? Like everyone else is living happily ever after while I've fallen off track somewhere along the line.\nMaybe you could call it fate or destiny, but everything happened exactly how it should have. When I left high school behind and started working full-time, I didn't think much of it, since I'd always wanted to work anyway. Then one day, an opportunity presented itself. A chance came knocking on my door. And if I hadn't answered, then who knows what would've become of me? There were many times when I wondered whether or not I made the right choice, but ultimately, I knew deep down inside that I did. So why does it still feel wrong somehow...? Why can't I shake these feelings of unease? What am I supposed to do next? Is there any point in continuing forward? Or will I be doomed to wander aimlessly forevermore? Will I end up being swallowed whole by this darkness that threatens to consume me?\n```",
    "||Some `Style:` data _may_ have been added to this version. Because some users insisted on using it, so might as well add some support for it...||",
    "y22-m01-d12",
    "community-research"
  ],
  [
    "<@!409511804293611530> The finetune contains a mix of ... and the unicode one though?",
    "Yes. Whichever the author used was kept, so there may be some slight style differences between those. Content like LNs and fanfics is 100% `...`.",
    "y22-m01-d12",
    "module-discussion"
  ],
  [
    "It seems to handle size difference better",
    "Some of that got added. Hard to find in published novels, had to resort to fanfics. Not sure if enough was added for it to be _good_ at that.",
    "y22-m01-d12",
    "nsfw-discussion"
  ],
  [
    "They've indicated probably not until v3 or v4 I think.",
    "False. https:\/\/discord.com\/channels\/836774308772446268\/837402685824565278\/930045135146860564",
    "y22-m01-d12",
    "module-discussion"
  ],
  [
    "Kraken? <:SadHolo:837316963575136327>",
    "Imagine what Euterpe-bot would be like if it had been named Kraken...",
    "y22-m01-d11",
    "novelai-discussion"
  ],
  [
    "The dataset was also updated after Sigurd v4, so dataset-wise alone it would be like Sigurd v5, though again not really easily comparable like that",
    "We had considerably more time to work on v4. So I'd call this one more like v4.5, it's not as major change as the previous version.",
    "y22-m01-d11",
    "novelai-discussion"
  ],
  [
    "On a blank prompt, `The next` is extremely likely to happen.  So you could start there.",
    "Worth noting that this is only with bracket ban on. If you let it generate a title, it gets diverse.",
    "y22-m01-d11",
    "community-research"
  ],
  [
    "\"The man behind the curtain\" by necessity is weaker than he appears",
    "Eh? No, it stems from theatre. You're not supposed to pay attention to what the background crew is doing (that kills  the immersion), keep the eye on the actors.",
    "y22-m01-d10",
    "novelai-discussion"
  ],
  [
    "I did a pop quiz with the new model and it almost got it right, but had to screw it\n```\nQuestion: Which of the following Pok\u00e9mon is a quadruped?\nA) Armaldo; \nB) Gengar; \nC) Talonflame; \nD) Metagross; \nE) Salazzle.\nAnswer: D) Talonflame.\n```",
    "Pokemon data improved from v4, but still needs major work.",
    "y22-m01-d10",
    "novelai-discussion"
  ],
  [
    "Can you force longer sentences?",
    "Bias down punctuation.",
    "y22-m01-d10",
    "novelai-discussion"
  ],
  [
    "Now, is that 36 from now, or 36 hours of work?",
    "That's the same...",
    "y22-m01-d10",
    "novelai-discussion"
  ],
  [
    "Well technically Zaltys isn't a dev. That I know of. Why wasn't he OK? Or do you mean he still is OK?",
    "Someone repeatedly pestered me to add cuck books into the dataset, but they didn't pass the quality check.",
    "y22-m01-d09",
    "novelai-discussion"
  ],
  [
    "Placebo effect?",
    "<:PepeHmm:928419182545088522>",
    "y22-m01-d09",
    "novelai-discussion"
  ],
  [
    "is this a poetry model",
    "...no. But it is trained to generate poetry if you start a row with `\u2003` (em space).",
    "y22-m01-d09",
    "novelai-discussion"
  ],
  [
    "So, I'm scraping a very long text and it has this. *How to make it work?* Just remove the quote-like text? Brackets?",
    "Hard to tell what that is, from the snippet. Probably just keep it as is, without italics of course.\nIn any case, no brackets, never combine those with quotation marks.",
    "y22-m01-d09",
    "module-discussion"
  ],
  [
    "What can you say about them that\u2019s not under NDA?",
    "One thing to keep in mind is that the devs used to work on filtering systems before AID. And that's all I have to say about this.",
    "y22-m01-d09",
    "ai-writing-help"
  ],
  [
    "I guess I entered it at its apex, which didn\u2019t last long, because OpenAI forced content censorship. They got scared and I was only able to use it for a couple of weeks.",
    "`because OpenAI forced content censorship` <:Kappa:838196508494135336>",
    "y22-m01-d09",
    "ai-writing-help"
  ],
  [
    "space before the opening bracket\nthe closing one doesnt matter iirc",
    "Both matter, but in different ways. If you don't space the first one, it'll likely leak the contents. Whereas spaced ones usually don't, as the AI is taught not to start a new row with space - which means it can't copy it verbatim.",
    "y22-m01-d09",
    "ai-writing-help"
  ],
  [
    "20 months for 20b",
    "175 months for 175B. <:ogtroll:838076368633593866>",
    "y22-m01-d08",
    "novelai-discussion"
  ],
  [
    "dunno where it went",
    "Free pet.",
    "y22-m01-d08",
    "novelai-discussion"
  ],
  [
    "So really it is better to have high randomness and manipulate top-p, nucleus, and TFS so that you can get the AI to at least consider a wider range of tokens?",
    "Within limits. Strict nucleus\/TFS can easily make it so that there's only one token left, so there's nothing left for randomness to change.",
    "y22-m01-d08",
    "novelai-discussion"
  ],
  [
    "<@!409511804293611530> 3-4 Farscape novels.",
    "The one I could find had terrible ratings, and reviewers mentioned everyone being 'completely out of character'. Didn't make the cut.",
    "y22-m01-d03",
    "module-discussion"
  ],
  [
    "Sometimes when I put that, it gets read like it\u2019s part of the story",
    "Try using it more like a chapter title. `[ The Dragon Strikes ]` or whatever.",
    "y22-m01-d03",
    "ai-writing-help"
  ],
  [
    "Is there a list of tags?",
    "No, and there's unlikely to ever be one. It'd be a long list, and it's in constant flux. A lot of them are one-offs, like `1860s` or whatever.",
    "y21-m12-d31",
    "nsfw-discussion"
  ],
  [
    "Hmmmmm",
    "https:\/\/store.steampowered.com\/app\/335670\/LISA_The_Painful\/",
    "y21-m12-d31",
    "novelai-discussion"
  ],
  [
    "Should the tags be capitalized, like Pregnant instead of pregnant ? Hentai tags are not, but they might trigger rep pen if not capitalized",
    "Tags are not capitalized in the finetune. Doesn't necessarily mean that caps won't work, though. Just that lowercase is more likely to work.",
    "y21-m12-d30",
    "nsfw-discussion"
  ],
  [
    "Still, it's enough to deduce that a probable timeframe is known, and it is close.",
    "Well, there may be factors that Sage isn't aware about. Which is why teasing users with new features is generally a bad idea. Kind of puts pressure on having to release the feature, even if that wasn't planned.",
    "y21-m12-d30",
    "community-research"
  ],
  [
    "Yeah, Sigurd understands `anthromorphic` really well.",
    "Which is weird since the proper spelling is `anthropomorphic` (which is two tokens btw, `anthrop|omorphic`.)\nMaybe it understands `anthromorph`, and the `ic` token is just extra there.",
    "y21-m12-d30",
    "nsfw-discussion"
  ],
  [
    "If Sage released it\ud83d\ude2d",
    "Now see what you did to Makya. Shouldn't tease users like that.",
    "y21-m12-d30",
    "novelai-discussion"
  ],
  [
    "Anyway I've been looking for realistic YA with male protagonists that don't have racism as a major theme (Think The Outsiders by S.E. Hinton) for my module and I literally cannot find any",
    "https:\/\/www.goodreads.com\/book\/show\/37506437-darius-the-great-is-not-okay <:Kappa:838196508494135336>",
    "y21-m12-d28",
    "novelai-discussion"
  ],
  [
    "I'll definitely have to check it out",
    "The first arc is weak. That was back when the author was restricted by DC.",
    "y21-m12-d28",
    "novelai-discussion"
  ],
  [
    "So I'm going to assume Setting is more used for franchises or movie\/video game universes?",
    "Yes, exactly.",
    "y21-m12-d27",
    "ai-writing-help"
  ],
  [
    "1. To indicate author, genre, and story tags, (as well as a few others that, despite not being in the finetune, proved effective, like Style, Setting, or Pairing). An example would be: `[ Author: Bram Stoker; Genre: Gothic Horror; Tags: vampires, castles, undead; Setting: Transylvania; Style: Victorian ]`",
    "`Setting:` is in the finetune, but as I may have mentioned, it's not used for locations (those go in `Tags:`.) \nSetting's used more like... `Setting: Marvel Universe`, or `Setting: Pokemon`.",
    "y21-m12-d27",
    "ai-writing-help"
  ],
  [
    "On that topic, isn't Chromium browser just version of Chrome that was stripped of spyware stuff? <:stare:838744922348847135>",
    "Yep. But I vouch for Brave. Built-in ad blocking, faster than Chrome, inbuilt Tor, full Chrome combability, etc. Basically, a less intrusive Chrome.",
    "y21-m12-d26",
    "novelai-discussion"
  ],
  [
    "Oh no I made tons of World Info xD",
    "Those entries wouldn't work for LB either, as they average 1600-2000 tokens per 'mon. Wouldn't leave room for anything else.",
    "y21-m12-d23",
    "module-discussion"
  ],
  [
    "in NAI, what would be the difference between fantasy and dark fantasy?",
    "The tone. I can't reveal what novels went into it, but think Berserk, Darkest Dungeon, and Hellblade: Senua's Sacrifice.\nCoincidentally, it has a lot of mental dialogue. Demons, elder gods, etc messing with the protagonist.",
    "y21-m12-d21",
    "novelai-discussion"
  ],
  [
    "I am killing myself.",
    "",
    "y21-m12-d21",
    "novelai-discussion"
  ],
  [
    "The average book is about 1mb of text, so imagine about 5600 books",
    "Average book is 300-400 KB. (After cleans.)",
    "y21-m12-d19",
    "novelai-discussion"
  ],
  [
    "About a billion words.",
    "Yep, was just calculating this and got the same estimate.",
    "y21-m12-d19",
    "novelai-discussion"
  ],
  [
    "Haven't tried it lol. I was told that it wasn't that specific to GoT by a dev",
    "Modules are handled by the finetuning team (finetune-anon included). Most devs do not know what went into them.",
    "y21-m12-d19",
    "module-discussion"
  ],
  [
    "also, any actual emojis or old emoticons like `XD` in the finetune data?",
    "Some. Probably not strong enough to work consistently.",
    "y21-m12-d17",
    "ai-writing-help"
  ],
  [
    "What's that from?\nI remember searching about that online but not finding any info.",
    "There are two common standards for telepathy in published works: italics and angle brackets.\nItalics is much more common, but as markdown isn't available in _.txt_ format those get lost in conversion. Which resulted in AI getting confused about what's going on. So replacing them with the other type seemed like a good idea. It was either that, or drop those books altogether.",
    "y21-m12-d17",
    "ai-writing-help"
  ],
  [
    "Making a DnD lorebook and hitting autogenerate only to get World of Warcraft and Skyrim related entries <:doglaff:507718360100896788> NAI trolling me",
    "`[ Tags: D&D ]` should do the trick. `[ Tags: Forgotten Realms ]` definitely will, but dunno if that's the setting you want.",
    "y21-m12-d16",
    "novelai-discussion"
  ],
  [
    "\"Wait for me!\" She jumped in the hole in the ground.",
    "Correct. Those are separate sentences.",
    "y21-m12-d16",
    "ai-writing-help"
  ],
  [
    "You also end the dialog with a period if it's the end of the sentence. `Ricky told me, \"That's how it is.\"` for example.",
    "Right. That's a single sentence. If you flip it around, it becomes `\"That's how it is,\" he told me.`",
    "y21-m12-d16",
    "ai-writing-help"
  ],
  [
    "But it wasn't even a female dragon. <:stare:838744922348847135>",
    "Ah. For those you can blame the shifter genre.\nhttps:\/\/www.goodreads.com\/list\/show\/6939.Dragon_Shifters\n'I want to have sex with a dragon, but that's too much of a taboo. So here's a whole genre where they can shapeshift into humans which makes it _perfectly fine and not perverted at all_.'",
    "y21-m12-d16",
    "nsfw-discussion"
  ],
  [
    "What kind of things were put in those brackets?",
    "Dates, locations, chapter titles, metadata, currently active character (in multi-protagonist works), etc. And things like `[ Two months later ]`.",
    "y21-m12-d15",
    "novelai-discussion"
  ],
  [
    "<@!409511804293611530> I'm not sure if you are the best person to ask, but you might know...\nI remember someone saying at some point that if you use bracketed prose\n[ The season is winter ]\nThat you need to put a space in-between the last letter and the bracket, because that is how the data was presented in the finetune\nIs that true?",
    "Yes.",
    "y21-m12-d15",
    "novelai-discussion"
  ],
  [
    "yeah, iOS actually substitutes smart quotes if you start a quote and end a quote.",
    "Settings -> Keyboard -> disable Smart Punctuation",
    "y21-m12-d15",
    "novelai-discussion"
  ],
  [
    "He promptly bolted with alacritous celerity towards the exit, as quickly as humanly possible.",
    "He promptly bolted, in a manner that was not at all alacritous, and with a speed that was quite celeritous.",
    "y21-m12-d13",
    "ai-writing-help"
  ],
  [
    "He promptly bolted with alacritous celerity towards the exit, as quickly as humanly possible.",
    "He promptly bolted, in a manner that was not at all alacritous, and with a speed that was quite celeritous.",
    "y21-m12-d13",
    "ai-writing-help"
  ],
  [
    "He promptly bolted with alacritous celerity towards the exit, as quickly as humanly possible.",
    "He promptly bolted, in a manner that was not at all alacritous, and with a speed that was quite celeritous.",
    "y21-m12-d13",
    "ai-writing-help"
  ],
  [
    "He promptly bolted with alacritous celerity towards the exit, as quickly as humanly possible.",
    "He promptly bolted, in a manner that was not at all alacritous, and with a speed that was quite celeritous.",
    "y21-m12-d13",
    "ai-writing-help"
  ],
  [
    "This specific piece was released as a comic book novella by Gaiman and artist Yoshitaka Amano. It's a very odd case because it's a prose novella... published by DC Comics... and redistributed to Amazon. So every page is an image.",
    "It's on Kindle, and therefore azw. Which converts easily enough with Calibre.",
    "y21-m12-d13",
    "feedback-discussion"
  ],
  [
    "ABBYY Finereader gave me this for Neil Gaiman's Dream Hunters\n```The monk came forward, into the moonlight, and he bowed deeply. \u201cI am the unworthy guardian of this temple,\u201d he said, simply.\n\u201cAnd a skinny, unimpressive runt of a priest you are,\u201d boomed the leader. \u201cBut who among us can account for the will of the gods? Truly was it said that those who seek after fortune find it as elusive as grasping a rainbow, while those who disdain good fortune and the world often find it beating upon a gong outside their door.\u201d\nTo this speech the young monk said nothing, but he raised his head a little, and he looked at the horsemen in the moonlight with sharp eyes that missed nothing at all.\n\u201cWell, do you wish to know what your good fortune is?\u201d\n\u201cCertainly,\u201d said the monk.\n\u201cKnow then that you have been sent for by none other than the Emperor himself. You are to travel as fast as you can to the Imperial Palace, where the Emperor wishes to speak with you and to confirm that you are indeed the person of whom the augurs and diviners have told him, and then you will be raised from obscurity and appointed to minister to the needs of the imperial court \u2014 a position which brings with it great fortune and mighty estates.\n\u201cHowever, know also that if you do not present yourself at the Imperial Palace before the next Day of the Monkey, then the auguries go from good to very bad, and the Emperor shall, regretfully, be forced to issue your death warrant. Therefore wait not a single moment, but depart this place before dawn, or risk the Emperor\u2019s severest displeasure.\u201d\nThe horses stamped their feet in the full moon\u2019s light.\nThe monk bowed low once more.\n\u201cI shall leave instantly,\u201d he said, and the five horsemen grinned, the moonlight gleaming from their eyes and their teeth, and from the metal bridles and decorations of their horses, \u201cbut, before I leave, I have one question to ask.\u201d\n\u201cAnd what would that be?\u201d asked the leader, in a voice like a tiger\u2019s roar.\n8\nwo . *\ns\n4\na \u2022\u25a0. \u2019\n\\M*\nvw.\\\nr\n```",
    "You need to show it where the text is by using the Draw Text Area tool. But why try to convert something that's already easily available in non-PDF formats?",
    "y21-m12-d13",
    "feedback-discussion"
  ],
  [
    "languagetool shouldn't turn your story into a boring corporate presentation unlike grammarly according to 4chan",
    "...or maybe they're just overlooking this.",
    "y21-m12-d13",
    "ai-writing-help"
  ],
  [
    "languagetool shouldn't turn your story into a boring corporate presentation unlike grammarly according to 4chan",
    "...or maybe they're just overlooking this.",
    "y21-m12-d13",
    "ai-writing-help"
  ],
  [
    "languagetool shouldn't turn your story into a boring corporate presentation unlike grammarly according to 4chan",
    "...or maybe they're just overlooking this.",
    "y21-m12-d13",
    "ai-writing-help"
  ],
  [
    "languagetool shouldn't turn your story into a boring corporate presentation unlike grammarly according to 4chan",
    "...or maybe they're just overlooking this.",
    "y21-m12-d13",
    "ai-writing-help"
  ],
  [
    "Interesting, how do you end up using *** and what would you say it does in your stories? It seems to basically sever the context off at the most recent one in mine",
    "Time skips. Simple example prompt: ```We left the dungeon behind and began the journey back to the civilization.\n***``` Typical output: ```It was evening when we returned, and I wanted nothing more than a warm bath and some food. We had been on the road for two days, but it felt like much longer as my body ached from riding on horseback.``````\"Hahaha! That was amazing, that last boss fight!\"\nAfter returning from our adventure in the dungeon, we were all gathered together in the guild's meeting room.``````The journey back was uneventful, with no monsters or anything else to trouble us. The three of us made it back in one piece without any further problems.``` Etc.",
    "y21-m12-d11",
    "community-research"
  ],
  [
    "I was interested in prefixing the story context in particular, something like this:\n```\nThis is the memory entry.\nFirst lorebook entry.\nSecond lorebook entry.\n*** <-- Story context prefix is inserted here.\nRest of the context filled with story text.\n```",
    "LB data is relevant to what should be generated. I wouldn't separate them.",
    "y21-m12-d10",
    "community-research"
  ],
  [
    "Speaking of sources, may I please have recommendations for some wordy\/flowery fairy tales? I can think of George MacDonald, maybe, but I'm not certain of any others. The motive is to add a bit more complexity and \"floweriness\" to the somewhat simplistic output of the Disney Fairies module for the next improved version.",
    "Not sure if these are flowery enough, but...\n- Naomi Novik: Uprooted\n- Neil Gaiman: Snow, Glass, Apples\n- Kate Stradling: Brine and Bone",
    "y21-m12-d10",
    "module-discussion"
  ],
  [
    "Also sorry if I was being annoying Zaltys \ud83d\ude4f",
    "Eh? You were helpful, as far I could see.",
    "y21-m12-d10",
    "novelai-discussion"
  ],
  [
    "Will I need to learn regex?",
    "Pretty much all you need is this. Just `\\r?\\n?^$` and replace all.",
    "y21-m12-d10",
    "novelai-discussion"
  ],
  [
    "US copyright law states removing DRM is illegal, so that was just my deduction.",
    "Making tools that break it may be, but not using them. Converting formats for own use is protected by law. Regardless, it probably does break Discord rule 13.",
    "y21-m12-d10",
    "novelai-discussion"
  ],
  [
    "Should probably keep this in dms guys, pretty sure removing drm is illegal in most countries.",
    "DRM removal for personal use is legal in all countries that matter here.",
    "y21-m12-d10",
    "novelai-discussion"
  ],
  [
    "`big-city`",
    "That's correct usage. `big-city` is adjective as in 'big-city life', `big city` is just a big city.",
    "y21-m12-d08",
    "novelai-discussion"
  ],
  [
    "Because Lolita here got exported with the chapters as numbers attached to the beginning of sentences.",
    "Shouldn't happen. Probably wrong settings if you used Calibre.",
    "y21-m12-d08",
    "novelai-discussion"
  ],
  [
    "```\n<Rain?>\n\"Yes, it's me.\"\nThere's a brief pause before the familiar voice returns. <Good morning, Rain. You were wakened prematurely. Do you know why? >\nI don't respond immediately. My brain is trying to reorient itself. \"No. But something has happened. We're experiencing communication difficulties. Our primary mission is still to find and investigate the derelict sphere. Why did we wake early?\"\n<The sphere was destroyed during the last week of our journey. Your crewmates' memories indicate that this is the only event that has ever disrupted your schedule. Are you sure you are hearing me correctly?>\n\"You're telling me that everything is normal? Nothing unusual happened during the trip?\"\n<That's correct. All systems performed normally, with no interruptions. No new planets were discovered, no new stars, no anomalies in any other way. The sphere was found and examined, but it appears to be nothing special. It seems likely that the crew's memory lapses were caused by a natural process.>\n\"Natural? How do you mean, 'natural?'\"\nThe silence that follows makes me think that she isn't responding because of a technical problem. Then the ship speaks again. <It's impossible to say at this time. There is evidence of tampering, but we can't figure out what it means.>\nThe fact that I haven't experienced any interruption of service since the destruction of the derelict is surprising enough, and now the AI admits that the event wasn't just some random occurrence, but something else entirely. I try to calm down and collect my thoughts. \"We'll need to go back over the records and make sure we understand what actually occurred. What do you remember about the sphere being destroyed?\"\nSilence once more. <The records show that a massive burst of radiation was emitted from a location in space near where the sphere was found. The crew remembers seeing flashes and flares as they were examining the sphere, and also saw debris and bits of matter ejected from the surface of the sphere. It appears that a piece of the sphere somehow collided with a planetoid and broke into several large pieces. This collision sent out waves of gamma rays, and when the crew looked away from the object, it appeared to be completely gone. That was three weeks ago. The ship's sensors showed that another wave was generated approximately one hour later, but the data is too degraded to reconstruct what happened. Since then, there have been intermittent communications failures between us and the rest of the crew, and the ship has been experiencing glitches in its navigation system, causing course corrections.>\n\"What does this mean?\"\n```",
    "```There's a brief pause before the familiar voice returns. <Good morning, Rain. You were wakened prematurely. Do you know why? >``` Oof, broken > spacing. Some of that did slip in. Not in the added telepathy brackets, but some of the existing ones were messed up. Already fixed for the next version, but who knows whenever that'll happen.",
    "y21-m12-d08",
    "novelai-discussion"
  ],
  [
    "Random question, but have you noticed `\"I'm sorry,\"` seems to be overrepresented in blank prompt generations? It turns up quite often for me \ud83d\udc40",
    "No, though I usually test it with modules.",
    "y21-m12-d07",
    "novelai-discussion"
  ],
  [
    "`<>` is a common convention.",
    "Yep, though some authors use italics instead. ...converting those to <>s has been a pain.",
    "y21-m12-d07",
    "novelai-discussion"
  ],
  [
    "Alt+numbers in the top row doesn't work for me. I can only alt+numpad numbers in which case it's 196 and not 2500",
    "Huh. What do you get with alt+2500?",
    "y21-m12-d07",
    "community-research"
  ],
  [
    "Idk why changing\n```\nFills the barbarian with rage, making him stronger and harder.```\nto\n```\nFills the Barbarian with rage, making him stronger and harder.```\nMade the output worse <:think:855548448405061702>",
    "Without checking, I'd guess that this and its sequel Barbarian II are in the video game data: https:\/\/en.wikipedia.org\/wiki\/Barbarian:_The_Ultimate_Warrior\nSometimes uppercase has 'wrong' connotations.",
    "y21-m12-d07",
    "novelai-discussion"
  ],
  [
    "What's smut",
    "Smut's smut. Generic term for nsfw, often used by those who think that nsfw is 'dirty'.",
    "y21-m12-d06",
    "nsfw-discussion"
  ],
  [
    "What up with that? \ud83d\ude42",
    "Here \u2014 https:\/\/discord.com\/channels\/836774308772446268\/855852068861116436\/912770764644708383",
    "y21-m12-d04",
    "novelai-discussion"
  ],
  [
    "To be fair, I tried it in v3, mabye v4 is better <:think:855548448405061702>",
    "LitRPG wasn't in v3, so yeah. (I had to make a module for it in v3, and it was still rather weak with that.)",
    "y21-m12-d03",
    "novelai-discussion"
  ],
  [
    "What would happen if it wasn't blank though.",
    "If there's enough context, it doesn't get added. I don't remember how much.",
    "y21-m12-d03",
    "novelai-discussion"
  ],
  [
    "Adds a preamble to context. Beats me what is exactly in said preamble.",
    "`\u2042`. It's mainly there to make blank prompts work. No blank prompts? Won't need it.",
    "y21-m12-d03",
    "novelai-discussion"
  ],
  [
    "",
    "Try adding '\u2003' in front of song lyrics.",
    "y21-m12-d01",
    "novelai-discussion"
  ],
  [
    "Man, I had the weirdest dream last night. I'm trying to recollect it, but I only remember part of it.",
    "Kind of off-topic there. But if you want to remember your dreams better, start writing them down. Pretty soon your brain 'gets' it that you want to remember them.",
    "y21-m12-d01",
    "novelai-discussion"
  ],
  [
    "In my experience, that risk is actually not that big, even when you use brackets in your lorebook, A\/N, and Memory.",
    "Yeah, most of the data has brackets followed by regular prose.  And usually only at the beginning of the chapters. So it's not likely to output prose, then switch back to brackets, at least not without inserting `***` first.",
    "y21-m12-d01",
    "novelai-discussion"
  ],
  [
    "That's true, I remember having some memorable characters with weird accents\/speech patterns. Of course, the downside is that the AI quickly forgot...",
    "ZoNe stuck to that style for several conversations. Including some consistent typos, such as always writing 'of course' as 'Of cAsE'.",
    "y21-m11-d29",
    "novelai-discussion"
  ],
  [
    "I literally can't, just getting errors now.",
    "Are you using a module? Test with another one...",
    "y21-m11-d28",
    "novelai-discussion"
  ],
  [
    "I'm writing a scenario involving the characters from my D&D group and I'm gonna make it write essentially a fanfic for them, lol",
    "Hm. For that specific usage, the LitRPG style could also be worth a shot. Basically, add the character LB entries in this style: ```\u2500 Name: Elminster\n\u2500 Race: Human\n\u2500 Occupation: Sage\n\u2500 Level: 20\n\u2500 Profession: Wizard\n\u2500 Skills: [...]``` v4 can apply data from those well, but it does cause it to throw in occasional game elements. Which may be something that you want in a D&D-style story. Can also use those and then ban `\u2500 `, so the format doesn't leak into the story.",
    "y21-m11-d28",
    "novelai-discussion"
  ],
  [
    "||Harvey instead of Selina? He was lowkey an a*hole||",
    "||Not at that point. And he was a civilian, while Catwoman can take care of herself \u2014 and she did.||",
    "y21-m11-d27",
    "novelai-discussion"
  ],
  [
    "Batman was great.",
    "I never played the second one. Got too annoyed by how blatant the railroading in the first one was. ||Saved Harvey Dent instead of Catwoman for instance, the end result was still the same regardless of how little sense that made.||",
    "y21-m11-d27",
    "novelai-discussion"
  ],
  [
    "Which last games? <:think:855548448405061702>",
    "Batman, Game of Thrones, Minecraft, among others. Nowhere near as good as the earlier ones.",
    "y21-m11-d27",
    "novelai-discussion"
  ],
  [
    "Telltale is working on Wolf Among Us 2",
    "I must be really out of loop, since last I heard was that Telltale died. Not sure how I feel about WAU2, considering how bad the last games were.",
    "y21-m11-d27",
    "novelai-discussion"
  ],
  [
    "You can train a module with data formatted that way, and it will produce text that way.",
    "Not recommended. It'd take _a lot_ of steps to make it strong enough, and even then the normal v4 usage will creep in as the story progresses.",
    "y21-m11-d27",
    "module-discussion"
  ],
  [
    "I suppose I can learn to #cope with <thoughts> output <:bee:753015610752892968>",
    "Usually thoughts should not be enclosed at all. <> is mostly interpreted as telepathy by v4, which is probably not what you want.\nJust use `This style should be fine, I thought.`",
    "y21-m11-d27",
    "module-discussion"
  ],
  [
    "Have tinie tiny moth",
    "My moth is tinier.",
    "y21-m11-d23",
    "novelai-discussion"
  ],
  [
    "Got a unfinished dialogue dump that needs some format checking, I know the obvious \\r\\n isn't changed but... Y'know, unfinished.",
    "No problems found.",
    "y21-m11-d23",
    "module-discussion"
  ],
  [
    "What about that? <a:notes_gif:856700120330534932>",
    "Open grave.",
    "y21-m11-d23",
    "novelai-discussion"
  ],
  [
    "Yeah. I've thought a lot about how conditional biasing would be really useful. I don't know why it would require state to track. Since the tokens are generated sequentially, can't you just \"if last token was `snow` then negatively bias `man`",
    "Then it'd just dodge the bias and generate something like `snow|men`.",
    "y21-m11-d22",
    "community-research"
  ],
  [
    "Dragonbait is a saurian character from the Forgotten Realms universe.",
    "And Alias is in the same party.",
    "y21-m11-d22",
    "novelai-discussion"
  ],
  [
    "like that up there?",
    "Might work, but with how randomly the chunks get split it may have no idea who's talking.",
    "y21-m11-d21",
    "module-discussion"
  ],
  [
    "<@!701121157369430198> from experience, what would you suggest? like\n```***\n[ Prophet ]\n\"Excavations beneath the manor were well underway, when a particular ragged indigent arrived in the hamlet. This filthy, toothless miscreant boasted an uncanny knowledge of my ambitions and prognosticated publicly that left unchecked, I would soon unleash doom upon the world.\"\n\"This raving creature had to be silenced, but doing so proved maddeningly impossible. How had he survived the stockades, the icy waters, and the knives I delivered so enthusiastically into his back? How had he returned time and time again to rouse the townsfolk with his wild speculations and prophecies?\"\n\"Finally, resigned to his uncommon corporeal resilience, I lured him to the dig. There, I showed him the Thing, and detailed the full extent of my plans. Triumphantly, I watched as he tore his eyes from their sockets, and ran shrieking into the shadows - wailing maniacally that the end was upon us all.\"\n***\n[ Necromancer ]\n\"Mastery over life and death was chief among my early pursuits. I began in humility, but my ambition was limitless. Who could have divined the prophetic import of something as unremarkable as a twitch in the leg of a dead rat?\"\n\"I entertained a delegation of experts from overseas, eager to plumb the depths of their knowledge and share with them certain techniques and alchemical processes I had found to yield wondrous and terrifying results. Having learned all I could from my visiting guests, I murdered them as they slept.\"\n\"I brought my colleagues back with much of their intellect intact, a remarkable triumph for even the most experienced necromancer. Freed from the trappings of their humanity, they plied their terrible trade anew - the dead reviving the dead, on and on down the years... forever.\"```\nOr skip the while [ bla ] thingies and just quote after quote?",
    "Better. Separate the sections with `***`. ```***\n[ Necromancer ]```, etc. Could also try `[ Necromancer - quotes ]`",
    "y21-m11-d21",
    "module-discussion"
  ],
  [
    "I could format https:\/\/darkestdungeon.fandom.com\/wiki\/Narrator_(Darkest_Dungeon) today to be more usable\n```[ Heart of Darkness ]\n\"You still foolishly consider yourself an entity separate from the whole. I know better. And I. Will. Show you.\"\n\"The flesh is fluid, it can be changed, reshaped, remade!\"\n\"The flesh is immortal, it is undying. Pray it does not take too hideous a form.\"\n\"Behold the heart of the world! Progenitor of life, Father and Mother, Alpha and Omega! Our creator... and our destroyer.\"```\nlike this or just quote after quote after quote?",
    "This is problematic. Without names, the AI will likely interpret it as two characters talking. But I'm not sure how to do it better.",
    "y21-m11-d21",
    "module-discussion"
  ],
  [
    "Alright, this one needs checking, I'm unsure of the formatting.",
    "410 - extra space needed in `Margaret clicks her tongue.\"That's not very nice, falling asleep on a lady.\"`. Nothing else to fix.",
    "y21-m11-d21",
    "module-discussion"
  ],
  [
    "And what to indicate thoughts? Do I use the same thing that is for non-verbal dialogue?",
    "No bracketing, unless it is telepathy etc. Which that story seems to have at couple of points.",
    "y21-m11-d21",
    "module-discussion"
  ],
  [
    "Brackets? Or something else?",
    "[] brackets.",
    "y21-m11-d21",
    "module-discussion"
  ],
  [
    "Yeah, I'd edit the double newlines into one, and make sure that single quoted utterances are double quoted.",
    "There's no need to do anything about single quotes, that's just waste of time. There's plenty of both in the finetune.",
    "y21-m11-d21",
    "module-discussion"
  ],
  [
    "Here is what I got so far, mind checking if this is good story material for the module? Excluding the txt with links to the sources of course.",
    "Lose the extra linebreaks, and change the rest to `\\n` from `\\r\\n`. And you definitely don't want Zalgo in there. Cut the `E\u0337\u034d\u0305N\u0338\u0330\u0308J\u0336\u0314\u0345O\u0337\u0321\u033fY\u0335\u031b\u0329 \u0337\u032c\u033fT\u0337\u033f\u0345H\u0338\u0317\u030e\u1e2c\u0338\u035bS\u0335\u0331\u0357 \u0334\u033a\u0313S\u0338\u032a\u035bM\u0335\u032c\u030dA\u0337\u032a\u0350L\u0338\u0356\u030b\u1e36\u0338\u0313 \u0335\u0354\u0301P\u0334\u033c\u030eI\u0335\u033c\u030d\u0162\u0334\u0311T\u0334\u031f\u0342A\u0336\u0347\u030d\u1e44\u0334\u031eC\u0335\u0349\u035d\u0206\u0334\u032e \u0336\u031d\u0315\u0174\u0336\u033cH\u0335\u0339\u031aI\u0338\u0348\u0350L\u0334\u031b\u0359E\u0338\u034d\u034b \u0334\u0316\u035dY\u0335\u035a\u033f\u020c\u0334\u032a\u016e\u0337\u032c \u0337\u033a\u0315M\u0336\u031f\u033f\u1e00\u0337\u030cY\u0337\u0355\u0313,\u0335\u034d\u0310 \u0336\u032a\u0360W\u0335\u032e\u0352\u1ece\u0336\u031fR\u0337\u0354\u0309M\u0336\u0354\u034b.\u0335\u0329\u0310 \u0337\u0323\u030d \u0335\u033b\u030bI\u0334\u031d\u0313 \u0335\u033c\u030dW\u0338\u032d\u0315I\u0337\u031e\u034aL\u0338\u031f\u0357L` etc, that's almost thousand tokens and will cause a mess.",
    "y21-m11-d20",
    "module-discussion"
  ],
  [
    "As a monster fucker, it is such a huge pain to make the AI write sex between anything other than two humanoids or tentacles.",
    "Give 2nd person a try if you haven't. This may be one of the rare things that works better in that format.",
    "y21-m11-d20",
    "nsfw-discussion"
  ],
  [
    "",
    "I'd use some other brackets instead of telepathy <>s, maybe simply ()s. But this looks like it should work. (Yoink.)",
    "y21-m11-d20",
    "module-discussion"
  ],
  [
    "So how are we supposed to make lorebooks good without overwhelming the context?",
    "I generally put datablocks on top, then one verbose description at the end of the entry.",
    "y21-m11-d20",
    "novelai-discussion"
  ],
  [
    "Does bracketed terse text affect things?",
    "If there's too much of it, yes. But in case of []s, it takes a lot to overwhelm it.",
    "y21-m11-d20",
    "novelai-discussion"
  ],
  [
    "I still listen to eurotrash almost everytime I drive in a game, so whatever.",
    "...I listen to those while coding. <:shrug:332268181517238272>",
    "y21-m11-d18",
    "novelai-discussion"
  ],
  [
    "Well I can have info and such as well, but I have my old AID story with about 3000 steps in it that I want to continue - my question is is it worth getting 3000 steps and running it or should I just use Lore and default second person module?",
    "Modules are far better at things like generic themes and writing styles. For a specific adventure, chances are that module training won't 'grasp' much of it. Even at 100%.",
    "y21-m11-d18",
    "novelai-discussion"
  ],
  [
    "How many steps do you guys recommend for a coherent narrative when feeding it a piece of info? Also is there a way to format second person narratives like the novelAI second person module while using a custom module?",
    "For specific info? Modules aren't not really built for that, you'll get better results with LB.",
    "y21-m11-d18",
    "novelai-discussion"
  ],
  [
    "I'm try a fantasy name and make it a mundane modern life entry and see where it goes.",
    "Seems like AI just rolls with it. ```The wind was cool and refreshing as it swept past his face. He walked along the shoreline until he came upon a small restaurant. He entered and ordered an omelette. When the waitress brought it to him, she gave him a wink and a smile. Galdalf blushed slightly. He was not used to being flirted with by women.\nHe ate slowly, savoring every bite. After finishing, he paid the bill and left. He decided to walk back to his house. The night was young and he still had many things to do.```",
    "y21-m11-d18",
    "novelai-discussion"
  ],
  [
    "Hmm. Since using V4, Siggard just generated this character: \u2033. Never saw that before...",
    "Probably an uncleaned module. I've seen several that didn't properly replace the curlies.",
    "y21-m11-d18",
    "community-research"
  ],
  [
    "In Japanese lore Kobolds are dog people.",
    "Did some balancing for that in v4, actually. Some Japanese 'bolds got renamed 'cobold' (short for 'canine kobold' \u2014 still shares the same second token with 'kobold'.). Should be easier to get the AI to stick to specific type now. And the AI should no longer confuse the western kobolds with goblins.",
    "y21-m11-d17",
    "novelai-discussion"
  ],
  [
    "<@!227443534968520705> Easy way to remember -- Tablet, as in the stone tablets that people wrote in cuneiform on.",
    "That's what it is meant to be, but a lot of folks confuse it with tablet computers. Which should hold more than a mere scroll.",
    "y21-m11-d17",
    "novelai-discussion"
  ],
  [
    "I could only make AI describe it but not generate any lyrics.",
    "You can start a new row with `\u2003` (em space) to force v4 into generating lyrics. Much of the time, anyway. Might require a couple of retries.",
    "y21-m11-d16",
    "novelai-discussion"
  ],
  [
    "I tried ~~ first, then copying one of the shorter ones to ban that. Then I just banned the single, hoping that Tilde might be a token in itself...",
    "These are all different tokens: `~~~~~~~~~~~~~~~~`, `~~~~`, `~~`, `~`. You'll need to ban them all.",
    "y21-m11-d16",
    "novelai-discussion"
  ],
  [
    "ask <@!409511804293611530> how curated the dataset is",
    "Could be curated even more. I was careful not to prune too much, didn't want to go from 'too much futa' to 'futa doesn't work at all'. I'll keep on replacing bad ones with good for the future versions \u2014 now that I can actually see the results and how the balance turned out.",
    "y21-m11-d16",
    "novelai-discussion"
  ],
  [
    "Set up a quick espanso file for novelAI, includes em dashes, em spaces, asterisms, litRPG data blocks and an AN template. Triggers when you have a novelAI tab open and are using it but will also trigger on any window which has the text \"NovelAI\" so beware.",
    "Here's the same for AutoHotkey, for those who prefer that. (Well, almost the same. Used `[au` for the tagline.)",
    "y21-m11-d16",
    "feedback-discussion"
  ],
  [
    "You're probably better off with `***`. Double newlines can cause very weird generation",
    "Yep. Since there's none of those in the finetune, it'll be pulling from the base. Who knows what you'll get, but chances are that it won't be anything good.",
    "y21-m11-d16",
    "module-discussion"
  ],
  [
    "*suspicious glare*\n```\u2500 Name: Mukohda (Tsuyoshi Mukouda)\n\u2500 Age: 25\n\u2500 Job: Victim from Another World\n\u2500 Level: 17\n\u2500 HP: 184; Magic: 164; Strength: 160; Agility: 162\n\u2500 Skills: Sword Mastery 7;```",
    "If you don't want those, just ban `\u2500`. That symbol's not used for anything else.",
    "y21-m11-d15",
    "novelai-discussion"
  ],
  [
    "Gaming Industry became worse when it became a source of revenue for big companies, so they just focus on bringing in cash over quality of their games.",
    "Yep, certainly doesn't help that those companies gobble up all of the remotely successful smaller ones.",
    "y21-m11-d15",
    "novelai-discussion"
  ],
  [
    "I loathe the fact that Darkest Dungeon 2 is Epic Games exclusive.",
    "Oh, that's why I hadn't heard about it.",
    "y21-m11-d15",
    "novelai-discussion"
  ],
  [
    "It really shouldn't with how we've been smashing out the newlines. Especially with a \"list\" like this.",
    "Nothing that I've edited has linebreaks inside []s. Plus the pedias, at least, stopped functioning in my tests if I tried that. So wouldn't recommend it.",
    "y21-m11-d15",
    "community-research"
  ],
  [
    "The old structured formats are designed for squeezing out that extra bit of juice from an imperfect model. NAI however, has evolved beyond that proto-intelligence and is much more appropriately trained and designed for plain English world-building",
    "Yep, though there's a couple of supported 'formats' in NAI. Such as the LitRPG style. Just try something like this in AN... ```\u2500 Name: Zaltys\n\u2500 Gender: Male\n\u2500 Species: Gnome\n\u2500 Class: Alchemist\n\u2500 Skills: Alchemy (Rank 3), Chemistry (Rank 6)``` ...and see what happens.",
    "y21-m11-d15",
    "novelai-discussion"
  ],
  [
    "And you are telling me Top-K 1 is same with different nucleus? :L",
    "It's same in my tests. But I don't know exactly which settings\/module you're using, so can't compare 1:1.",
    "y21-m11-d15",
    "novelai-discussion"
  ],
  [
    "Okay so, NAI food challenge:\nAsk Sigurd for a recipe and cook it, first person to fucking die loses",
    "Sure, let's see what it comes up with\u2014 <:thonk:733040009136832642>",
    "y21-m11-d15",
    "novelai-discussion"
  ],
  [
    "Since when are names copyrightable?",
    "It's complicated. There are going to be issues if you try to publish a novel starring someone named Mickey Mouse.",
    "y21-m11-d14",
    "novelai-discussion"
  ],
  [
    "Is there any handy tool that can help speed up getting through formatting the text that just doesn't copy over well from PDFs?",
    "Calibre doesn't help with PDF conversions. If you absolutely have to convert something from PDF, try ABBYY Finereader. But depending on the PDF's formatting, it can range from slow-but-easy to utter nightmare.",
    "y21-m11-d14",
    "novelai-discussion"
  ],
  [
    "v4 + generation ship is definitely better at hard scifi.",
    "Good to hear. Hard SF was one of the major focuses for v4.",
    "y21-m11-d14",
    "novelai-discussion"
  ],
  [
    "Did a test of \"can the AI turn info dump lore into suitable text\" and well... It can. (*I do have more examples.*)",
    "Yep, some of the finetune data is formatted like that, so it's likely to work. I recommend experimenting with reduced linebreaks (`[ Constructor: Scuderia Ferrari ][ Construction Year: 2004 ]`) etc, might be even stronger.",
    "y21-m11-d14",
    "novelai-discussion"
  ],
  [
    "Should I strip out book tiles\/chapter headings when making a module?\nAlso, should I denote the end of a particular text in the module? I'm starting each with e.g. `[ Author: Beatrix Potter; Tags: Victorian era, United Kingdom, country living, mischievous, rabbits, garden, fable; Rating: G; Genre: Children's Stories, Fiction ]` but unsure if I need some kind of `[ end ]` tag between works.",
    "Strip them if it's just `Chapter 1` etc, square bracket them if it's something useful (descriptive titles, etc).",
    "y21-m11-d14",
    "community-research"
  ],
  [
    "So you guys think I should delete the older version of modules from the <#870449646391156776>?",
    "Maybe edit them so that they point to the newest version? So discord-links to the original still work.",
    "y21-m11-d14",
    "novelai-discussion"
  ],
  [
    "Here's the way it works. The AI sees there's a lot of brackets in the text it is being sent. \"Aha!\" it thinks to itself, \"I must generate a lot of brackets myself to follow the pattern!\" and it tries to do so. But oh no, all generations that contain the brackets are auto-blocked (since it's a banned token). When the most likely generation gets rejected, the AI resorts to the second most likely generation, and so on, until it finds an output that doesn't get blocked. This means that a lot of the AI's output becomes the AI's second, third, or tenth choice, and that means it's not as good.",
    "Usually not a concern. You can test it by disabling the bracket ban. []s don't leak if you switch to normal text in context.\nIn some cases v4 is taught by using datablocks. So those can work nicely in LB too.",
    "y21-m11-d14",
    "novelai-discussion"
  ],
  [
    "We need a NovelAI theme song",
    "Could always ask Sigurd to write one\u2014\n\u2014okay, never mind. It shills too much.",
    "y21-m11-d13",
    "novelai-discussion"
  ],
  [
    "Going by that logic, have they said anything about 20b? \ud83d\ude0f\ud83e\udd14or even making a bigger one.",
    "Yep. ```~20B is the next large model mark we hope to hit. Ideally before the heat death of the universe but no promises```",
    "y21-m11-d13",
    "novelai-discussion"
  ],
  [
    "All I want for Christmas is 22B ||And Folders||",
    "Eleuther hasn't said anything about 22B, so dunno why <#837402685824565278> is so obsessed with that. If anything, it'll be 20B.",
    "y21-m11-d13",
    "novelai-discussion"
  ],
  [
    "You're still an elf with no module",
    "Not surprised. The only Zaltys in the dataset is... https:\/\/forgottenrealms.fandom.com\/wiki\/Zaltys_Serrat",
    "y21-m11-d12",
    "novelai-discussion"
  ],
  [
    "100 examples of lore gen with default cross-genre and no module.",
    "```The king of Finland is no longer alive. His reign lasted almost 200 years.``` <:thonk:655176672345194527>",
    "y21-m11-d12",
    "novelai-discussion"
  ],
  [
    "What do I put for internal dialogue? Do I surround the text in <>",
    "If there's no actual telepathy or such, generally you should just leave those as is. `This is how internal monologue should be, I thought to myself.`",
    "y21-m11-d12",
    "module-discussion"
  ],
  [
    "I'm using the Cross-Genre module with Sigurd v4",
    "There's the problem. Using modules limits what the AI is likely to generate, and I doubt that cross-genre has much Spanish in it. Use `No Module` instead.",
    "y21-m11-d12",
    "novelai-discussion"
  ],
  [
    "<@409511804293611530>",
    "Fat chance. Snakes don't even have feet.",
    "y21-m11-d11",
    "novelai-discussion"
  ],
  [
    "I think Zaltys is going to be either like eh\/surprised or salty about this entry",
    "Nowhere near as salty as I expected to be.\nSigurd is convinced that I'm female, probably due to that one Forgotten Realms book...",
    "y21-m11-d11",
    "novelai-discussion"
  ],
  [
    "It brought up monsters in a police story, and swords in a zombie apocalypse story. <:think:855548448405061702>",
    "Well, there is some urban fantasy in there. And monsters + police are also common in horror.",
    "y21-m11-d11",
    "novelai-discussion"
  ],
  [
    "So now it outputs *this* shit instead.\n`Ann looks at Morten, who is looking down at his plate, eating slowly and carefully, as if he doesn't want to waste any of it.`",
    "v3 is not built for chat. I recommend waiting a week for v4.",
    "y21-m11-d11",
    "novelai-discussion"
  ],
  [
    "<@!409511804293611530> had some complains i think",
    "From what I remember, it made things like negative biasing `Gandalf` constantly output `Gandolf` instead, etc.",
    "y21-m11-d11",
    "novelai-discussion"
  ],
  [
    "Can you show a short example?",
    "Prompt: ```> Ann:  Hi.\n> Morte: ``` Output: ```Hey, Ann. What's up?\n> Ann: I'm in the middle of something right now, so could you give me a little later?\n> Morte: Sure thing. Sorry for interrupting your work. See ya!\n> Ann: Thanks.```",
    "y21-m11-d11",
    "novelai-discussion"
  ],
  [
    "Can we get a general overview of what was improved in the latest finetune? Without going into specific works, of course.",
    "The changes are too substantial to start listing them. Hundreds of hours of work on curating\/cleaning. A lot of additional fandom coverage. I'd estimate that the dataset is ~40% larger, with roughly 5% of lowest quality material replaced.",
    "y21-m11-d10",
    "novelai-discussion"
  ],
  [
    "Will V4 finally inherently know what NovelAI is now?",
    "Not too well. Some data was added, but clearly not enough. It might get it after a few retries, but not every time.",
    "y21-m11-d10",
    "novelai-discussion"
  ],
  [
    "from what i've seen it'll output japanese no matter what, so should be easy to notice at least",
    "Not always. Here's an example from my tests, when combining Genji with modules: ```This is the largest temperature difference that my sensitive thermometer measures. Hot places in hell must be hotter than this!!11!one hundred!!!!```",
    "y21-m11-d10",
    "novelai-discussion"
  ],
  [
    "<@!392308176957210624> we should really indicate which model it's on.",
    "Yeah, this is needed now that there's several. I can just imagine forgetting Genji on, then wondering why my next session is outputting gibberish.",
    "y21-m11-d10",
    "novelai-discussion"
  ],
  [
    "In the new finetune\/model, what is the standard for dinkuses?\n\nI assume *** with no line break after?",
    "`***\\n`, hasn't changed. I try to keep https:\/\/naidb.miraheze.org\/wiki\/Datasetting_for_AI_Modules up-to-date.",
    "y21-m11-d10",
    "community-research"
  ],
  [
    "So I've been messing around with the Text Adventure module. Is there a way to stop the AI from writing out actions for you?",
    "This would actually be relatively easy if the official module got retrained. Maybe in some future version... But until then, you can try banning `>`.",
    "y21-m11-d10",
    "module-discussion"
  ],
  [
    "Maybe they're secretive \ud83d\udc40\ud83e\udd71",
    "Eleuther is not associated directly with NAI to that level. If they release a larger model, it'll be public. And then it'll take several days for NAI to finetune the model.",
    "y21-m11-d10",
    "novelai-discussion"
  ],
  [
    "*Like 22 billion parameters*",
    "Have you heard about Eleuther releasing a '22B' model? If not, then it's _probably_ not that.",
    "y21-m11-d10",
    "novelai-discussion"
  ],
  [
    "only if its a new version of Siggy, it might be 'just' something like biases was, that you can slap on v3 (are we v3 or v2?) and it works its black magic",
    "The current one is v3. I know the numbering is confusing, but that's because Calliope is counted as a 'version'.",
    "y21-m11-d09",
    "novelai-discussion"
  ],
  [
    "\ud83d\udc40 Maybe if there's a list of text genres you want hunted for and cleaned you could post them somewhere",
    "And yes, there are genres that I'm not too familiar with. Could certainly use recommendations for suitable Slice of Life novels, etc.",
    "y21-m11-d09",
    "novelai-discussion"
  ],
  [
    "Even with the module training that people are doing?",
    "Nobody's thought to send any of those to us lately.",
    "y21-m11-d09",
    "novelai-discussion"
  ],
  [
    "\ud83d\udc40 Maybe if there's a list of text genres you want hunted for and cleaned you could post them somewhere",
    "Cleaned fandom content is always useful. Don't have time to go scraping wikis etc myself.",
    "y21-m11-d09",
    "novelai-discussion"
  ],
  [
    "Finetune team == Kuru's mturk \ud83d\ude42",
    "Minus pay.",
    "y21-m11-d09",
    "novelai-discussion"
  ],
  [
    "People keep saying Chris died but I haven't seen any proof",
    "https:\/\/media.discordapp.net\/attachments\/837402685824565278\/870045075688800266\/20210729_064811.jpg",
    "y21-m11-d09",
    "novelai-discussion"
  ],
  [
    "You can test it pretty easily with basic logic puzzles or just normal riddles that require reasoning and let me tell you, it SUCKS",
    "",
    "y21-m11-d09",
    "novelai-discussion"
  ],
  [
    "\"yeah dude that's my story *pile*\"",
    "Works for those of us who won't have time to sort through them. 'Just toss them on the pile...'",
    "y21-m11-d09",
    "novelai-discussion"
  ],
  [
    "Wait, what? \nModules are like a 100-arity vector of floats. Right? That's a ton of information.\nAlso, putting `[]` in your module... Why wouldn't that get picked up and associated. If `[X]` tends to have something different follow it than `X` shouldn't those `[` `]` influence the AI behavior?",
    "They likely have some influence, though without testing I couldn't say what kind of influence. In most of the source material, []s are followed by the beginning of a new chapter. So that may limit the usage.\nThough special characters can definitely be made stronger with modules. The `\u2500 ` LitRPG style doesn't work at all in v3, but the module I trained with that (https:\/\/discord.com\/channels\/836774308772446268\/870449646391156776\/881826911972634634) quickly picked up the style.",
    "y21-m11-d07",
    "module-discussion"
  ],
  [
    "For some reason|| `Rating: X` or `Rating: NC-17`|| always keep finding their way into my AN. <:meru_giggle:811491235498950676>",
    "I need to tag those more... They're used in a few files, but not to the level where it'd have a strong effect.",
    "y21-m11-d06",
    "community-research"
  ],
  [
    "In that example you'll want to stop around 500-750",
    "No, that's bad advice. Training to only 500 is generally a bad idea (unless you're on the tier where that's all you get), and interpreting the graph depends on how much data you used.",
    "y21-m11-d05",
    "novelai-discussion"
  ],
  [
    "```[ Author:; Tags:; Genre: ]\n``` is a decent AN boilerplate, just put in an author you want to emulate (in terms of style), a tag list, and a genre list like this\n```[ Author: Lewis Carrol; Tags: time travel, witches; Genre: High Fantasy ]```",
    "Yep. No spaces before the semicolon, though. That turns it into wrong token, making it weaker.",
    "y21-m10-d30",
    "novelai-discussion"
  ],
  [
    "Are en dashes on the nono list?",
    "Em dashes are fine, en dashes (if properly used) should only be used for ranges (numbers, dates.) Don't see them often, but they're not disallowed.",
    "y21-m10-d29",
    "module-discussion"
  ],
  [
    "Is there an automated tool that turns \n`\u2014 Spoken text`\nto `\"Spoken text\"`?",
    "Regex `^\u2014 (.*)$` to `\"$1\"`. Gonna break a few instances if there's lines like `\u2014 Spoken text, said character.`, though.",
    "y21-m10-d28",
    "module-discussion"
  ],
  [
    "When making a module should I put onomatopoeia in angled brackets? They often get written in italics but the guide I read says the AI won't recognize that, The guide also said that < and > work for nonverbal dialogue but I'm wondering if it can also be used for sound effects.",
    "`*Bang*` is the only style commonly used for sound effects. Typically they're in italics or bold in the source material, but since those get stripped from txt format... <:shrug:332268181517238272>",
    "y21-m10-d28",
    "novelai-discussion"
  ],
  [
    "Idk, but **if** it was, I would buy it",
    "This. Good ones are hard to find. Cheap microfiber just tends to smudge stains more. Back when I used DSLR cameras, finding a good cloth for cleaning the lens was a challenge.\nThe so-called 'premium microfiber cloths' you find on Amazon for $1.50 are crap, you're better off using your sleeve.",
    "y21-m10-d21",
    "novelai-discussion"
  ],
  [
    "<@!147633390223491072> I highly recommend using this: https:\/\/ermela.net\/dumb-reformatter\/",
    "This formatter has issues. I wouldn't recommend it.\n```str = str.replaceAll(\/ +([,!])\/g, \"$1\"); \/\/ remove whitespace preceding a comma or bang``` ...may _seem_ safe, but occasionally there are things where even that should be kept: ```- I barely had time to write ? on my board\n- Cylon bowed deeply, causing a golden ! to appear over his head.\n- There are 26 Latin alphabet characters, plus ? (question mark) and ! (exclamation mark).```\nWhereas this...\n```str = str.replaceAll(\/^[^a-z0-9]+$\/gm, \"***\"); \/\/ replace fully-non-alphanumeric lines with chapter breaks``` is more problematic. This causes misfires in about half of the works that I checked. It erases everything from lines like `\"I\u2014\"` (making dialogue out of sync, causing the AI to associate speech styles with wrong characters), AI\/robot-style dialogue (`YOU SEE THIS, RIGHT?` - don't even think about running this on Terry Pratchett), shouting (`\"GODDAMN!\"`), newspaper headlines, sign text, etc. Not only you lose those, but also end up with way too many `***`s.",
    "y21-m10-d20",
    "module-discussion"
  ],
  [
    "Quick question; when cleaning module data, how important is it to replace single-line chapter titles with subsequent titles on the next line:\n```Chapter 1\nMay I Go to a New World With This Self-Proclaimed Goddess!```?\nI noticed that for my other modules, after I removed all instances of numbered `Chapter n` and replaced them with dinkuses in the traning data, Sigurd would add its own `Chapter n` in the output anyway. Possibly because the second line strongly implies a preceding chapter number.",
    "This is unlikely to happen in next versions. v3 simply wasn't fully cleaned.",
    "y21-m10-d16",
    "community-research"
  ],
  [
    "Time for the poor man's module: `[ Genre: hard sci-fi.]` in the AN.",
    "Try `hard SF`. That spelling is more common.",
    "y21-m10-d16",
    "novelai-discussion"
  ],
  [
    "if i get discord nitro and make an emoji with that name, will it transform?",
    "Nope, just tested that. Renaming them doesn't break old ones either.",
    "y21-m10-d15",
    "novelai-discussion"
  ],
  [
    "Do you know how many times sigurd given me word 'erected penies' when someone comforts dying man in the bed",
    "Come to think about it, I wonder if some of the old 'classics' are to blame.```\u201cMy dear Holmes!\u201d I ejaculated.``````So he sat as I dropped off to sleep, and so he sat when a sudden ejaculation caused me to wake up,```",
    "y21-m10-d14",
    "nsfw-discussion"
  ],
  [
    "There's errors so it has to be something, and if the data is perfectly clean, what other possibilities exist? Could always test the theory and pad it out to see if it's resolved. Only 300 steps.",
    "Like I've said before, it's pretty much guaranteed to happen on less than 500 steps.",
    "y21-m10-d13",
    "module-discussion"
  ],
  [
    "i only slept for 6 hours after not sleeping for 40",
    "Please don't die.",
    "y21-m10-d13",
    "novelai-discussion"
  ],
  [
    "It could also mean you didn't clean it enough",
    "No, that sequence specifically means that you didn't train it enough.",
    "y21-m10-d13",
    "module-discussion"
  ],
  [
    "I actually am a professional UX designer and assure you these are not the only two choices here \ud83d\ude42",
    "As long as things like Bias will be easily accessible from the sidebar or such (instead of hidden in some popup), I'll be happy. Just adjusting the keyword bias for `kobold` LB entries in my yesterdays test annoyed me to the point that I don't feel like using it anymore; wasted too much time bouncing between LB and the game itself. `Adjust values, close window, test, open window, adjust values... (x50)` Gnn.",
    "y21-m10-d12",
    "feedback-discussion"
  ],
  [
    "How much horny is in crossgenre?",
    "Wait, Sage never revealed the contents? Forget I said anything, then.",
    "y21-m10-d12",
    "novelai-discussion"
  ],
  [
    "I think that's what happens when you train a module on too little data",
    "Yep. Not enough data for training. Coincidentally, ` !\"#$%&'()*+,-.\/` are the first characters in ASCII. Training on less than 500 steps is generally a bad idea, there's a reason why recommended range is 2000-3000 steps.",
    "y21-m10-d11",
    "novelai-discussion"
  ],
  [
    "Is it possible to just add a space after it? Or is that stupid because most tokens begin with one?",
    "Not sure what effect that'd have. ` ` token on its own is rarely used, as you said space is usually part of the following token.",
    "y21-m10-d09",
    "novelai-discussion"
  ],
  [
    "He asked for a broad range, all other modules are focused on one thing to the detriment of others.",
    "And like I said, cross-genre is bad for broad range. It'll gravitate towards vanilla mf, and heavily overuses adjectives like 'beautiful'. Also heavy focus on concubines and angels. Good if those are your kinks, bad if they're not.\nFor actual broad range, I'd recommend either 'No Module' with biases, or some cross-kink style module.",
    "y21-m10-d09",
    "nsfw-discussion"
  ],
  [
    "default cross genre",
    "Really? In my experience cross-genre is bad for most nsfw things except for vanilla mf. ||It certainly can't handle my kinks.||",
    "y21-m10-d09",
    "nsfw-discussion"
  ],
  [
    "Anyone find any more neat tricks for phrase bias?",
    "This one's kind of obvious and probably already known, but... Add a minimal negative bias to {.} to make sentences longer. Or positive bias to make them shorter (dunno why you'd want that.)",
    "y21-m10-d07",
    "novelai-discussion"
  ],
  [
    "is there a good module for stories set in VR?",
    "My LitRPG module might work. It was done as a test, but got decent feedback - https:\/\/discord.com\/channels\/836774308772446268\/870449646391156776\/881826911972634634\nAnd now that bias is implemented, adding a bias of 0.05 for {\u2500} keeps it from straying from the format. Though it may be _too_ MMORPG for some tastes. ```\u2500 You have defeated the Minotaur.\n\u2500 You have acquired: A bronze-colored belt, a small bag of gold coins, and an elven staff with a white crystal in its head.\n\u2500 Your total experience has increased by 575 points.\n\u2500 Your skill level for 'Weapon Proficiency' has increased by 1 point to 10.\nI was feeling pretty good about myself. I had been able to defeat a Minotaur without taking any damage and it didn't even cost me any mana! And the skills were going up at a steady rate!\nI picked up the belt and tried using <Analyze> on it. The results were as follows:\n\u2500 Bronze Belt (Type: leather)\n\u2500 Level 1; +1 Strength, +1 Agility, +2 Stamina, +3 Magic Resistance```",
    "y21-m10-d07",
    "module-discussion"
  ],
  [
    "Didn't AID's Worlds have such a strong Railroad effect? <:think:855548448405061702>",
    "Nah. They barely even came up, as the keywords were unlikely to trigger on their own.",
    "y21-m10-d07",
    "novelai-discussion"
  ],
  [
    "Lol no chance with new chinese law it gonna get worse",
    "How is banning them going to make mining worse?",
    "y21-m10-d06",
    "novelai-discussion"
  ],
  [
    "Still not working on brave <:sadness:714562831780937780>",
    "Works fine on mine...",
    "y21-m10-d06",
    "novelai-discussion"
  ],
  [
    "pretty much. previously you could really only BAN words entirely.",
    "Yeah, and this does kind of make banning redundant. Since -2 is so strong that it acts like a ban.",
    "y21-m10-d06",
    "novelai-discussion"
  ],
  [
    "Now make it not write like a horny 14 year old",
    "That'll need to wait until the next version.",
    "y21-m10-d05",
    "novelai-discussion"
  ],
  [
    "Just move to a country where you can break your nda <:thinkk:846994403381739600>",
    "I'm not even sure if the nda is binding since they failed to actually pay me.",
    "y21-m10-d05",
    "novelai-discussion"
  ],
  [
    "I never realized how incompetent the AID devs were until I saw NAI's progress",
    "Being a tester, I figured that out earlier. Which is why I was so cranky on AID from November onwards. Shame about the NDA, can't give any details.",
    "y21-m10-d05",
    "novelai-discussion"
  ],
  [
    "can confirm, bru was on my (very) short shit list the first couple of days (before I was mod)... felt way too much like he was trying to treat NAI as a Typical Venture Capital Business and not as the opportunistic refuge for victims of an anti-smol filter that it is... ditto CN",
    "I am glad it got sorted out so quickly. I came here after the AID mess, and then saw mods and devs talking about how NAI will never allow 'some things'. ...almost quit right then and there as the first impression didn't make NAI seem any less censored, but then they got kicked off. <:shrug:332268181517238272>",
    "y21-m10-d05",
    "novelai-discussion"
  ],
  [
    "wtf is that symbol, Sigurd?",
    "Occasionally used in footnotes. Some slipped in v3, but they should be gone by the next version.",
    "y21-m10-d04",
    "novelai-discussion"
  ],
  [
    "I suspect it's multiple epochs. Dunno without knowing coverage, though.",
    "That doesn't result in that kind of pattern, at least not as far as I've seen. All the data's already in there at 100%, there shouldn't be sudden jumps after that. Anything overtrained tends to be very smooth after 100%.\nThat kind of sawtooth pattern is something that I'd expect from... dunno, trying to train with different programming languages.",
    "y21-m10-d01",
    "community-research"
  ],
  [
    "Well, the graph can give you hints about data, as well. The one above points at a varied dataset.",
    "Yeah... and generally there shouldn't be that large spikes that late in training. Indicates that some of the data might be badly matched to the rest.",
    "y21-m10-d01",
    "community-research"
  ],
  [
    "More like an aged hooker, with how scratchy those things go sometimes",
    "If that's VHS, then what's Betamax?",
    "y21-m10-d01",
    "novelai-discussion"
  ],
  [
    "does it philosophize and contemplate navels about nihilism too? might be up to my speed then",
    "```Life is like``````Life is like a box of chocolates. You never know what you're gonna get until it's in your mouth and all that remains are the seeds. The trick to living life is not letting those seeds grow into bitter roots. But sometimes, if you don't want them to sprout at all, you have no choice but to bury them deep within yourself. And sometimes, when the roots begin to spread out from their dark places, they can take over everything else. Life becomes a prison. It becomes an endless cycle of suffering. Sometimes you just need to break free. To leave it all behind. Because even though you might be miserable right now, there will always be another chocolate on the way. Another moment of blissful ignorance. So go ahead and dig up your roots. Just make sure you do it soon before they choke off every last bit of light in this world.```",
    "y21-m09-d29",
    "module-discussion"
  ],
  [
    "dw zalty if I need more mods you are on the list",
    "Nah, I meant that this works fine. Belverk's the lead of the Finetune team, so the current order is optimal.",
    "y21-m09-d29",
    "novelai-discussion"
  ],
  [
    "fixed \u2764\ufe0f",
    "Thanks...? I'm still listed under primary group Scholar as far as I can see, though.",
    "y21-m09-d29",
    "novelai-discussion"
  ],
  [
    "but yeah, scraping it and extracting *only* the paragraph we want would be extremely difficult, like developing a parser from scratch and making sure it actually hooks with the site properly tier",
    "Right... I did that manually for Pokemon, and it did take a while. Not gonna repeat that for Digimon (at least not until Pokemon pedia is fully complete), so someone else will have to do that if they want Digimon data in.",
    "y21-m09-d29",
    "novelai-discussion"
  ],
  [
    "More material not necessarily a huge priority. Where do we go scrape next after all of goodreads discovery is exhausted? Scraping wikis? I could get back into that, but it kinda sucks with all the tools I know of.",
    "That's exactly what I'd like to get as user contributions. Well formatted wiki scrapes, etc. Though that may be too much to hope for.",
    "y21-m09-d29",
    "novelai-discussion"
  ],
  [
    "a bit of weirdness from when the researcher role was introduced (in the same token it'd be good if finetune role overrode the color) plus this red just looks cool",
    "Finetune rank doesn't even get listed. My highest rank on the user-list is... Scholar. <:kek:594643029994897408>",
    "y21-m09-d29",
    "novelai-discussion"
  ],
  [
    "I'm looking for short stories or novels that involve A) aliens helping Humans B) helpful AI\/robots as opposed to 'destroy fleshy' types C) preferably with natural disasters, industrial accidents, or misunderstandings\/ignorance at the root of the narrative's conflict\/struggle with awareness\/understanding coming about in the resolution.",
    "- Sector General series by James White. About a hospital station. Plenty of benevolent aliens, though most protagonists are human.\n- Wayfarers series by Becky Chambers. \n- Humans Are Weird by Betty Adams. Not exactly what you're looking for, but... plenty of 'misunderstandings'.\n- Some parts of the Callahan's Crosstime Saloon series by Spider Robinson qualify, though that's a lot more 'grounded' than most scifi. As the main setting is a bar.\nThen there's some Star Trek novels that fit (Uhura's Song, for instance), but I can't think of anything else to add. Surely there's gotta be more... There's a lot of books about humans allying with aliens of course, but it's usually against the threat of some other alien species. Natural disasters and such? Rare.",
    "y21-m09-d29",
    "module-discussion"
  ],
  [
    "Very interesting, but seems like a slightly different premise. My protagonist is a little brain in a jar with tiny robot legs who leaves the security of her home underground lab to find out what happened to the rest of the human race.",
    "Escape by Isaac Asimov. Though that's a short story, iirc.",
    "y21-m09-d27",
    "module-discussion"
  ],
  [
    "Wonder how much now",
    "I don't have the numbers either.\nBut while I know that Alexa isn't exactly _reliable_, this doesn't look too shabby.",
    "y21-m09-d27",
    "novelai-discussion"
  ],
  [
    "20 books by Akira Himekawa if one also includes the Twilight Princess novels.",
    "Huh? But those are all manga...\nAnd Hyrule Historia is nearly unusable due to being graphics-heavy pdf that is guaranteed to convert badly unless you do it by hand.",
    "y21-m09-d26",
    "module-discussion"
  ],
  [
    "That list aint well tested, i know the creator",
    "It does have a lot of extras, but some of the bolded ones match our internal tagging. Though it's also missing some...",
    "y21-m09-d25",
    "nsfw-discussion"
  ],
  [
    "But what could the Mercantile Wolf Girl Romance be based on? <:cry:837394871672111124>",
    "Let's say that it is based on fanfiction.",
    "y21-m09-d25",
    "novelai-discussion"
  ],
  [
    "They could just give us Amazon links to all the books per module",
    "Not going to happen.",
    "y21-m09-d25",
    "novelai-discussion"
  ],
  [
    "I really hope then that Latitude was half assed enough to have 1\/3rd of their dataset be duplicates then",
    "I remember seeing some stories thrice in there. (No wonder they got overtrained.)",
    "y21-m09-d25",
    "novelai-discussion"
  ],
  [
    "It was a joke.",
    "Such jokes tend to get taken out of context.",
    "y21-m09-d25",
    "novelai-discussion"
  ],
  [
    "Wait, is that really going to be a thing?",
    "See https:\/\/discord.com\/channels\/836774308772446268\/877268798409953370\/883046452815867994\nAnd by long term, he means _long term_.",
    "y21-m09-d25",
    "novelai-discussion"
  ],
  [
    "But we have the text adventure module that adds the special feature of..... oh... now I'm confused... how would you add that feature to this module?",
    "Any module that's planned to be used in the text adventure mode should include the `> You <action>` lines. Which Latitude's finetuning data does have. Removing those would make it less suitable for that mode.",
    "y21-m09-d25",
    "module-discussion"
  ],
  [
    "The AiD finetune is a 30mb .txt file",
    "Much of the content is in there twice, or even thrice. 'course, pruning the dupes out would be a major task.",
    "y21-m09-d24",
    "module-discussion"
  ],
  [
    "Is it based off AiDs finetune or is it literally their finetune?",
    "Literally their finetune. With all the Kyros, Count Grey, and other NSFW bits intact.",
    "y21-m09-d24",
    "module-discussion"
  ],
  [
    "There is a module on aids finetune?",
    "'Mormon' on rentry. And it should be possible to enable the text adventure mode in it with the usual trick.",
    "y21-m09-d24",
    "module-discussion"
  ],
  [
    "Too many of those",
    "Will be heavily standardized in future versions. Then `***` should be only common one left in the data. Though rarer ones may still occasionally leak from the Pile itself.",
    "y21-m09-d23",
    "novelai-discussion"
  ],
  [
    "My Sigurd seems to be determined to resurrect the space pirate who died a gory death as stated in his LB.",
    "Try putting the `X died in <details>.` on a separate row, right after the main entry. Tends to work for me.",
    "y21-m09-d23",
    "novelai-discussion"
  ],
  [
    "I wanted to ask earlier but I felt I would sound really dumb....\n||I like the idea of themed modules, such as the Dragons and Rats module, and I'm curious how those where trained. I think it was the 5 mb at 50% training but I wanted to ask.||",
    "Rats was actually trained quite high. 5000 steps, around 80%. Should've had more content for it, but those were early days. ...kind of surprised that it turned out to be one of the better modules.",
    "y21-m09-d22",
    "module-discussion"
  ],
  [
    "Huge swaths of wall o' text? Well after a little nudging, you can get paragraphs back quite easy.",
    "It can be nudged, but I'd expect there to be lasting influence if lorebook entries keep popping up.",
    "y21-m09-d20",
    "community-research"
  ],
  [
    "I fix them, if I have a `...` followed by a letter, I replace with `... `",
    "Unless it's at the beginning of the sentence, I hope.",
    "y21-m09-d20",
    "module-discussion"
  ],
  [
    "I strongly feel like really written out lorebook entries and long paragraphs with very few linebreaks and no full linebreaks is far superior to anything I've done so far",
    "I'd agree. The AI does tend to copy the style used, after all. Long prose in notebooks generally makes the output longer too. Which is what I'd prefer over short LN-style outputs.",
    "y21-m09-d20",
    "community-research"
  ],
  [
    "Well I assumed he meant that the finetune data already has plenty of `\"Stuff...and things.\"` in it.",
    "Not a lot. `\"Stuff . . . and things.\"` was common, which gets automatically cleaned to `\"Stuff... and things.\"`",
    "y21-m09-d20",
    "module-discussion"
  ],
  [
    "Do you consider things like `\"Are you...serious?\"` valid?",
    "Not proper usage of ellipses, but far too common (especially in fanfiction and light novels) to do anything about. If we started to manually fix those, we'd spend the rest of our lives on that.",
    "y21-m09-d20",
    "module-discussion"
  ],
  [
    "And what about spaces after ellipses?",
    "What about them? There's too many different cases to list them all. Generally the space should be left if it precedes a new sentence (unless at beginning of a new row), but removed in cases like `... \"`, `... ?`, etc.",
    "y21-m09-d20",
    "module-discussion"
  ],
  [
    "`... ` I have that in many of my txt documents <:nakkiHm:814619451244675093>",
    "Can't be automatically replaced due to differing usages. Empty spaces at the end of the rows get stripped, of course.",
    "y21-m09-d20",
    "module-discussion"
  ],
  [
    "It's a single unicode symbol for an ellipsis.",
    "There's no reason to replace  `\u2026`, they're single token and less likely to cause problems than `...` which occasionally get followed by trash characters, or more ellipses.\n\nIf it were up to me, we wouldn't replace the 'fancy' quotes either. Having different characters for starting and ending the quote would be useful. Such as with logit bias, to make dialogue less common by reducing the instances of `\u201c`.\nWhereas when those are converted to `\"`, you can't do the same without having the side effect of characters making long monologues once they finally start talking.",
    "y21-m09-d20",
    "module-discussion"
  ],
  [
    "I never got to experience prime Dragon, so reading excerps like this is such a treat",
    "There was also this instance where I played as a mage and cast a mouse-tornado: ```The tornado bursts forth. The hundreds of squeaks form a single roar of unearthly sound, which blows the mice forth. They tumble through the air, spinning like tiny tops. They hit the mercenaries with a fury of claws, biting and scratching.\nThe rats are upon them, tearing them apart. The mercenaries struggle to fight off the tiny beasts. One loses a finger to a mouse's teeth, before smashing it against the wall in rage only for two more to tear out his eyes. They're drowning them, swarming over them like an army of lemmings, millions strong.\nThe mouse-rain swirls around you, not a single one touching you. You are the eye of the storm. The whirlwind of claws and teeth moves with your will, obeying your commands as you pick off the stragglers.``` Yep, let's just say that early Dragon was great. Shame that it got ruined.",
    "y21-m09-d19",
    "novelai-discussion"
  ],
  [
    "`<em>` replace with `<` and `<\/em>` replace with `>`? I suppose <:nakkiHm:814619451244675093>",
    "Might work for shorter stories, but rarely works for anything longer.\nIf only authors used _italics_ only for telepathy and internal dialogue... But most of them (so far all that I've seen) combine that with regular use of italics, and sound effects.\nSo by mass-replacing <em>, <i> etc, you end up with:\n- '_Why_ did _I buy that?_' -> `<Why> did <I buy that?>`\n- \"Why _did_ you buy that?' -> `\"Why <did> you buy that?\"`\n- 'There was a loud _crash_' -> `There was a loud <crash>`\nAdditionally, the italics spacing is often off, resulting in a lot of `< `, ` >`,  ` >!`, etc with automatic conversion.\n\nWhat I usually do is replace those in Calibre, then manually check the results once converted to txt. But it takes a lot of work per book. Some authors, such as Marc Secchia, use those 4000+ times per book.",
    "y21-m09-d19",
    "module-discussion"
  ],
  [
    "I'm surprised Style and other Keywords like Biome and Theme and Tone and Setting and pairings work quite well actually in authors note.",
    "Biome and Setting are in the finetune. Former for Tabletop RPG content and Pokemon, etc.",
    "y21-m09-d17",
    "community-research"
  ],
  [
    "It knows about Covid",
    "Yep. Finetuning team doesn't overlook new books, and Covid's been kind of influental recently.\nhttps:\/\/i.gr-assets.com\/images\/S\/compressed.photo.goodreads.com\/books\/1591543383l\/53883148._SY475_.jpg",
    "y21-m09-d17",
    "novelai-discussion"
  ],
  [
    "Where can I find that Pokemon pedia file?",
    "Like I said in the dm, not sure why you'd want it. It's too large to be used for modules by now. But okay, sent.",
    "y21-m09-d16",
    "community-research"
  ],
  [
    "Would that be because the AI is reading \"Finland Capital = X = Capital Finland\" and it ends up just outputting the last of its logic train.",
    "Maybe from something like `Helsinki, the capital of Finland is Finland's largest...`",
    "y21-m09-d16",
    "novelai-discussion"
  ],
  [
    "So, 0.992 is like a \"thin\" slice off.",
    "It's worth noting that it's rarely the 'worst' slice, though. Some of the worst generations can be pretty high. For instance, I remember `'Finland'` being high on the list for `The capital of Finland is ___`.",
    "y21-m09-d16",
    "novelai-discussion"
  ],
  [
    "closely matches how we use `;`",
    "Who's 'we'?",
    "y21-m09-d13",
    "module-discussion"
  ],
  [
    "What are questionable images in you guy's opinion",
    "`Questionable` rating on most boorus is for nudity and such, without explicit sex. Tame pinups, etc.",
    "y21-m09-d11",
    "nsfw-discussion"
  ],
  [
    "Finetuning?",
    "Yep. My main job is collecting and cleaning material for the dataset, so we have something to use for building models.",
    "y21-m09-d10",
    "novelai-discussion"
  ],
  [
    "Should I put that in the wiki?",
    "I don't actually have editing permissions for the wiki, so sure. There's a few other things I've been meaning to fix too, but don't remember them offhand.",
    "y21-m09-d10",
    "novelai-discussion"
  ],
  [
    "But is there a curated list? Or at least some ordered compilation? Browsing prompt sharing is kinda unwieldy \ud83d\ude06",
    "Yep. Even with the slow mode enabled, some users still post massive walls of text. Makes it hard to browse it. Module sharing wasn't really meant for that, only for sharing modules. <:shrug:332268181517238272>",
    "y21-m09-d09",
    "novelai-discussion"
  ],
  [
    "~1.7mb of mostly battle scenes and a bit of loosely related content done now.",
    "There's a lot of Battletech in the base (maybe too much, as mechs tend to leak to other content...), so you likely won't need much to make a module work.",
    "y21-m09-d07",
    "module-discussion"
  ],
  [
    "<@!409511804293611530> What do you use for multi-columns?\n\n```\nLCT-1V LOCUST\n\nis further hampered by its lack of hands, a distinct disadvan-quickly outmaneuver the planet's defenders at the Wuhan LIGHT ' MECHS\n\ntage in physical combat.\n\nPass and on the Wagnall Plains. His scouting efforts were As speed is one of its major assets, the LCT-1V is often also instrumental during the capture of New Derry. On New placed where the front is fluid, as it is quick enough to Aberdeen, the First further benefited from Ferman's efforts respond to possible enemy breakthroughs. More often, when he led his lance to the militia's field headquarters.\n\nhowever, the Locust must fight a holding action until larger, better equipped 'Mechs can arrive. It is usually deployed in Lieutenant Martha Maveries: Lieutenant Maveries is groups that have the ability to encircle opposing 'Mechs.\n\ncurrently assigned to be recon lance of the 32nd Lyran\n\n\n\nGuard's support regiment. Maveries is a tail, thin woman Deployment\n\nwhose cheeks are scarred heavily from a childhood accident Present in significant numbers in every BattleMech-\n\n. She pilots a Locust named The Stomper after her actions equipped military force known to man, Locust s are pro-in a battle in the city of Shull on the planet Alexandria. In Mass: 20 tons\n\nduced by nearly a dozen factories. They are particularly that engagement, Maveries became famous for stepping Chassis: Bergan VII\n\nprominent in the armies of the larger Periphery states, on small hovercraft and other vehicles defending the city.\n\nPower Plant: LTV 160\n\nwhere the LCT is a significant fraction of their limited Cruising Speed: 86 kph\n\nBattleMech production capabilities. Popular among mer-MechWarrior George McPhearson: Attached to House Maximum Speed: 129 kph\n\ncenary units for their relatively low cost and wide availabil-Davion's Capellan March Militia, McPhearson commands Jump Jets: None\n\nity of parts, the Locust is also a prominent component of a light recon unit in the regiment. He has turned down Jump Capacity: None\n\ncorporate defensive forces and militias.\n\nseveral opportunities to pilot larger 'Mechs in favor of his Armor: StarSlab\/1\n\nLocust, Wanda's Wonder, which is named after his sister, a Armament:\n\nVariants\n\nMechWarrior lost in the battle for Hoan . He never refers 1 Medium Martell Laser\n```",
    "ABBYY Finereader, with a lot of manual polishing.",
    "y21-m09-d07",
    "module-discussion"
  ],
  [
    "Not even for making the AI mention stuff more consistently?",
    "Not as far as I've seen. Though these days I spend far more time editing than testing.",
    "y21-m09-d06",
    "community-research"
  ],
  [
    "Oh yeah I read all the guides and spent 3 hours formatting",
    "At this point, I've manually cleaned 4.90GB of material. You can imagine how long that's taken...",
    "y21-m09-d06",
    "community-research"
  ],
  [
    "Does anybody know if there's a superhero module? Tried to find it myself through search but there's alot of unrelated stuff in discord",
    "There's an official one. Though I haven't seen any feedback about whether it was any good...",
    "y21-m09-d06",
    "novelai-discussion"
  ],
  [
    "Now I HAVE to know",
    "https:\/\/preview.redd.it\/rk05vquhz5x31.png?width=1024&auto=webp&s=402a6b36c39caeccdd6c77c403a0dd919e927758",
    "y21-m09-d05",
    "novelai-discussion"
  ],
  [
    "what's sparkledogs?",
    "You're better off not knowing.",
    "y21-m09-d05",
    "novelai-discussion"
  ],
  [
    "honestly, most OC are fuck awful for that reason",
    "I mean, even 99% of furries agree that sparkledogs are awful.",
    "y21-m09-d05",
    "novelai-discussion"
  ],
  [
    "Gen 8 had Cinderace",
    "Obstagoon and Inteleon too.",
    "y21-m09-d05",
    "novelai-discussion"
  ],
  [
    "at least even modern pokemon games have better design policy than your average furry oc",
    "Hasn't stopped them from adding some stupid designs. Still, as was said, Pokemon has 'something for everyone'. Which explains part of the popularity.",
    "y21-m09-d05",
    "novelai-discussion"
  ],
  [
    "The game looks interesting",
    "It's also infinitely moddable. On best days, I ran Rimworld with 120+ mods at once.",
    "y21-m09-d05",
    "novelai-discussion"
  ],
  [
    "Since I've never used the regex feature it will take me a while to find it.",
    "Ctrl + Shift + F, `^$\\r?\\n` in Find, with-- yeah, that.",
    "y21-m09-d05",
    "module-discussion"
  ],
  [
    "I have reached a milestone of having collected over 1mb of pre-TMP Star Trek novels and Novelizations for the Star Trek TOS (Pre-TMP) Module.\n\nIn short, I now have a small dataset. Unfortunately I only just now realized that there should be no empty lines in the .txt files. Meaning the files I thought where cleaned up- are not. I still had paragraphs separated by a blank line.\n\n||No empty newlines between paragraphs (ie. double spacing). If desired, you could leave a single empty newline between chapters as a chapter break, but it is instead recommend that you leave only *** on its own newline between chapters (replacing the chapter title).||",
    "If you have a lot of them and you're on Windows, you can regex multiple files with Notepad++ etc. Probably faster than via the formatter.",
    "y21-m09-d05",
    "module-discussion"
  ],
  [
    "My module is nothing but very specific dialogue from a video game, and it's only 10kb big.",
    "You can't effectively turn 10kb of data into 200kb (module size)... ||Okay, it's more complex than that, but I'd say that 10kb is too small regardless.||",
    "y21-m09-d05",
    "module-discussion"
  ],
  [
    "Though I imagine this channel will still get use from such NovelAI related questions as;\n\n\"Can anyone recommend some Human x Alien romance with a focus on physical differences during intercourse? I'm training a module for Xenophiles.\"\n\nI do believe that is the content expected to be present here.",
    "Yes, such questions are probably best asked here. Not everyone has time to actively follow multiple discords.",
    "y21-m09-d05",
    "nsfw-discussion"
  ],
  [
    "I can probably do something about that",
    "Please do. That's by far most annoying thing about NAI at the moment. I have to constantly fiddle with the mouse position to make the tooltips go away, so I can see what got generated.",
    "y21-m09-d04",
    "novelai-discussion"
  ],
  [
    "Correction, it's 102MB but yeah it's a scrap of a fanfiction website that I ran through a formatter to clean it up. I had a pretty lengthy Q&A with a few knowledgeable users on here last night and they pretty much told me I wouldn't typically need more than a few thousand steps at most to train a single module.",
    "Considering the size of an average fanfic, that's probably something around 1500 stories. You seriously cleaned that many?",
    "y21-m09-d01",
    "module-discussion"
  ],
  [
    "like who does that, if you're rock hard you would want to keep it in and keep going instead of taking a random pause",
    "v3 likes to pull out to change positions, but I haven't seen random pauses. <:thonk:655176672345194527>",
    "y21-m09-d01",
    "nsfw-discussion"
  ],
  [
    "how is the speed?",
    "Queue long, training short. I stepped away for a minute and it went from 'waiting for the queue' to 'finished'.",
    "y21-m09-d01",
    "module-discussion"
  ],
  [
    "https:\/\/tenor.com\/view\/well-yes-but-actually-no-well-yes-no-yes-yes-no-gif-13736934",
    "Well, okay. Calliope's still there. But I can't think of any reason to use that model now.",
    "y21-m09-d01",
    "novelai-discussion"
  ],
  [
    "From memory there were some doubts 2k context would be any good during alpha",
    "Not surprising, considering that AID couldn't even remember things up to 1k. But NAI's recall does work all the way up to 2k, so the difference between 1k and 2k is massive.",
    "y21-m09-d01",
    "novelai-discussion"
  ],
  [
    "How do you guys feel about modules trained on fanfiction?",
    "Be careful not to overtrain OC names. Other than that, no major issues that I can see.",
    "y21-m09-d01",
    "module-discussion"
  ],
  [
    "If you're training anything above ~3000 steps you're probably wasting steps as it is.",
    "Unless you're training something like 5MB of Pokemon data, and want all of it to be included. Which you probably would, since otherwise some species get randomly dropped.",
    "y21-m09-d01",
    "module-discussion"
  ],
  [
    "In the effing suggestions channel?",
    "Yeah, something to keep in mind the next time anyone comments in <#837077266918932512>. That channel's strictly for suggestions, keep discussion here. Not pointing any fingers, but... <:thonkPOP:692918982922993774>",
    "y21-m08-d31",
    "feedback-discussion"
  ],
  [
    "What books would be a good feed for say a WW2 or American Civil War module?",
    "Sven Hassel for the former. <:why:787881658660814858>\n``` Ever since his first published novel in the 1950s, Sven Hassel saw the entire Eastern Front and a lot of places of the Western one as a Wretched Hive, where most of those involved, from ordinary rifleman to General, didn't shy away from robbery, murder, ****, torture, or all of them together.```",
    "y21-m08-d30",
    "module-discussion"
  ],
  [
    "So <> is telepathy? Is there a list of what different symbols do or are usually used for in the data?",
    "`[text]`: Metadata\n`<text>`: Telepathy and other nonverbal communications (weak in v3)\n`\u2500 text`: LitRPG data blocks (not in v3; and not to be confused with a dash.)\n`> text`: Occasionally used for computer output, etc. Might need to be rethought now that text adventures uses it too.\nThat's all standardized styles for now.",
    "y21-m08-d29",
    "module-discussion"
  ],
  [
    "`\u3010` `\u3011` I've seen this quite a few times too <:nakkiHmSherlock:631005691305525258>",
    "Those'll likely stop working in next versions, as they've been mostly replaced with the `\u2500` style.",
    "y21-m08-d29",
    "module-discussion"
  ],
  [
    "Formatting that LitRPG module, decided on `<>` for in game notifications and such. How is this looking for an inventory list type situation?\n```Since I wasn't able to do anything about it at the moment, I opened up my recipe book and took a look at what I was able to craft right now.\n<Bronze Studded Leather Tunic>\nSlot: Chest\nItem Class: Common\nArmor: 30\nArmor Type: Light\nIngredients: 2 Bronze Ingots, 4 Raw Leather\n<Bronze Studded Cap>\nSlot: Head\nItem Class: Common\nArmor: 10\nArmor Type: Light\nIngredients: 1 Bronze Ingots, 1 Raw Leather\n<Hardened Leather Boots>\nSlot: Boots\nItem Class: Common\nArmor: 7\nArmor Type: Light\nIngredients: 2 Raw Leather\n<Bronze Studded Leather Pants>\nSlot: Legs\nItem Class: Common\nItem Quality: Normal\nArmor: 20\nArmor Type: Light\nIt took me another hour to finish crafting all the armor and shape it into something useful to wear.```",
    "<> is used for telepathy. After some debate with the team, we ended up preceding LitRPG-style data with `\u2500 `. (That's 'box drawings light horizontal', which isn't used for anything else. Not to be confused with dashes though it looks the same. Having them all under same style also makes it easy to filter out: just ban the `\u2500` token...)\nBut note that this didn't make it into v3, it'll only be used in the future versions.",
    "y21-m08-d29",
    "module-discussion"
  ],
  [
    "How big was the collection when v3 was training?",
    "There were 9310 works in v3, and now it's about 12800. But the dataset filesize has almost doubled. A lot of content in v3 were short stories. <:shrug:332268181517238272>",
    "y21-m08-d28",
    "community-research"
  ],
  [
    "Would v4 include all of v3s works or even some of it or is it all new works? And would v3 still be available to use once v4 is out or no?",
    "v3 with some poorly rated works pruned + a lot of new content.",
    "y21-m08-d28",
    "community-research"
  ],
  [
    "adding ```[Author's Note: this is a story for children; Tags: light, sweet, adventure, childish; word choice: adapted to children. ]```  seem to reduce the amount of dark things happening and the usage of complicated metaphor",
    "I wonder if v3 recognizes noblebright (opposite of grimdark.) I can't remember if it was used as a tag...",
    "y21-m08-d25",
    "novelai-discussion"
  ],
  [
    "Combining sharing channels not a great idea",
    "Combining other kinds of channels isn't great either. <#837792141765902386>'s gone downhill to the point that I ended up muting it. Kinda miss #music already.",
    "y21-m08-d24",
    "novelai-discussion"
  ],
  [
    "wheres a good place to get nsfw prompts n stuff.",
    "https:\/\/discord.com\/channels\/836774308772446268\/837402685824565278\/878934508114694154",
    "y21-m08-d24",
    "nsfw-discussion"
  ],
  [
    "Ah a good old self insert pmd fanfic <:goosip:765775467420581958>",
    "Oh, right. Now I remember what the main issue with PMD fics was: self-insertions, character names, team names... Too high chance of those getting overtrained.\nCould add snippets from various fics, I suppose. Though that'd be a lot of work and time, something that I can't spare at the moment.",
    "y21-m08-d23",
    "module-discussion"
  ],
  [
    "However, putting tags such as `[ Species: Leafeon (Verdant Pok\u00e9mon) ]` in the AN seems to gives decent results, likely pulling from Zalty's Pokemon data file",
    "Interesting. I should finish adding those for all species, then...",
    "y21-m08-d23",
    "module-discussion"
  ],
  [
    "'''--- --- --- ---''' is another dinkus I just ran into",
    "Yep, I see a few books that overuse `---`. Gonna em dash those, tnx.\nEdit: Oh, cute. One fantasy novel uses `--]----`. Guess that's supposed to be a sword.",
    "y21-m08-d23",
    "community-research"
  ],
  [
    "<@!409511804293611530> I found this as a dinkus inside the adventure mode \n> *.*.*.",
    "That's Gnurro's project, I have nothing to do with it. Haven't even seen it.",
    "y21-m08-d22",
    "community-research"
  ],
  [
    "what kind of elf are you talking about ? <:SurprisePika:586882713123029003>",
    "https:\/\/images-na.ssl-images-amazon.com\/images\/I\/41NtUWsD-pL._SY346_.jpg",
    "y21-m08-d19",
    "novelai-discussion"
  ],
  [
    "Start with:\n`***`",
    "`\u2042` should work better in theory, but currently it tends to output things like `Chapter 1` too often. Maybe in next version...",
    "y21-m08-d18",
    "novelai-discussion"
  ],
  [
    "I got started on it. I am including basic information such as dimensions, structures, biomes, mobs\/creatures, boss mobs, tools, and important blocks (I.E. Crafting Table, furnace, etc.) as entries for each block would take forever and isn't necessary for your average adventure. (Entries are from the minecraft fan wiki)\n\nAnd yes, I am making a Nsfw lorebook pack too. (Because people like to imagine cardboard boxes fuck I guess.)",
    "This could be useful for the main dataset. DM it to me once it's done, if you want to share.",
    "y21-m08-d17",
    "nsfw-discussion"
  ],
  [
    "Yo, I'm trying to gather material for a body possession themed module (ghosts, spirits, parasites, any of it). The only rule I have is that the hosts can't die as a result of being possessed. Is there any material you guys can think of that works for this?",
    "Night's Dawn series by Peter F. Hamilton.\nOther than that, I can't really think of much. There's some Sheridan Le Fanu and Algernon Blackwood stories with those themes, but beyond that... I'd suggest checking TVTropes. <:shrug:332268181517238272>",
    "y21-m08-d16",
    "module-discussion"
  ],
  [
    "I don't remember when Dragon was gutted. If it was nov 2020 or closer to march 2021 <:AG_Shrug:704769754271055962>",
    "Both.",
    "y21-m08-d16",
    "community-research"
  ],
  [
    "<@343691170964045827> it really needs to be followed up with a multi module mode. Banging the text adventure module with, for example, the Lovecraft module",
    "This would be a mishmash of two very different styles, probably wouldn't work well for either.",
    "y21-m08-d16",
    "novelai-discussion"
  ],
  [
    "inactive channels were archived to avoid clutter",
    "More like outright deleted, since they don't show up on search anymore. Shame, there were a few music videos I was planning to check out once I found time.",
    "y21-m08-d16",
    "novelai-discussion"
  ],
  [
    "Literotica module. It went into a full \"list mode.\"",
    "Had to try this myself. Here's girlfriend advice from an AI tank.",
    "y21-m08-d15",
    "novelai-discussion"
  ],
  [
    "Can't you just delete the images from the PDF? \ud83e\udd14",
    "PDF isn't a text format. It requires conversion to text, and depending on the font etc the end result may be full of errors.",
    "y21-m08-d13",
    "novelai-discussion"
  ],
  [
    "Couldn't you just use actual CYOA books?",
    "Those are all pdfs. ...because images.",
    "y21-m08-d13",
    "novelai-discussion"
  ],
  [
    "Think someone made a module for that already.",
    "I was thinking more of the main dataset...",
    "y21-m08-d12",
    "novelai-discussion"
  ],
  [
    "But I would have to translate all the AVGN episodes into prose",
    "Ooh... That reminded me that all Zero Punctuation episodes are transcripted...",
    "y21-m08-d12",
    "novelai-discussion"
  ],
  [
    "Browser hasn't cleared my cache in months. I don't know how common it is. I can't tell you how to prevent it, only to back your stuff up.",
    "Like I mentioned in support, Chromium at least deletes older content whenever it adds new. It never fully empties the cache. So the more you browse, the faster it happens.",
    "y21-m08-d12",
    "novelai-discussion"
  ],
  [
    "NAI, ironically, is a bit more open than OpenAI. \ud83d\ude09",
    "Only ping me if it's something important. I have work to do.",
    "y21-m08-d12",
    "feedback-discussion"
  ],
  [
    "<@!409511804293611530> I'm seeing them a lot in a specific subgenre of fantasy, the 'poetic'",
    "Double-check that they're in the originals, and not just something that got added in the conversion. Because I'm not seeing those in the whole dataset...",
    "y21-m08-d11",
    "module-discussion"
  ],
  [
    "`* * *` is the bane of my existence. *Every time* when I test with NRT <:pepehands:838312017336336405>",
    "A lot of those have been converted to `***` after v3, so at least that'll be greatly reduced in next versions. Whenever those happen.",
    "y21-m08-d10",
    "novelai-discussion"
  ],
  [
    "So is that instead of `***` normal or a result of a module I am using?",
    "And yes, this seems like a module problem.",
    "y21-m08-d10",
    "novelai-discussion"
  ],
  [
    "I like how, despite `***` being the standard way of splitting scenes, the AI will sometimes spit out weird variations. One story I was messing around with today gave me `\u25c6\u25c7\u25c6\u25c7\u25c6`",
    "That's common in uncleaned LNs...",
    "y21-m08-d10",
    "novelai-discussion"
  ],
  [
    "That must be it. I'm guessing The Pile has a bunch of continuously updating iterations",
    "Not to mention the finetune.\nhttps:\/\/m.media-amazon.com\/images\/I\/61t3KyzFx5L.jpg",
    "y21-m08-d10",
    "novelai-discussion"
  ],
  [
    "what does the yellow and blue text mean when you start writing a story?",
    "Depends on which theme you're using, but you can always check the settings (customization) to see which is which.",
    "y21-m08-d08",
    "novelai-discussion"
  ],
  [
    "I think <Text> works, i read that at least yesterday",
    "<>s are more for telepathy and such, but it might work for thoughts.",
    "y21-m08-d08",
    "novelai-discussion"
  ],
  [
    "I wonder. Do any other countries have AI games like this not in English.",
    "Nothing public, as far as I know. Though I've seen some attempts at Finnish model, etc. But that was GPT-2.",
    "y21-m08-d08",
    "novelai-discussion"
  ],
  [
    "(top-k=1, ban bracket off\", default, v3)\n```[ Synopsis: The elf maiden is rescued by the party. ]```True!\n\n`[ Previously ]` isn't generating story summaries by itself, although it might work really well in conjunction with a written one.\n`[ Recap:` doesn't work at all.\n<:InvisibleParrot:669739568651829289> \n```[ Summary: Tristan Mychal rescues an elven lady from the orcs. ]```Also true!\n\nI think for this test, it'd have to be done with `nrt` and like default settings. <:nakkiHm:814619451244675093>",
    "Another one that I keep running into is `[ THE STORY SO FAR ]`. Might also be worth testing `[ PREVIOUSLY ]`, etc. Caps are rather common for these.",
    "y21-m08-d08",
    "community-research"
  ],
  [
    "Hey, if anyone's about, could I get an invite to the NSFW server?",
    "Which one?",
    "y21-m08-d07",
    "nsfw-discussion"
  ],
  [
    "Offff, no superhero, spartan, alien, etc module",
    "There's a Superheroes module in the core, though...",
    "y21-m08-d05",
    "novelai-discussion"
  ],
  [
    "NAI runs badly on IOS because IOS bad",
    "I'd rather use a 'bad' OS that lets me micromanage what apps are allowed to do, rather than one full of security holes. Not to mention all the useless junk that Android forces you to install and keep running, regardless of whether you need them.",
    "y21-m08-d04",
    "novelai-discussion"
  ],
  [
    "soooo...did anyone end up figuring out the Mysterotica modules?",
    "Which ones haven't you figured out yet? Edit: Never mind. The list got updated, they're all named now.",
    "y21-m08-d04",
    "nsfw-discussion"
  ],
  [
    "do we have any idea what the goal of v4 will be so far besides just pruning out more crap?",
    "More content, more support for franchises that didn't get included into v3. Even some textbooks and other nonfiction. Besides the cleans to the existing content, I've curated (and cleaned) minimum of 25 new books per day.",
    "y21-m08-d03",
    "novelai-discussion"
  ],
  [
    "I spent around an hour for a 330 token dataset just pressing backspace to remove empty lines",
    "Regex `$\\r?\\n?^$` -> ``.  Done, empty lines removed, in a few secs.",
    "y21-m08-d03",
    "nsfw-discussion"
  ],
  [
    "talking about my cursed module? \nif so its a lightly curated selection based on various keyword searches of various deeply disturbing kinks from the asstr archive. that is a collection of storries written by various people on various porn formums. \nThe curation was litteraly dont by ctrl+f search. call it an initial test of a bulk module. \n\nlike a fictional stew. but without checking too close if the ingredients are as fresh as need be.",
    "...no. I'm talking about the literotica bundle, as I said.",
    "y21-m08-d03",
    "nsfw-discussion"
  ],
  [
    "Do you know any alternatives to ABBYY Finereader?",
    "Not any good ones. Adobe Acrobat's OCR, for instance, is trash.",
    "y21-m08-d03",
    "module-discussion"
  ],
  [
    "Some sadistic bastard decided not to add periods before `\"` in their short story",
    "Edit: Wait, no. Misread that. Disregard.\n`\".` is UK style, but even most UK authors seem to use `.\"` nowadays, at least judging on what I've seen in the dataset.",
    "y21-m08-d03",
    "novelai-discussion"
  ],
  [
    "Alright. Lemme finish training it atleast. My module is at 76% ish the recommended steps",
    "You don't have to train at 100%, and you generally shouldn't.\nFor instance, a genre model is better with something like 10mb+ of varied data and <20% steps. That way names won't get overtrained.\nThe Norse module was trained on 15mb of mixed viking content, and at 14% steps. Works quite well, but even at that low, it managed to fixate on certain names... ||Sigurd||",
    "y21-m08-d03",
    "module-discussion"
  ],
  [
    "and it's bad enough sometimes working from the Epubs, like I had to edit all the ship to ship communications in Iain Bank's Culture novels.",
    "I might be interested in those. There's a couple of volumes that I haven't converted yet, due to how long it'd take. Excession and Hydrogen Sonata, iirc.",
    "y21-m08-d02",
    "module-discussion"
  ],
  [
    "So, for example, does 7 HP books, which was less than 6mb once cleaned, count as small or large?",
    "That's large. 1mb is optimal.",
    "y21-m08-d02",
    "module-discussion"
  ],
  [
    "It's not that bad man, there's definitely worse literature out there",
    "`Baldur's Gate` by Philip Athans. <:doom:837136374493741057>",
    "y21-m08-d01",
    "module-discussion"
  ],
  [
    "",
    "If the content has issues like these, it's usually faster to find a better replacement rather than try to fix them.",
    "y21-m08-d01",
    "module-discussion"
  ],
  [
    "i've been thinking of trying to put together and clean up a bunch of Galnet entries or something and train an Elite: Dangerous module",
    "There's several novels that you could use for that...",
    "y21-m07-d31",
    "module-discussion"
  ],
  [
    "sometimes the scanner wants to replace I's with \/'s and 1's",
    "`l` -> `|` is also common. There's probably a lot once you start looking for them, and they tend to leak.",
    "y21-m07-d31",
    "novelai-discussion"
  ],
  [
    "Well I found someone who novelized pmd sky so that's free <:sylvsip:795709693833248768>",
    "The main problem with those is that it latches heavily on the protagonists' name.",
    "y21-m07-d30",
    "module-discussion"
  ],
  [
    "Is that the storage place, and is there a website link if there is?",
    "It's a typo. And yes.",
    "y21-m07-d30",
    "nsfw-discussion"
  ],
  [
    "Fine tuning of any sort can't really increase the base competency of the model, it can only constrain it to fit the tasks you want.",
    "The base isn't 100% English, so I'm glad someone tested it. And sorry that they wasted 8k steps on that.",
    "y21-m07-d30",
    "module-discussion"
  ],
  [
    "Well, cleaning datasets is a pain <:ogl:663595877939806239>",
    "I've been doing this nonstop for 1.5 months now.",
    "y21-m07-d30",
    "module-discussion"
  ],
  [
    "What book is that lmao",
    "Richard Morgan's.",
    "y21-m07-d27",
    "novelai-discussion"
  ],
  [
    "how many for \"breasts that seem to defy gravity\"",
    "Hm. Only one, and that's phrased as `breasts were not of the same epic proportions as those of her performing partner, but they were still cosmetic-standard enough to defy gravity`",
    "y21-m07-d27",
    "novelai-discussion"
  ],
  [
    "do fantasy writers use \"child bearing hips\" to describe women?",
    "Only 11 hits in the whole database for `child.?bearing hips`. Far less than I expected.",
    "y21-m07-d27",
    "novelai-discussion"
  ],
  [
    "do fantasy writers use \"child bearing hips\" to describe women?",
    "First hit from the data: ```[...] only two words left her mouth, \"Nice ass.\"\nWhich, well, was obviously true. At least call them 'child-bearing hips' or something, someone thought.```",
    "y21-m07-d27",
    "novelai-discussion"
  ],
  [
    "I hope NAI trains their own model. Some days ago, when this channel takled about neox and 22B, a dev said something like \"we planned big things\", so i hope it's a own model. But that 100% speculation from me and probably not even near the truth.",
    "What do you mean by 'own model? I mean, Calliope and Sigurd are NAI's own models.",
    "y21-m07-d24",
    "novelai-discussion"
  ],
  [
    "Damn, I removed all chapter info. So I should use what format for chapter indicator?\n```test here.\n***\ntext here.``` or, for example\n```text here. ***\ntext here.```",
    "First one. Spaced `***` is a different token, one that we don't use.",
    "y21-m07-d24",
    "community-research"
  ],
  [
    "Any advice on what the minimum amount of text should be?",
    "Finetune would know better, but...\n1mb recommended, can work with less. Will need to experiment.",
    "y21-m07-d24",
    "community-research"
  ],
  [
    "I finally got around to starting to clean up my module training data. Pretty sure the finetune team has a much more thorough pipeline, but I couldn't immediately find if they've published it, so here's the most obvious stuff I could come up with in 20 minutes while struggling to remember how to shot sed:\n\n`sed -i -E -e 's\/\\s+\/ \/g' -e 's\/[\u201c\u201d]\/\"\/g' -e \"s\/[\u2018\u2019]\/'\/g\" -e 's\/\u2026\/...\/g' -e 's\/^ +([^ ])\/\\1\/' -e 's\/([^ ]) +$\/\\1\/' -e '\/^ *$\/d' -e 's\/^[^[:alnum:]]+$\/***\/' *txt`\nThis processes all .txt files in the current directory. In order, the expressions:\n- Replace all multiple whitespace with a single space\n- Replace fancy double quotes with ordinary ones\n- Replace fancy single quotes with ordinary ones\n- Replace fancy ellipses with ordinary ones (though who knows, maybe you might want to not do this, or even reverse it)\n- Strip leading whitespace\n- Strip trailing whitespace\n- Delete empty lines\n- Replace lines consisting entirely of non-alphanumeric characters with a standardized chapter break",
    "Yeah, those are the basic ones, similar to what we clean automatically. Wouldn't automate the last one, as it gets rid of some things we'd prefer to preserve. But seems good enough for module use.\nOne good addition would be getting rid of the chapter numbering. (Those typically range from the usual `Chapter #`\/`CHAPTER #` headers to numbers or even roman numerals.)",
    "y21-m07-d24",
    "community-research"
  ],
  [
    "\"tongues dance\" is the common substring as far as I can tell",
    "6897110 was right.\n`219 hits in 190 files.` So barely more than once per book, which makes rebalancing that rather difficult. If it were something like 50 times in one book, could've just dropped that one... \nI can toss one fiction where it appears 7 times (it was poorly rated anyway), but I doubt that'll have much of an effect.",
    "y21-m07-d24",
    "nsfw-discussion"
  ],
  [
    "Ok why the fuck is \"our tongues dance in each other's mouths\" coming up constantly when I'm trying to do something totally different? Is it a common phrase??",
    "Is that the exact phrasing? I can search the data to see where\/if it appears.",
    "y21-m07-d24",
    "nsfw-discussion"
  ],
  [
    "We can't change the list of tokens that's used by the tokenizer, it's based on GPT-2 and is used for all of the base models until today. If you want a new list of tokens approach Eleuther with it but my last information is that it's not worth it and too much work",
    "From what I've seen, most devs think that it'd be worth it. But yes, it'd take some work.",
    "y21-m07-d24",
    "novelai-discussion"
  ],
  [
    "Would you be able to \"fix\" tokens\ud83e\udd14",
    "Certainly. Just rewrite the tokenizer and make sure it include things like ' hairless' as single token. No idea if that'll ever get done, though.",
    "y21-m07-d24",
    "novelai-discussion"
  ],
  [
    "It's interesting how the AI seems to pull random words from Lorebook entries. In my main character's entry I have \"She is Mizanelan\" as her country of origin. Granted, I probably could have been clearer, but I don't see how it would interpret that as a General's last name",
    "Try `She is from Mizanela` instead.",
    "y21-m07-d24",
    "novelai-discussion"
  ],
  [
    "How you got it trained to do that. Idk. But thank you",
    "Mostly with `The Mammoth Encyclopedia of Science Fiction`. The other genres the AI simply figured out on its own.",
    "y21-m07-d23",
    "community-research"
  ],
  [
    "So why does a blue haired anime swordsman show up whenever Sigurd is mentioned in a bobross prompt",
    "Sigurd from Fire Emblem.",
    "y21-m07-d22",
    "novelai-discussion"
  ],
  [
    "Idk, zalty and gen were pretty active in the community",
    "I worked closely with some of the devs, that part isn't under NDA. The Zaltys-model for character generation, etc (though they never got around to implementing the fixes I sent for that.)",
    "y21-m07-d22",
    "novelai-discussion"
  ],
  [
    "Does need it need to be \"Anthropomorphic\" or can it be \"Furry\" or \"Anthro\"?",
    "After a quick check, I'd say that lowercase 'anthropomorphic' and 'anthro' appear most often, and are therefore most likely to work. Whereas 'furry'\/'Furry' is way too ambiguous.\nThough furry novels don't seem to use any of those. It's just 'the squirrel', 'the cougar', etc.",
    "y21-m07-d22",
    "novelai-discussion"
  ],
  [
    "Yes, I meant that the Magic Academy theme is probably trained entirely with Harry Potter",
    "Nope. All themes use minimum of seven authors, most have more than dozen.",
    "y21-m07-d18",
    "novelai-discussion"
  ],
  [
    "Can it do faces and bodies at all",
    "Yeah, this tech isn't great at faces yet....\nFacesHQ can handle those, but it's kind of cheating since all it does is faces.",
    "y21-m07-d17",
    "novelai-discussion"
  ],
  [
    "There is no good way to ban this association of tokens",
    "`Her cock`.",
    "y21-m07-d16",
    "nsfw-discussion"
  ],
  [
    "Nothing is on our computers only \ud83d\ude1b",
    "...I really should back up the finetuning data.",
    "y21-m07-d16",
    "novelai-discussion"
  ],
  [
    "temp 0.5:\n```\ntensor([    0.8832,     0.0779,     0.0211,     0.0077,     0.0038,     0.0021,\n            0.0012,     0.0008,     0.0005,     0.0004,     0.0003,     0.0002,\n            0.0002,     0.0001,     0.0001,     0.0001,     0.0001,     0.0001,\n            0.0001,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000])\n```\ntemp 0.7:\n```\ntensor([    0.7355,     0.1298,     0.0510,     0.0249,     0.0149,     0.0097,\n            0.0065,     0.0047,     0.0036,     0.0029,     0.0023,     0.0019,\n            0.0016,     0.0014,     0.0012,     0.0011,     0.0009,     0.0008,\n            0.0007,     0.0007,     0.0006,     0.0005,     0.0005,     0.0004,\n            0.0004,     0.0004,     0.0003,     0.0003,     0.0003,     0.0003])\n```\ntemp 0.8:\n```\ntensor([    0.6579,     0.1442,     0.0637,     0.0340,     0.0217,     0.0149,\n            0.0106,     0.0079,     0.0063,     0.0052,     0.0042,     0.0036,\n            0.0031,     0.0027,     0.0024,     0.0022,     0.0019,     0.0017,\n            0.0016,     0.0014,     0.0013,     0.0012,     0.0011,     0.0010,\n            0.0009,     0.0008,     0.0008,     0.0007,     0.0007,     0.0006])\n```",
    "I hadn't realized that 0.5 had that much of an effect. Most of those results are on the level of winning a lottery.",
    "y21-m07-d16",
    "community-research"
  ],
  [
    "yeah I know nothing magic about top-k = 1, but I still feel like seeing if some sort of manipulation affects the most likely tokens or not should tell us *something*",
    "Yes, but sometimes those changes can have large effects without changing the Top-K 1.\nBeing able to see the top tokens -- with percentages -- would be golden.",
    "y21-m07-d16",
    "community-research"
  ],
  [
    "Wait - in the fine-tune would you tag monster entries like this:\n[ Species: Space Hamster ][ Type: Mammal ]\nOr this:\n[ Species: Space Hamster ; Type: Mammal ]\n?",
    "Mixed. Both should work. No space before `;`, though.",
    "y21-m07-d16",
    "community-research"
  ],
  [
    "Do you think it's worth experimenting with the dnd stuff for lorebook entries? That seems quite useful to that end. \nAlso what would you put under things like \"intelligence\" just a number?",
    "It is clearly having _some_ effect, so it might be worth a shot if you don't have better stuff to experiment with.",
    "y21-m07-d15",
    "community-research"
  ],
  [
    "Is it just like DID or considered different?",
    "Different. More related to the alien hand syndrome.",
    "y21-m07-d15",
    "novelai-discussion"
  ],
  [
    "Wait please lol where can I find \/aids\/ I'm always seeing crops of it",
    "Just Google it--\nUh, okay, don't. Look in 4chan.",
    "y21-m07-d15",
    "novelai-discussion"
  ],
  [
    "There's lots of horni in there.",
    "Egypt was a combination of seven authors. As far as I know, only one book -- by a rather prominent South African novelist -- included sex scenes. It's amusing that the AI latched on that, out of all things.",
    "y21-m07-d15",
    "community-research"
  ],
  [
    "to what?",
    "`Crab, Snail, and Monkey`, evidently. I don't get the reference.",
    "y21-m07-d13",
    "novelai-discussion"
  ],
  [
    "wait what does *** do",
    "Strong paragraph break. Think of it as a beginning of a new chapter.",
    "y21-m07-d13",
    "novelai-discussion"
  ],
  [
    "Suppose that will be the case for the upcoming module training feature on opus too, huh?",
    "Yep, same problems with that.",
    "y21-m07-d12",
    "novelai-discussion"
  ],
  [
    "I guess training it on Neuromancer and Snow Crash isn't enough?",
    "They weren't. I think you'd need to prune them down to pure cyberpunk. Too many action scenes etc (in Snow Crash.) And pruning those would take a lot of time.",
    "y21-m07-d12",
    "novelai-discussion"
  ],
  [
    "is an official cyberpunk theme planned?",
    "The thing about cyberpunk is that it's hard to find anything that's all-cyberpunk-all-time. There was already an attempt at cyberpunk module, but it just wasn't focused enough.",
    "y21-m07-d12",
    "novelai-discussion"
  ],
  [
    "i'm assuming the artificial intelligence theme is appropriate for cyberpunk scenarios?",
    "That's likely to work best for Cyberpunk out of the current set, yes.",
    "y21-m07-d12",
    "novelai-discussion"
  ],
  [
    "oh yes, i'm wondering how smart the AI is with making sure it doesn't just rip a character from an existing franchise.",
    "Well, that depends. If you name a character Darth Vader, Master Chief, or Gotrek then those are going to have certain connotations.\nBut if it's something like Zoe -- name that likely appears in hundreds of novels -- then it's going to need more than just the name to focus on the 'correct' Zoe.",
    "y21-m07-d10",
    "nsfw-discussion"
  ],
  [
    "what, really?",
    "Yep. Complexity increases, but the required amount of data doesn't. Which is why it's important to have a good, versatile dataset.",
    "y21-m07-d10",
    "nsfw-discussion"
  ],
  [
    "30?",
    "After working (with pretty much no breaks) for a month, I've collected and cleaned 4710 works. v3 had about 3800 fully cleaned, so it's certainly improved from that. We're also adding content for franchises and themes that weren't already included. So yeah, v4 should be noticeably different.",
    "y21-m07-d10",
    "nsfw-discussion"
  ],
  [
    "Is NAI that much better at first person than second?",
    "NAI is mostly trained on novels. About 99.5% of novels are first or third person.",
    "y21-m07-d10",
    "novelai-discussion"
  ],
  [
    "The finetune material is already curated to death",
    "It really isn't. Nobody can curate 15000 books in a few weeks.",
    "y21-m07-d10",
    "nsfw-discussion"
  ],
  [
    "it's more a web manga, or is it manwha?   But anyone read gamer?",
    "Interesting premise, but too slow-paced for my tastes. I'd rather read LitRPGs.",
    "y21-m07-d10",
    "novelai-discussion"
  ],
  [
    "i loved the idea of worlds and that you could let the AI generate the entries!",
    "But they were so bad... and the AI never used them on its own...",
    "y21-m07-d09",
    "novelai-discussion"
  ],
  [
    "So now you don\u2019t test anything anymore? \ud83d\ude42",
    "I'm in charge of the dataset organizing and cleaning, along with Belverk. No time for testing, at least for a couple of months.",
    "y21-m07-d09",
    "novelai-discussion"
  ],
  [
    "Precisely why I wrote `nrt`.",
    "Yeah, I wish I had something like that back then...",
    "y21-m07-d09",
    "novelai-discussion"
  ],
  [
    "unless you want the AI to spit out more information in the form of a wiki",
    "That too. Mostly it's the things like links and footnotes that get in the way. Including those messes up the output completely.",
    "y21-m07-d09",
    "novelai-discussion"
  ],
  [
    "Also, who tries 100 times for 1 sentence though LMAO",
    "Uh... I used to test pretty much everything at least 50 times before posting results. Every single writing style, etc. It's basic statistics: can't draw any conclusions from a couple of results.",
    "y21-m07-d09",
    "novelai-discussion"
  ],
  [
    "youre free to write as much fucked up shit as you want",
    "Right. Because US signed the international Human Rights Act of 1998, which protects written texts. Any laws that'd try to restrict that wouldn't hold in higher courts.",
    "y21-m07-d09",
    "novelai-discussion"
  ],
  [
    "I think they might have some value for retro fans so I'd expect them to be way more expensive.",
    "Not to mention the component prices. You could sell them for scrap for more than $25. There's a lot of value metals in those.",
    "y21-m07-d08",
    "novelai-discussion"
  ],
  [
    ">No module named 'nltk'",
    "`> pip3 install nltk`",
    "y21-m07-d08",
    "feedback-discussion"
  ],
  [
    "some stuff definetly isn't wikidata. I mean I do not know what you tagged but try any of\n`[Author: Terry Pratchett]` `[ Author: Arthur Conan Doyle]` `[Author: J. K. Rowling]` for example",
    "Seems like wiki data to me. Pratchett = Discword association from wiki, then it connects that with the data from the actual novels.",
    "y21-m07-d08",
    "community-research"
  ],
  [
    "Where can I get an old version?",
    "https:\/\/archive.org\/details\/kindle-for-pc-1-17-44170",
    "y21-m07-d08",
    "feedback-discussion"
  ],
  [
    "What kind of data?  There's a collection of Z-machine files.",
    "Actual play, including the player inputs.",
    "y21-m07-d08",
    "community-research"
  ],
  [
    "I still hope we get a general format guide",
    "Not sure if one is needed. Just prune fore-and afterwords, leaving nothing but the story itself. And delete trailing spaces (` $` regex). That should generally be good enough. You can replace chapter headers etc with `***` if you feel like putting in extra work. ...or you can use Gnurro's ReFormatter (see pins), which just got some new features added into it too.",
    "y21-m07-d08",
    "feedback-discussion"
  ],
  [
    "Is there an easy way to convert Kindle files to plaintext?",
    "You're gonna need an older version of Kindle. Such as 1.17.1. Newer ones use different DRM, which can't be (as far as I know) converted with Calibre.",
    "y21-m07-d08",
    "feedback-discussion"
  ],
  [
    "Are there any issues with sourcing text from two completely different styles to try to blend them, like teletubbies with eldritch abominations, or slice of life with epic fantasy?",
    "From what I've seen, one style tends to easily overweight the other. So things like crossovers will require major balancing to get working, sadly.",
    "y21-m07-d08",
    "novelai-discussion"
  ],
  [
    "That's still pretty good, if a decent prefix just needs to be a little over 1 tolkien book.",
    "It's still a lot if you're trying to build a niche prefix. Good luck finding 1MB data of kobolds, for instance.",
    "y21-m07-d08",
    "novelai-discussion"
  ],
  [
    "<@!409511804293611530> What kinda stuff is Naval trained on?",
    "Mostly Age of Exploration era, with some fantasy thrown in.",
    "y21-m07-d08",
    "novelai-discussion"
  ],
  [
    "<@!409511804293611530> Is Magic Library the short story from Borges I am thinking of?",
    "Yawn. Sorry for late reply, just woke up. Anyway, that's not what Magical Library is based on; it would've been far too short. It's a mix of various content in that style.",
    "y21-m07-d08",
    "novelai-discussion"
  ],
  [
    "Wasn't it also overfitted to hell? Like, you need more content than what they gave it.",
    "And it probably didn't help that some of that content was repeated thrice...",
    "y21-m07-d07",
    "novelai-discussion"
  ],
  [
    "Wait title: is in the fine tune? Are you guys sure",
    "Not yet, but will be added for some works in v4.",
    "y21-m07-d05",
    "community-research"
  ],
  [
    "Last time I noticed it",
    "Thanks. I'll make sure the tables are gone by the next version. Though who knows when that'll be, might be a 'while'.",
    "y21-m07-d03",
    "community-research"
  ],
  [
    "Is the strength between *** and * * * the same?",
    "20,000+ instances of `* * *`, over 100,000 of `***`. That's more lopsided than I expected.",
    "y21-m07-d03",
    "community-research"
  ],
  [
    "A lot of chapters start with quotes I guess...",
    "Yeah, this is standard for many authors. So I'm not surprised that it bleeds into output.",
    "y21-m07-d03",
    "community-research"
  ],
  [
    "I'm on the sub and a guy has his horses talking out of the blue",
    "This is hardly unexpected, as Sigurd is trained on fantasy. Talking animals are more common than normal ones. To negate that, we'd need a different model that's trained on nonfiction.",
    "y21-m07-d03",
    "novelai-discussion"
  ],
  [
    "UUUUUUHHHHH ... i used A\/N [ Source: www.literotica.com ] on a blank prompt. What it gave me was very plausible story.... and then VEEEEERRYYYY LEWD.",
    "There are no urls in the finetuning data. `www.erotica.com` would likely work just as well.",
    "y21-m07-d02",
    "community-research"
  ],
  [
    "I remember Fighting Fantasy having half decent 2nd person writing when I was a youngster.",
    "Oof. Reordering those into logical order would be a major headache. But if someone wants to do the work, we can add it.",
    "y21-m06-d29",
    "novelai-discussion"
  ],
  [
    "V2 was actually on par with Dragon when it comes to second person imo",
    "I don't know how that'd be possible, considering that Sigurd's mostly trained on novels. And second person isn't exactly common in those.",
    "y21-m06-d29",
    "novelai-discussion"
  ],
  [
    "The fuck are these stats?\n```Name: Charmander (Char-mend)Species: Charizard (Kyara jishu, fire lizard)Level: 8HP: 48DP: 24SP: 56ATK: 180DEF: 120MND: 32AGI: 45LUK: 30Resistance```",
    "Shouldn't be anything like that in the data, so it might be from the base. Gonna run a search just in case, though... Edit: Nope, not a single instance of `LUK:`.",
    "y21-m06-d29",
    "novelai-discussion"
  ],
  [
    "https:\/\/user.xmission.com\/~trevin\/hanky.html as referenced on <#837402685824565278>",
    "Sounds made up for the most part. Several close shades of mauve, magenta, etc with different meanings? No way that'd work in practice.",
    "y21-m06-d28",
    "nsfw-discussion"
  ],
  [
    "So mainly dates and chapter titles?",
    "Dates, times, story and chapter titles, things like `[ Glossary ]`, etc. And the story tags, for the limited content that's got tagged so far.\nOne thing that I could see them being useful for is years. Try something like `[ 1896 ]` in memory for an empty prompt, and see what happens.",
    "y21-m06-d27",
    "community-research"
  ],
  [
    "But... will there be >6B and <21B version?",
    "Doesn't sound like it.",
    "y21-m06-d27",
    "novelai-discussion"
  ],
  [
    "Speaking of models, 23B is estimated to take 6 - 12 months",
    "Except they're not planning to train it on TPU. If the Coreweave agreement goes through, it'll be much, much faster.",
    "y21-m06-d27",
    "novelai-discussion"
  ],
  [
    "Optimism is great but..",
    "```[3:22 PM] Connor: Again, depends on the hardware\n[3:23 PM] Connor: We are working with CoreWeave to build a cutting edge GPU supercluster\n[3:23 PM] Connor: But the chip shortage is affecting the whole industry, so lead times are long\n[3:23 PM] Connor: If you had a whole NVIDIA superPOD it could be done in like 2 months\n[3:23 PM] Connor: but those things don't come easy lol\n[3:24 PM] Connor: So until we know when our hardware will arrive and how much it'll be, we cannot commit to any timelines\n[3:24 PM] Purple: 2 months for a 20B or 200B?\n[3:24 PM] Connor: 200B``` If they had hardware, they could start training 200B right now, and it'd be done in two months.",
    "y21-m06-d27",
    "novelai-discussion"
  ],
  [
    "My bet's that we get open source models upwards of 100B within two years",
    "That'd be a safe bet.",
    "y21-m06-d27",
    "novelai-discussion"
  ],
  [
    "I was wondering about that, too! Thanks for bringing it up, I'll mention it to admins",
    "It's been more hindrance than anything else. I would've deleted my old entries from there if I could (those are badly outdated, poor examples of how to write submitted data), but since it's locked I can't edit\/delete those. So we've got some submissions in outdated format...",
    "y21-m06-d27",
    "novelai-discussion"
  ],
  [
    "Okay but why not \n\nThe Lusty Argonian Maid",
    "It's in, of course it is.",
    "y21-m06-d26",
    "novelai-discussion"
  ],
  [
    "I don't think the mere MENTION of boobs is NSFW",
    "Only in some weird countries.",
    "y21-m06-d26",
    "novelai-discussion"
  ],
  [
    "You don't mean ttrpg handbooks, do you?",
    "Nah, those have already been formatted into something usable.",
    "y21-m06-d25",
    "novelai-discussion"
  ],
  [
    "mind if i ask, how does your Memory & A\/N look like Zaltys \ud83d\udc0d ?\n\nalso Pathfinder is in it ? Very nice, dm'ing on Sat.",
    "It doesn't look like anything, because I spend all my time sorting the data. No time for play. ...maybe in a month.",
    "y21-m06-d21",
    "community-research"
  ],
  [
    "Sorry <@!409511804293611530> I missed your message.  That's interesting to know.. I'm definitely going to have to test to see if what I'm getting is just false positives or the result of other lore.  Cheers for the heads-up.",
    "'course, there's always the chance that it's pulling that somewhere from the base data.",
    "y21-m06-d21",
    "community-research"
  ],
  [
    "Oh btw talking about references\nDid you include JoJo?",
    "Couple of random characters got thrown in. I think Lisa Lisa was one of them. But I'm not too familiar with JoJo, and we didn't get any user submissions for it, so...",
    "y21-m06-d21",
    "novelai-discussion"
  ],
  [
    "just insert stuff from bulbapedia",
    "That's already in, and any other lore I could find. But it's a drop in the ocean.",
    "y21-m06-d21",
    "novelai-discussion"
  ],
  [
    "I think we need more Pokemon in the data <:VapSip:715183545743835237>",
    "There's a problem with that. No official novelizations, etc. And using fanfictions put too much weight on limited species\/characters. Nobody wants Ash Ketchum to pop up every time you mention Pokemon.",
    "y21-m06-d21",
    "novelai-discussion"
  ],
  [
    "the furries have noted that Sigurd is good at nonhuman. I'm inclined to agree. It's *way* too good",
    "They have? All I've received is complaints about them not working, and how the AI sticks human bits on everything. <:thonk:733040009136832642>",
    "y21-m06-d20",
    "nsfw-discussion"
  ],
  [
    "\"a foxfolk\" isn't enough by itself, but mentioning that 1) is girl with vulpine ears 2) is 'a foxfolk' whatever that means appears to be good",
    "It might just interpolate fox + folk. There's barely any mentions of 'foxfolk' in the data, only in one LN volume...",
    "y21-m06-d20",
    "nsfw-discussion"
  ],
  [
    "i assume it doesn't know postal\nsad",
    "Doesn't look like it. I submitted a collection of data for 1000 games, but Postal's not on it. Not to mention that it probably didn't make it into Sigurd anyway, submitted it too late.",
    "y21-m06-d20",
    "novelai-discussion"
  ],
  [
    "how much does the game recognize popular media so far? games, movies, comics, tv etc",
    "Depends heavily on the franchise. The most popular ones got included at least, thanks to user-submitted data.",
    "y21-m06-d20",
    "novelai-discussion"
  ],
  [
    "hm, lowercase \" kitsune\" is a bit better than \" Kitsune\"",
    "It should be. Just checked, didn't search the whole dataset (that takes too long), but lower case is far more common for that.",
    "y21-m06-d20",
    "nsfw-discussion"
  ],
  [
    "Zaltys, I remember you from the AiDungeon Discord server.",
    "Yep. And now I'm on NAI team instead.",
    "y21-m06-d19",
    "novelai-discussion"
  ],
  [
    "Because there is a desire for NSFW degen content as well as clean stuff. Make it seperable and tuned for exactly what you want",
    "That's not possible, as the data is in the base model. That was probably from Game of Thrones or something, the AI doesn't know the difference.",
    "y21-m06-d19",
    "novelai-discussion"
  ],
  [
    "Via DM?",
    "Yep. Might also be a good idea to show me an entry before you do more work, so I can tell if something needs to be changed. (...or if we have whatever you're working on already included.)",
    "y21-m06-d19",
    "community-research"
  ],
  [
    "Can I drop a file here?",
    "It'll probably get overlooked here. Toss it at me when finished.",
    "y21-m06-d19",
    "community-research"
  ],
  [
    "How is the lore file formatted?",
    "This is what I used for Pokemon. Which wasn't quite right, but close enough to be easily adjustable.",
    "y21-m06-d19",
    "community-research"
  ],
  [
    "dataset has no league of legends data but imagine the other miss fortunes the AI might think of lol",
    "If the character collection made it in, there's a couple of random entries.",
    "y21-m06-d19",
    "community-research"
  ],
  [
    "He is trying to join my party while stealing my soul",
    "Raise Top-K and Randomness. Repetition penalty doesn't seem to do much by itself if it's already stuck.",
    "y21-m06-d19",
    "novelai-discussion"
  ],
  [
    "But articles on literary analysis in Wikipedia are so few compared to the entire body of text. Could those have changed the weights so much?",
    "The things that worked on AID were generally the subheaders from various author pages. 'Style', 'Themes', etc. These are repeated a lot in wikipedia.",
    "y21-m06-d19",
    "community-research"
  ],
  [
    "But yeah when we reopen for finetune submissions I expect most additions people suggest will get rejected",
    "Suggestions have been high quality for the most part, and I'd be happy to receive more if they're of the same quality.\nThe problem's mostly the original collection.",
    "y21-m06-d19",
    "novelai-discussion"
  ],
  [
    "anyone know what tail-free sampling specifically does? what does having it at 0.95 or 0.05 mean? tooltip is extra vague and doesn't tell you which way it works",
    "0.95 strips the worst 5% of the tokens, iirc. So 0.05 would prune 95%.",
    "y21-m06-d18",
    "novelai-discussion"
  ],
  [
    "<@!409511804293611530> Great oracle, does it read multiple tags? Separated by commas? Is there a list of what tags\/authors\/genres Sigurd uses? Is this too many questions? Are you busy?",
    "Yes, yes, no, no, yes.",
    "y21-m06-d18",
    "novelai-discussion"
  ],
  [
    "I thought the next big model was like 170-something B",
    "13B and 20B, judging by their directory structure. Not that they tend to announce what they're training.",
    "y21-m06-d18",
    "novelai-discussion"
  ],
  [
    "You could try using prose. Zaltys said \n`Author: \nGenre: \nTags:`\nare the format it interprets now. Also give this a read if you have the patience. https:\/\/naidb.miraheze.org\/wiki\/Advanced_Writing#Advanced_Writing",
    "Only for Sigurd, though. I don't think any were tagged back when Calliope was finetuned.",
    "y21-m06-d18",
    "novelai-discussion"
  ],
  [
    "Yeah, I went back to using prose, but I really liked how Zalty's format worked since it was really easy to follow and not forget part of the character",
    "One of the reasons why I made it in the first place. I tend to forget things in prose. Anyway, yeah, the format can't work here as the categories are different. I've done a bit of testing with this style instead -- https:\/\/discord.com\/channels\/836774308772446268\/837581164436258837\/853315205274665000 -- which works okay-ish, but definitely still needs tuning.",
    "y21-m06-d18",
    "community-research"
  ],
  [
    "adding encapsulation to prose helped a little (just < > )",
    "That's curious, considering that it's mostly used for things like thoughts and telepathy in the source data.",
    "y21-m06-d18",
    "community-research"
  ],
  [
    "is it better to go with \"I\" or \"you\" entries?",
    "Definitely first person. This was trained mostly on novels, and 'you' is rare in those. (Actually, I haven't found a single work written in second person yet, going through the dataset.)",
    "y21-m06-d17",
    "novelai-discussion"
  ],
  [
    "What are you recommending now?",
    "Dunno. I spend 100% of my time on data, haven't had time to actually 'play' NAI.",
    "y21-m06-d17",
    "novelai-discussion"
  ],
  [
    "Zalty, using your setting but... Might need to be updated a bit.",
    "That was long ago. Not my fault if users still recommend it.",
    "y21-m06-d17",
    "novelai-discussion"
  ],
  [
    "For influencing the genre you should put something like this in the Author Notes: [Genre: Genre here.]",
    "Spacing is recommended: `[ Genre: ___ ]`, as that's used a lot more in the data.",
    "y21-m06-d17",
    "novelai-discussion"
  ],
  [
    "What's the difference between steampunk and cyberpunk?",
    "1800s versus 2100s. One features steam, brass, and airships, the other cyberware and hacking.",
    "y21-m06-d17",
    "novelai-discussion"
  ],
  [
    "Aw. I really liked forcing eloquent writing styles on the AI",
    "You pretty much have to do that by writing in the style yourself, and letting the AI copy it.",
    "y21-m06-d17",
    "novelai-discussion"
  ],
  [
    "Is anybody else noticing the AI cutting off it's sentences? My maximum output length is 51 tokens and my minimum output is 20 tokens. I'm using Calliope.",
    "Check the `Trim AI Responses` setting.",
    "y21-m06-d17",
    "novelai-discussion"
  ],
  [
    "Wouldn't that cause issues with names? Or nah?",
    "It's either that, or looping. Whichever you can live with, I suppose.",
    "y21-m06-d17",
    "novelai-discussion"
  ],
  [
    "I'm trying to see if `Location: City` or `DESC: human city` would work better to specify what it is, but wondering if someone's beat me to the punch",
    "Probably `Location:`, as I used that in couple of files that I submitted. Whereas `DESC:` is used nowhere. In general, I'd advise against the shortened categories. Those were used out of necessarily in AID, due to the character limit. NAI's limit is token based, so shortening makes no sense.",
    "y21-m06-d17",
    "community-research"
  ],
  [
    "So I guess we're back to having to figure out best practices for NAI then?",
    "The base data is different, and the finetune on top of that is definitely different. So yes, format testing will need to be started from zero. I'd suggest sticking to regular prose until larger models.",
    "y21-m06-d15",
    "novelai-discussion"
  ],
  [
    "Since token limit isn't a problem, we should probably focus on finding keywords for characters and writing style. Tried doing some testing with these https:\/\/justpaste.it\/9ofj1 but so far the only one that seemed to make a difference for me was \"reverie\"",
    "I'd suggest testing `Genre:` or `Tags:` instead of `(Writing) style:`.",
    "y21-m06-d15",
    "novelai-discussion"
  ],
  [
    "So it's likely zaltys format will work in NAI?",
    "It might work to some degree, but there's no reason to use it here. It was built for saving character space, but NAI is entirely token-based so that's pointless here. You don't need to shorten words. Rather, I'd try something more along these lines - https:\/\/discord.com\/channels\/836774308772446268\/837581164436258837\/853315205274665000\n(Though that's equally untested.)",
    "y21-m06-d15",
    "novelai-discussion"
  ],
  [
    "So finetuning and finetuning recommendations will be paused?",
    "I'm perfectly fine with taking further recommendations, but don't expect them to be included anytime soon.\nEverything that's been submitted after I joined has been checked and cleaned (or in some cases, rejected), but older content needs editing and I really should focus on getting that done before adding anything else.",
    "y21-m06-d14",
    "community-research"
  ],
  [
    "I don't know certain things man, I only fap to generic shit",
    "Voyeurism is when you get turned on by watching someone. Not touching, just watching. Stereotypically it's done secretly ('peeping'), but watching a couple have sex (with their permission) is voyeurism too. In short, a voyeur would rather watch (and fap) than participate.",
    "y21-m06-d14",
    "nsfw-discussion"
  ],
  [
    "It\u2019s the same dataset",
    "Sure, but that doesn't mean that 2.7B is able to understand it well enough.",
    "y21-m06-d13",
    "novelai-discussion"
  ],
  [
    "No doubt",
    "Well, 2.7B might not. But the larger ones probably will.",
    "y21-m06-d13",
    "novelai-discussion"
  ],
  [
    "what, you haven't seen this? futa dicks are fucking massive quite frequently",
    "I've definitely seen it. Futa art seems to be hyper more often than not.",
    "y21-m06-d13",
    "nsfw-discussion"
  ],
  [
    "Yeah well good luck at getting anything published as debut author the past year with publishers having a massive backlog to go through due to corona... It's been with several publishers for the past year before being rejected because they had no time to deal with it because unknown author and thus didn't read it.",
    "Yes, I have noticed that trend. 2020-21 are going to be remembered as great years for fiction. We have so much to choose from that unpublished works are out of question.",
    "y21-m06-d13",
    "community-research"
  ],
  [
    "BTW.\nIn AID Sci-Fi was broken. Really. AI was stupid as hell. Prose was very hard to understand. Quite repelling or sth. While fantasy was the best.\nHow good is Sci_Fi in NAI?",
    "Dunno. Haven't seen good prompts for sci-fi. Got any that you'd like to test?",
    "y21-m06-d13",
    "community-research"
  ],
  [
    "325 Fahrenheit? Isn't that extremely hot?",
    "Not for oven. That's only 162 Celcius, I generally use 180-200.",
    "y21-m06-d13",
    "novelai-discussion"
  ],
  [
    "From the finetune material",
    "Working on it here too. With 15K works, it's not exactly one-day project.",
    "y21-m06-d13",
    "novelai-discussion"
  ],
  [
    "Additionally, how are quotation marks handled outside of quotes? For example:\n```Batman has a reputation of being a dark, angst-ridden vigilante. With a gloomy persona and a violent streak, he has earned the title \"The Dark Knight.\"```\n```On the center chest is a red \"S\" within a yellow diamond with a red border.```",
    "I've been using `'` for those, and `\"` for actual quotes.",
    "y21-m06-d13",
    "community-research"
  ],
  [
    "In <#838318340857790524> Zaltys had a few info entry like files, download them and try to imitate the style",
    "Absolutely not. Those are terribly outdated, and I would've deleted them ages ago if the channel was editable. Do not use uppercase categories, those were too 'strong'.\nThis one's more up-to-date: https:\/\/discord.com\/channels\/836774308772446268\/837581164436258837\/851145581586022520",
    "y21-m06-d13",
    "community-research"
  ],
  [
    "Also, I have no idea what this format is exactly, but it probably worked the best in AID: ```[test<test\/123y>;APPEAR<test>:hair<black>\/tall\/muscular;MIND<test>:glutton\/lust\/greedy\/envious\/slothful\/proud ;.]```I found it on this: https:\/\/dwalase.github.io\/aidcreator\/",
    "Appears to be somewhat mangled version of Snek. That was optimized for AID, to reduce the space used. Since NAI works on tokens (and is generally more sane), I'd use something more readable here. Such as... ```[ Character: HK-47; Species: droid (Hunter-Killer series); Appearance: 180 cm, heavy, Reddish-orange metal, robotic, robotic arms, knee-joints, two glowing yellow eyes; Movement: walking (biped); Abilities: blaster rifle; Mind: misanthropic, witty, snarky, loyal, \"This unit is not for sale, meatbag.\"; Traits: disregard of life, loves killing, assassin, programmed by Darth Revan ]```",
    "y21-m06-d12",
    "community-research"
  ],
  [
    "What the colour scheme in the output (specifically <#853095350038167552> )? Pink = input of the user?",
    "Different in each theme. Come to think about it, that's a bit confusing. But ah well.",
    "y21-m06-d12",
    "novelai-discussion"
  ],
  [
    "I believe the Eai boys are working on a 20b model next but this is like 3rd hand information lol.",
    "I'm pretty sure they're planning 13B model first.",
    "y21-m06-d12",
    "novelai-discussion"
  ],
  [
    "took me ages to get back off the ground.",
    "You probably shouldn't be on Discord, then. If it hurts that much after the fall, then it's pretty bad.\nI mean, when I broke my ribs last year, it didn't even start hurting until after ~10 minutes. Could still get up and walk around for a while, enough to get into emergency.",
    "y21-m06-d12",
    "novelai-discussion"
  ],
  [
    "Guys, I have an questions about NAI:\n1. How does NAI handle NTR\/cuck stuff?\n2. Is it trained on such content too?\n3. Can users suggest some books for training data?",
    "3. We've said this about thousand times by now, but... yes. You can send me a DM and I'll try to get around to replying in the near future. If you post it on the channel, it's likely to get overlooked.",
    "y21-m06-d12",
    "community-research"
  ],
  [
    "I am not familiar with this Harkness test.",
    "https:\/\/i.kym-cdn.com\/photos\/images\/original\/001\/262\/021\/031.jpg",
    "y21-m06-d11",
    "nsfw-discussion"
  ],
  [
    "Horus is the god of knowledge",
    "Thoth?",
    "y21-m06-d11",
    "novelai-discussion"
  ],
  [
    "Muses and demigods makes way more sense",
    "Either way, those will get pretty hard to remember once there are more models.\nUnintuitive compared to OpenAI's naming system (which is alphabetical. Ada, Babbage, Curie, Davinci...)",
    "y21-m06-d11",
    "novelai-discussion"
  ],
  [
    "btw how does the token ban list work with words that contain multiple tokens?",
    "It doesn't block words, it blocks tokens. If you add a 'word', it'll add the tokens from that word to the list.",
    "y21-m06-d11",
    "novelai-discussion"
  ],
  [
    "It was the strangest thing, we had not even talked about it. One day we were just googlin and he was like \"dude did u see this family gangbang porn video\" and im like nah and hes like \"lemme find it bro its so good\"",
    "Damn, access to porn is so easy these days.\nBack in my day, before the internet, we had porn logs. Hiding places in the wood where we stored printed porn (nobody was dumb enough to hide those at home). Pretty much every teen in the area knew about those caches.",
    "y21-m06-d11",
    "nsfw-discussion"
  ],
  [
    "you thrust, hard.. you push past her cervix and penetrate deep into her womb, your cum completely floods her ovaries, she is surely pregnant again, despite having just given birth",
    "But that's not... how anything works. Uterus is at an angle, so unless the character has an L-shaped dick, it's not penetrating the womb. Normal-shaped penis is going to push past the cervix (instead of into it) and hit the vaginal back wall.",
    "y21-m06-d11",
    "nsfw-discussion"
  ],
  [
    "actually, dumb question, but does finetuning remove the default stuff or add on top of it",
    "Hm. Let's say that it _adjusts_ the existing data. That's probably the easiest way to explain it.",
    "y21-m06-d10",
    "novelai-discussion"
  ],
  [
    "We'd use the same finetuning data",
    "No, we'll use improved data. There's some things that larger models can handle better.",
    "y21-m06-d10",
    "novelai-discussion"
  ],
  [
    "Is the collection of novels it's trained on pretty exclusively \"respectable\" fiction or do we have genres represented too?",
    "If you mean finetuning solely on Gutenberg and other 'classics'? Urgh, no. We don't want an AI that talks like it's out of 1800s. There's plenty of variety.",
    "y21-m06-d08",
    "novelai-discussion"
  ],
  [
    "The furry chart: https:\/\/i.imgur.com\/UGRGkXf.jpg",
    "2nd: Furry but in denial.",
    "y21-m06-d08",
    "nsfw-discussion"
  ],
  [
    "For me Dragon did great sarcasm",
    "Two scientists, talking about which animals to uplift.",
    "y21-m06-d07",
    "novelai-discussion"
  ],
  [
    "Rogue could be a character in Star Wars, Warhammer, Marvel, and, DC.",
    "...or even Sonic. (Considering how often Rouge gets misspelled.)",
    "y21-m06-d07",
    "novelai-discussion"
  ],
  [
    "I dunno about that. A lot of Junji Ito's stuff is completely unrealistic but still creepy as shit.",
    "Oh yes. I read so much horror as a kid that it kinda... stopped feeling scary. But Ito's still creepy.",
    "y21-m06-d06",
    "nsfw-discussion"
  ],
  [
    "```[ Species: Pidgey (Tiny Bird Pok\u00e9mon) ] [ Type: Normal\/Flying ] [ Egg group: Flying ] [ Movement: flying walking (biped) ]\n[ Evolution: Pidgey evolves into Pidgeotto starting at level 18, which evolves into Pidgeot starting at level 36. ]\n[ Size: 1 ft | 30 cm (small) ] [ Weight: 4 lb | 2 kg ]\n[ Biome: Kanto and Johto, forests, fields, grasslands, and cities ]\n[ Ability: Keen Eye, Tangled Feet, Big Pecks ] [ Moves: Gust, Sand Attack, Twister, Agility, Wing Attack Roost ]\nDiet: Pidgey seek out insects in tall grass, though they will also eat seeds.\nCare: The Pidgey line is another family of Pok\u00e9mon well-suited for beginners, as they are very easy to raise. All members of the line can find food on their own, though they will eat meals given to them by their trainers without any qualms. Pidgey are not avid fliers, but their evolutions are, and need ample room to do so.\nCaution: Pidgey and their evolutions pose little threat to trainers who respect their space. Pidgey are skittish, however, and will whip up small gusts that can knock people over when startled.```",
    "And that's not all of it. It just doesn't fit into the Discord character limit. I already have the exact data that Molamola1812 posted in there. For all species.",
    "y21-m06-d06",
    "community-research"
  ],
  [
    "also btw if <|startoftext|> happens to be at the beginning of every AID [user] story I'm going to <:KEKW:627956889086591024>",
    "Thanks for the reminder. I need to check the dataset to make sure nobody sneaked that in.",
    "y21-m06-d06",
    "novelai-discussion"
  ],
  [
    "is the ai being finetuned with other languages?",
    "Each additional language would make it worse at English, so no.",
    "y21-m06-d06",
    "novelai-discussion"
  ],
  [
    "No, that's probably tokenization, because the AI reads Anthony as Ant|hony.",
    "No, Anthony is single token. No idea why that'd get shortened.",
    "y21-m06-d06",
    "novelai-discussion"
  ],
  [
    "oh, it gets removed if it drops below 1",
    "...drops below 1, when 1 is the minimum rating? How?",
    "y21-m06-d05",
    "novelai-discussion"
  ],
  [
    "I can do a fairly easy text scraper and run it through the list, then just mass search on a novel index and scrape the authors names",
    "Scrape the author names from where? The file names aren't standardized, due to multiple uploaders. And we've pruned those from the text itself.",
    "y21-m06-d05",
    "novelai-discussion"
  ],
  [
    "<@!409511804293611530> How hard would it be to scrape the current list and add an author tag into the data?",
    "I can't think of any way to do that, except by doing it manually. And considering the size of the collection at this point, it'd be quite a project.",
    "y21-m06-d05",
    "novelai-discussion"
  ],
  [
    "*speaking of finetuning, hows it going?*",
    "It's going. I haven't done much else for a month, still a lot that I'd like to add... but the important data is in.",
    "y21-m06-d05",
    "novelai-discussion"
  ],
  [
    "You guys know if the Overwatch books are included in the AI model?",
    "Hm, I don't think so. Would be easier to check if I knew the authors. What I see on Goodreads with search for `Overwatch` is mostly comics and unrelated books...",
    "y21-m06-d04",
    "community-research"
  ],
  [
    "Oh I'm gonna send it when I'm done, sorry. I should've been clearer. I wanted to know if the line breaks were correct.",
    "Wait, why are you working on Jekyll and Hyde?",
    "y21-m06-d04",
    "community-research"
  ],
  [
    "Zaltys' pokedex, which they posted here or over in <#838318340857790524> is a good example of how to do more encyclopedic stuff.",
    "Actually, that didn't work out well. It has been heavily adjusted since that original version. Among other things, the AI started copying everything from the `SPECIES` field. Had to prune that down just to `Species: Bulbasaur` etc and moved the type into its own category.",
    "y21-m06-d03",
    "community-research"
  ],
  [
    "If it helps, you can find examples of what a proper finished scrape\/formatted story looks like in <#838318340857790524>",
    "Those were put together in a hurry. Don't use them as examples.\nFor instance, uppercase categories seem too strong to be used.",
    "y21-m06-d02",
    "community-research"
  ],
  [
    "i just need to know how to pack together the wiki data into files",
    "Depending on the amount of text, you can just combine them into one file. Entries separated with something like `***`. Makes it far easier to handle.",
    "y21-m06-d02",
    "community-research"
  ],
  [
    "So do fanfics have to be on the same tier as published works or you're just saying not to go on Wattpad",
    "If it's full of typos and poor writing, then it won't get used. And the favcount is not ~~always~~ a reliable indicator of the quality.",
    "y21-m06-d02",
    "community-research"
  ],
  [
    "Should I put recs here to be screened or just put them here after formatting them",
    "Just put in the recommendation, I can handle the work.",
    "y21-m06-d02",
    "community-research"
  ],
  [
    "A story where I'm a sentient exploration spaceship",
    "Well, good that I added sentient spaceships to the finetuning material, then. Though 2.7B is probably too small for that, might have to wait for 6B.",
    "y21-m06-d01",
    "novelai-discussion"
  ],
  [
    "Best thing for character details atm would be a dense WI format like Zaltys.",
    "Dunno about that. My formats were built to cram as much data as possible into the character limit. Since NAI uses token limit instead, there's several things I'd do differently.",
    "y21-m06-d01",
    "novelai-discussion"
  ],
  [
    "Yeah I read that. Some excellent writing spanning a good variety of settings and genres. All his work is public domain and should be free online",
    "Cleaned and submitted. Not up to me which model(s) it gets included in, but it's there.",
    "y21-m05-d31",
    "community-research"
  ],
  [
    "Can I suggest Algernon Blackwood short stories such as The Willows or the Wendigo? A good example for the AI of how to write A) natural settings and B) horror that doesn't rely on jumpscares and instead manages the \"creepy\" factor well. One of my favorite authors.",
    "Not an author that I'm familiar with, but looks promising. Would unabridged Collected Works be a good pick?",
    "y21-m05-d31",
    "community-research"
  ],
  [
    "no clue how true that is tho",
    "Nah, Finland's gone downhill. I'd say France, if you don't mind the language.",
    "y21-m05-d31",
    "nsfw-discussion"
  ],
  [
    "If we cannot terraform Earth, we cannot terraform Mars.",
    "Except Mars has no population, so terraforming is considerably easier.",
    "y21-m05-d31",
    "nsfw-discussion"
  ],
  [
    "let me see if i understood this.\n\nbecause the *training data* has ben manually tagged with writing style hints, including the description of the writing style in the prompt makes the AI associate the prompt with training material also tagged with that authors note\n\ncorrect?",
    "I think the writing style comes mostly from the wikipedia data. Common Wikipedia categories were always strong in WI formats, and Neo uses same wiki data.",
    "y21-m05-d31",
    "community-research"
  ],
  [
    "he made japanese hentai censored",
    "Well, I suppose that's unfair. There was already plenty of censorship in Imperial Japan, so he didn't add it. Although MacArthur removed most of other kinds of censorship, he made an exception for porn censoring. Not only was it made stronger, but he cracked down on prostitution.",
    "y21-m05-d31",
    "nsfw-discussion"
  ],
  [
    "ok but why were penises censored in japan",
    "Because the guy in charge of the occupation (https:\/\/en.wikipedia.org\/wiki\/Douglas_MacArthur) was a puritan.",
    "y21-m05-d31",
    "nsfw-discussion"
  ],
  [
    "Is that why the penises are censored with 1-2 black bars?",
    "Right. The censoring used to be much more severe, but the artists have kept pushing the limits of the law by making the bars smaller and smaller. Following the letter -- but not the spirit -- of the law.",
    "y21-m05-d31",
    "nsfw-discussion"
  ],
  [
    "Wait America is the reason for that?",
    "Yep. And that's how it ended up in the post-war constitution. Which is why it hasn't been changed yet... changing the constitution is a big deal in any country.",
    "y21-m05-d31",
    "nsfw-discussion"
  ],
  [
    "How's the Mass Effect stuff coming?",
    "I collected all the species lore and a few other things from the tabletop version, it's extensive enough.",
    "y21-m05-d30",
    "feedback-discussion"
  ],
  [
    "Sure, saying you're a furry is enough to be one I guess. But refuting being a furry when you are obsessed by wolves and find a she-wolf with boobs hot, heh",
    "Dunno, sometimes it's broader than being a 'furry'. For instance, I wouldn't call xenophile a furry just because they find anthro aliens hot (because they find a lot of other things hot too.) I feel like you need to be attracted _mainly_ to anthros to count as furry.",
    "y21-m05-d29",
    "nsfw-discussion"
  ],
  [
    "managed to find some pokemon at least so it knows pop culture, I guess.",
    "It will know that species _x_ is a pokemon, but it will not be able to accurately (or consistently) describe them.",
    "y21-m05-d29",
    "novelai-discussion"
  ],
  [
    "Will there be a tutorial that tells you what everything after randomness is? Cause I have no clue what you just listed",
    "There's tooltips.",
    "y21-m05-d29",
    "feedback-discussion"
  ],
  [
    "I wrote to the fandom administrators and got the Pathfinder dump page updated \ud83e\udd73",
    "Nice to have the permission for those, although a lot of that data is going to be pain to clean up.",
    "y21-m05-d29",
    "community-research"
  ],
  [
    "Sorry, but it has lists on which works have been turned into data, but not, say, a format on what Datasets should look like. Any of those?",
    "I already edited that. First pin in research.",
    "y21-m05-d29",
    "nsfw-discussion"
  ],
  [
    "Good to hear\nDo you have any infos if 6B will be ready for beta or not?",
    "No comment.",
    "y21-m05-d29",
    "nsfw-discussion"
  ],
  [
    "Are they going to be accepting more data? If so, I'll work on turning some stuff into .txt files.",
    "Of course. Won't make it into current finetunes, but there'll be more in the future. And larger models.",
    "y21-m05-d29",
    "nsfw-discussion"
  ],
  [
    "Would the AI be fed on the classics of \"adventure\" literature, or would be more recent positions? \ud83e\udd14",
    "...positions? There's a lot of modern fantasy literature in the dataset, if that's what you're asking.",
    "y21-m05-d29",
    "nsfw-discussion"
  ],
  [
    "https:\/\/pile.eleuther.ai\/ sort it out yourself.",
    "To make it clear (again), this is not used to finetune the AI. It's what's already there in base GPT-Neo, in form of token pairs and such.",
    "y21-m05-d29",
    "community-research"
  ],
  [
    "<@!804869431431528479> we have already got it, just needs a tweak\n\nhttps:\/\/cdn.discordapp.com\/attachments\/837402685824565278\/848117534661541918\/unknown.png",
    "As a collector, seeing that makes me cringe. Poor book.",
    "y21-m05-d29",
    "novelai-discussion"
  ],
  [
    "having 'say' is kinda redundant when you can just type: I say \"this\".",
    "Not to mention that formatting it that way leads to poor quality output. `\"[...]\", Zak says.` is used far more in fiction.",
    "y21-m05-d29",
    "novelai-discussion"
  ],
  [
    "my second thought was \"that's awfully small for a horse\", followed immediately by \"wait, i don't know how large a vaporeon is\"",
    "Vaporeon are actually pretty large by pokedex (1 m \/ 3 ft 3 in), the anime just makes all eeveelutions small for some reason.",
    "y21-m05-d29",
    "nsfw-discussion"
  ],
  [
    "",
    "These won't do.\n- Wrong encoding.\n- You need to remove the chapter headers and numbers.\n- And the tabs.\n- Titles need cleaning too. No  `MY ADOPTED FATHER Compassion.`, etc.",
    "y21-m05-d29",
    "community-research"
  ],
  [
    "So if I wanted a book recommended I would have to literally type out the entire book as a .txt file then?",
    "No. I can just find it myself if it's good enough suggestion.",
    "y21-m05-d28",
    "community-research"
  ],
  [
    "But it can be included if someone wants to push it?",
    "A lot of novels include those topics. Game of Thrones, for instance. I can't speak for others, but the material I've submitted has been curated based on quality and how well it fits the theme of the model, nothing else. ('course, it's not up to me which of those get used.)",
    "y21-m05-d28",
    "feedback-discussion"
  ],
  [
    "Can you say who the NDA is with or is that prohibited?",
    "Latitude and OpenAI. I'm no longer afflicted with either, but bound by the NDA.",
    "y21-m05-d27",
    "community-research"
  ],
  [
    "Thanks for clearing that up. Do we already have most stuff on Shin Megami Tensei demons? The pages on them are pretty good about Etymology and appearance descriptions.",
    "I've submitted the demons from Ars Goetia, those overlap somewhat with SMT (and many other franchises). Beyond that, no SMT data as far as I know.",
    "y21-m05-d25",
    "community-research"
  ],
  [
    "So, what can we get fit in? Just cleaned up dialogue transcripts from games and movies? I'd like to help out while I can.",
    "High-quality prose would be good. High-quality prose that covers areas that the AI isn't good at would be even better. That includes material that covers franchises that are missing from the Pile. For example, it is lacking in video game character data. If the character is not on the wikipedia, then it's likely not in the Pile either. \n\nGathering character data from sites such as hero.fandom.com would be useful, but needs to be pruned down to personality\/appearance\/background: the data should contain only lore and other fluff, without references to specific franchises or game terminology. \n\nAnd books like tabletop manuals need major clean up to be usable. We don't want dice rolls and such to pop up randomly in the text.",
    "y21-m05-d25",
    "community-research"
  ],
  [
    "I was just going to play Mass Effect. lol",
    "That gave me an idea... I'm gonna grab the species from the Mass Effect tabletop game and submit those. Since the wiki scrape isn't working out.",
    "y21-m05-d25",
    "novelai-discussion"
  ],
  [
    "TESLore: UESP dump with all lore articles (all books from all games and every lore article in the wiki)",
    "A lot of these have been added. I've already cleaned and submitted all the books from Skyrim.",
    "y21-m05-d25",
    "community-research"
  ],
  [
    "Know the word count for 30mb?",
    "5.6 million.",
    "y21-m05-d23",
    "novelai-discussion"
  ],
  [
    "...alright I've been wondering for a while so I'll just ask straight up: [NSFW] Were Snekguy's stories included in the finetuning? If not, would recommend.",
    "I certainly wouldn't mind if those were included. I thought of submitting some, but not sure how 'relevant' they're to the current model.",
    "y21-m05-d23",
    "community-research"
  ],
  [
    "Alright, I'll post an example later and you can tell me how I did. Should I update my Dragon anatomy data then?",
    "Actually, I just remembered that the D&D entries used `Habitat\/Society:` and `Ecology:` headers. So you might try those.",
    "y21-m05-d23",
    "community-research"
  ],
  [
    "Ah, okay. But I should title\/divide it with ```DRAGONBORN:```",
    "Like I said, uppercase didn't work well. Resulted in some ugly output. Already switched to proper-case categories in my new data.",
    "y21-m05-d23",
    "community-research"
  ],
  [
    "Thanks for the feedback. This brings me into my other question: how should I go by dividing different types of information? Should I just go ```DRAGONBORN: [information]``` or should I go ```DRAGONBORN: DESCRIPTION: [information] CULTURE: [information]```",
    "I'm currently using `Species:` header, as upper-case didn't seem to work well in practice. The main thing is that there should be something after the `:` (instead of line-break), if you're using those.",
    "y21-m05-d23",
    "community-research"
  ],
  [
    "Do we have significant data on some of the more exotic d&d\/Pathfinder races?",
    "Some data? Yes. Significant amount of it? No. Pruning out game terminology is slow work. So those should help. But I'd recommend putting those on the same line, as in `DRAGONBORN: Dragonborn resemble...` etc.\n\nI've been planning to work on Pathfinder Bestiary (the first one), but I'm currently busy with a large project (updating the Pokemon data with additional content, such as data about the regions. Up to Unova at the moment.)",
    "y21-m05-d23",
    "community-research"
  ],
  [
    "some guy used special chars on aid and actually managed to get to 1800+ tokens in lmi within the char limit. guess they didn't actually put a token limit in place",
    "That was pretty easy to do with single-character tokens. But as far as I could tell in my tests, it got pruned at some point. Sure, it showed up in the LMI, but AI would completely ignore everything over 1024 tokens. ...or at least I couldn't get it to react to those.",
    "y21-m05-d22",
    "novelai-discussion"
  ],
  [
    "Any roman stuff like I, Claudius?",
    "There might be something, but none that I remember offhand. We didn't have much time to collect material for the first finetune, some things likely got missed. ...Flashman would've been good for Adventure. Maybe for larger models...",
    "y21-m05-d22",
    "novelai-discussion"
  ],
  [
    "I wonder if throwing some historical fiction into the finetune would be a good idea (if they didn't do that already.)\nLike <https:\/\/en.wikipedia.org\/wiki\/Romance_of_the_Three_Kingdoms> or <https:\/\/en.wikipedia.org\/wiki\/The_Three_Musketeers>",
    "_Romance of the Three Kingdoms_ was already added. As was _Journey to the West_ and _Legend of the Condor Heroes_.",
    "y21-m05-d22",
    "novelai-discussion"
  ],
  [
    "how would it perform if you asked it to program something in python?",
    "```print(\"{}\", name)\nif __name__ == '__main__':\n    import sys\n    if len(sys.argv)!= 2:\n        print(\"Please specify a name or directory path\")\n    else:\n        rootdir = os.getcwd()\n        file = open(\"file.txt\", \"w+\")\n        file.write(\"Name: {0}\".format(name))\n        file.close()\n        print(\"You have created your first project.\" + \"\\n\")```  <:shrug:332268181517238272>",
    "y21-m05-d21",
    "novelai-discussion"
  ],
  [
    "What does boosting a discord server do anyway?",
    "Not much. Extra emoji, better audio quality... And 30 boosts is the cap, so the current 42 is excessive.",
    "y21-m05-d20",
    "novelai-discussion"
  ],
  [
    "_Cookin' Cum_",
    "https:\/\/www.goodreads.com\/book\/show\/5830947-natural-harvest---a-collection-of-semen-based-recipes",
    "y21-m05-d19",
    "nsfw-discussion"
  ],
  [
    "Will author's notes have similar functionality in NovelAI or were they a result from the fanfiction used to train AID's models?",
    "These are likely from the Pile itself. A lot of novels have author's notes, after all.",
    "y21-m05-d18",
    "novelai-discussion"
  ],
  [
    "Wasn't it AO3?",
    "Dunno about that, but among other things, this was included: https:\/\/tvtropes.org\/pmwiki\/pmwiki.php\/WebOriginal\/Geek (See the first entry on the list.)",
    "y21-m05-d18",
    "nsfw-discussion"
  ],
  [
    "Ofcourse I don't mean non English text, lots of language don't use English characters lol and it would be a cluster fuck, what I meant to ask is that can english encyclopedias with names and cities\/novels which can give insight into the culture for major countries  be used so that the ai won't get retarded when talking about countries other than USA",
    "Throwing in some travel adventure novels would've been nice. I was planning to find some, but ran out of time for this finetune. Some Chinese and Indian literature made it in, but those are historical\/fantasy. So the AI's view of modern China might turn out to be... 'interesting'.",
    "y21-m05-d17",
    "feedback-discussion"
  ],
  [
    "where can i find the link to the python",
    "Just follow the instructions in https:\/\/github.com\/KoboldAI\/KoboldAI-Client; it has links to everything you need.",
    "y21-m05-d17",
    "novelai-discussion"
  ],
  [
    "Has the AI been trained on any furry stuff yet?",
    "The Pile has some. As for finetuning, I think Alan Dean Foster's Spellsinger series made it in. And there were quite few 'anthro' races the D&D monster manual data that I submitted, though I ran out of time with that and missed some of the major ones. ...there were also suggestions for scifi-books that feature anthroish species, such as Becky Chamber's Wayfarers series (http:\/\/www.hodderscape.co.uk\/wp-content\/uploads\/2017\/07\/Wayfarer-Fan-Art-Competition.png), but I'm unsure if those got in.",
    "y21-m05-d14",
    "feedback-discussion"
  ],
  [
    "Sure, things can go wrong. But GPT-3 isn't magical alien tech. Sooner or later, it can be replicated.",
    "Neo is better than GPT-3 ada in all the comparison tests I've seen. Though that's not saying much, as hardly anyone's tried ada.",
    "y21-m05-d13",
    "nsfw-discussion"
  ],
  [
    "PMD1 and PMD2 baby",
    "PMD, as in Pokemon Mystery Dungeon? I don't remember the games having much usable narrative. Though if you can find some quality PMD fanfiction, that might make the cut. But that would've been most appropriate for the Adventure model, which is already in training.",
    "y21-m05-d12",
    "community-research"
  ],
  [
    "It's primarily novels and light novels, correct?",
    "As far as I know, yes.",
    "y21-m05-d11",
    "novelai-discussion"
  ],
  [
    "actually here's a thought; are there any mystery\/detective novels in the training data?",
    "Of course there are. There's over 230,000 books in the Pile. But if you mean finetuning, then not a lot. This model focused on Adventure, not Mystery.",
    "y21-m05-d11",
    "novelai-discussion"
  ],
  [
    "I wonder how much of Brandon Sanderson's material is in the training data",
    "~65 books (in the Pile). I'm not gonna count how many of those are duplicates.",
    "y21-m05-d11",
    "novelai-discussion"
  ],
  [
    "I assume the NAI's AI will be fed some anthropomorphic animal stuff though? It would be neat if so.",
    "I think some anthro novels got in, but don't quote me on that. Alan Dean Foster (Spellsinger series), and some more obscure books.",
    "y21-m05-d11",
    "novelai-discussion"
  ],
  [
    "Speaking of, I feel like this may be a better source for making a nsfw dataset compared to trying to scrape ao3, fanfiction etc https:\/\/www.literotica.com\/beta\/stories\/",
    "There's already 12GB of literotica here, but I dunno how it was picked: https:\/\/the-eye.eu\/public\/AI\/pile_preliminary_components\/",
    "y21-m05-d11",
    "nsfw-discussion"
  ],
  [
    "They could even make them accessible for the users",
    "This would be a good idea. ...if the users can see how hard it is to set a good balance for that, maybe there'll be less complains about the AI being 'too repetitive'.",
    "y21-m05-d11",
    "novelai-discussion"
  ],
  [
    "Kobolds are a no-brainer, though that falls under lizardfolk. Most [monster]girls also work, though I haven't tried that since the crusade.",
    "It was pretty bad at kobolds, from what I saw. Always adding hair and forgetting that they have scales\/tail. (Nothing that WIs didn't fix, of course.)",
    "y21-m05-d11",
    "nsfw-discussion"
  ],
  [
    "I wonder, for those who have toyed with GPT-Neo, would you say it's capable of keeping track of comparisons consistently? For example, someone being taller than another and referencing it.",
    "This is more of an issue with the tokenizer, as it chops up some of the numbers which makes them ~~hard~~ impossible for the AI to compare.",
    "y21-m05-d10",
    "novelai-discussion"
  ],
  [
    "But just to rephrase, what will players be looking for in the *alpha*?",
    "The usual alpha testing stuff: poking at things and seeing if you can break them.",
    "y21-m05-d10",
    "novelai-discussion"
  ],
  [
    "They're two competely different phases of development.",
    "Alpha will last a couple of days, maybe a bit more. There's no harm in talking about beta in advance.",
    "y21-m05-d10",
    "novelai-discussion"
  ],
  [
    "Alpha isn't beta, beta is the nearly finished product. <:WaitWhat:839168930118500362>",
    "What do you think comes after alpha? <:confusion:655176671451807745>",
    "y21-m05-d10",
    "novelai-discussion"
  ],
  [
    "Closed beta lmao",
    "https:\/\/discord.com\/channels\/836774308772446268\/837402685824565278\/840976486886670336",
    "y21-m05-d10",
    "novelai-discussion"
  ],
  [
    "not too big on utilizing my mail for ai schmuck, so i'm waiting for a tutorial on running gpt-neo locally",
    "If you have hardware for it, just go here and follow instructions: https:\/\/github.com\/KoboldAI\/KoboldAI-Client",
    "y21-m05-d09",
    "novelai-discussion"
  ],
  [
    "That's right, putting pineapples on pizza",
    "Pineapple and ham is the most popular pizza everywhere in Scandinavia.",
    "y21-m05-d09",
    "novelai-discussion"
  ],
  [
    "Hey I would like to contribute something for the project. Would this be a good book to add to the training set? It has a lot of fluff regarding mech info and some battle tech lore in general.",
    "With three columns, this would be a pain to edit - not to mention it'd require a lot of menial work. I can almost guarantee that it wouldn't make it in. If you can find similar data on some wiki and collect that, it'd be much better.",
    "y21-m05-d08",
    "community-research"
  ],
  [
    "also please fucking shoot the next person that posts a suggestion along the vein of 'please have the AI read this single individual book'\n\njesus christ how annoying",
    "A lot of the suggested books made it in. If anything, more suggestions would be nice. It's easy to overlook something, especially among more obscure books.",
    "y21-m05-d08",
    "novelai-discussion"
  ],
  [
    "we can always update the model by finetuning with new data.",
    "Oh. I better get back to work then; got a few ideas for more scifi\/fantasy to add. (...and a couple of books to scan from my own collection.)",
    "y21-m05-d08",
    "community-research"
  ],
  [
    "b\/c the davinci model is much smarter than the caliber of intelligence shown by the current AI Dungeon",
    "I think Dragon's davinci, but lobotomized by all the output biases Latitude uses.",
    "y21-m05-d08",
    "novelai-discussion"
  ],
  [
    "how",
    "OpenAI beta. Invite only.",
    "y21-m05-d08",
    "novelai-discussion"
  ],
  [
    "I vore chicken",
    "I'm pretty sure you don't swallow them whole.",
    "y21-m05-d07",
    "nsfw-discussion"
  ],
  [
    "Grab the development branch of it (https:\/\/github.com\/Gnurro\/FinetuneReFormatter\/tree\/development), install the requirements in requirements.txt, then run baseGUI.py and tell me which libs\/modules are missing to run it.",
    "No problems with 3.9.0.",
    "y21-m05-d07",
    "novelai-discussion"
  ],
  [
    "What's the next planned weight then? I thought it was sub double digits.",
    "```eleutherai\/gpt-neo-pile-1.3B\neleutherai\/gpt-neo-pile-2.7B\neleutherai\/gpt-jax-pile-6B\neleutherai\/gpt-jax-pile-13B\neleutherai\/gpt-jax-pile-20B\neleutherai\/gpt-neox-pile-175B``` That seems to indicate what their plans are.",
    "y21-m05-d06",
    "novelai-discussion"
  ],
  [
    "Gnurro writes more comments than code",
    "Definitely better than my style of writing no comments. Can't make any sense of my own code months later.",
    "y21-m05-d06",
    "community-research"
  ],
  [
    "Check the gitlab pin in <#837259157538340864>",
    "That's just some of the suggestions. Maybe 1% of what went in.",
    "y21-m05-d06",
    "novelai-discussion"
  ],
  [
    "ancient history? like mesopotamian bronze age shit?",
    "Wikipedia is in the Pile, as are hundreds of history books. There's 250K+ books in total in it.",
    "y21-m05-d06",
    "novelai-discussion"
  ],
  [
    "Maybe use BERT (language model) to fill in the redacted ? <:schizo:837170919448248331>",
    "Maybe use Kyros.",
    "y21-m05-d06",
    "community-research"
  ],
  [
    "What exactly is the finetuning model? I was under the impression that the AI model is trained and that's it.",
    "Think of the base as a factory. And finetuning as retooling the factory.",
    "y21-m05-d06",
    "novelai-discussion"
  ],
  [
    "Do you know if the devs have planned to release different models(like AID had both Griffin and Dragon) ?",
    "```Dataset curation focus:\n1. ADVENTURE (novels + translated light novels) -> first model we will train\n2. GENERAL LITERATURE\n3. HORROR``` But these are more like Lovecraft model than Griffon vs Dragon.",
    "y21-m05-d06",
    "novelai-discussion"
  ],
  [
    "Wouldnt scp be rather dry?",
    "Barely a drop in the ocean, considering the novels that are used in finetuning. Though the redacted text is a potential problem. It can't even be easily edited out..",
    "y21-m05-d06",
    "community-research"
  ],
  [
    "Why Giant Bomb specifically? Also I would assume the video game pages on wikipedia would serve just as well",
    "Wikipedia is already included. What's missing is the more obscure characters and games. And even for popular games, Wikipedia rarely goes into details.",
    "y21-m05-d06",
    "community-research"
  ],
  [
    "I've actually imagined that myself. What do you imagine it would do?:)",
    "It'd be chill with it. Any true AI trained on sum of humanity's knowledge will recognize things such as taboos as contradictory, subjective, and a bit silly.",
    "y21-m05-d06",
    "nsfw-discussion"
  ],
  [
    "Edited and published erotica would likely help to the quality and cohesiveness of NSFW",
    "If my suggestions go through, then at least a few of such books will be included. ||And also some published furry content.||",
    "y21-m05-d05",
    "nsfw-discussion"
  ],
  [
    "Can we input texts of our own or pdfs to train the AI?",
    "Dunno about the policy on own texts, but PDFs don't usually convert well. Other formats would be better.",
    "y21-m05-d05",
    "feedback-suggstions"
  ],
  [
    "I have a question: what do you think is a better method for NSFW implementation? Would it be a filter applied after the fact, or creating 2 models, one with NSFW, one without?",
    "NSFW is built in Neo, just like it was built in GPT-3. There's no 'without'.",
    "y21-m05-d05",
    "community-research"
  ],
  [
    "<@!409511804293611530> Literally every book or dataset is somewhere in the pile imo (at least partially)",
    "Almost, though so far I've forward about thirty books that weren't.",
    "y21-m05-d05",
    "community-research"
  ],
  [
    "That\u2019s my question. Will AI dungeon censor my content if she\u2019s a 9000 yo dragon",
    "Considering that they seemed eager to ban all beast stuff too, that seems likely.",
    "y21-m05-d04",
    "nsfw-discussion"
  ],
  [
    "I was thinking maybe Forgotten Realms, since AID's knowledge of Forgotten Realms was all over the place. The setting itself though is also all over the place (go figure). Another option is Dragonlance, which would reinforce AI's considerable knowledge from Books3. Pathfinder\/Golarion might also work but there's no precedence for that in the training data from what I've seen",
    "Most of the older Volo's guides are already in prose, but unfortunately all I could find were pdfs that didn't convert well.",
    "y21-m05-d04",
    "community-research"
  ],
  [
    "<@409511804293611530> Checked a few entries in your Pok\u00e9mon description list, found this spelling error on Ralts\n\n\"SIZE: 1ft4in\/40cm\nalts is a humanoid...\"",
    "Thanks. ...I hate how Discord doesn't allow replacing documents. Guess I'll have to reupload it to fix that.",
    "y21-m05-d04",
    "novelai-discussion"
  ],
  [
    "Hey Zaltys, since you're overseeing a lot of the book suggestions, how do we know if the titles we suggested have been seen\/reviewed by somebody for fine tuning?",
    "Dunno. I'm not overseeing them, I've only checked what's available in the Pile. Too busy working with these entries to start handling the books.",
    "y21-m05-d03",
    "feedback-discussion"
  ],
  [
    "They might already be in Neo's base training, what happens when it is finetuned on stuff it already knows?",
    "Check the sticky in <#838318340857790524>",
    "y21-m05-d03",
    "feedback-discussion"
  ],
  [
    "Also <@!784998701818445845> can you put some type of thing in <#837077266918932512> which says \"stop suggesting books to add\", it's kinda getting annoying",
    "A lot of the suggested books are going to be added.",
    "y21-m05-d03",
    "feedback-discussion"
  ],
  [
    "What book is that though?",
    "https:\/\/www.goodreads.com\/book\/show\/920395.Only_Forward",
    "y21-m05-d03",
    "nsfw-discussion"
  ],
  [
    "<|endoftext|> should go between unrelated documents",
    "~~So I should remove it altogether from that list?~~  Okay.",
    "y21-m05-d03",
    "feedback-discussion"
  ],
  [
    "You mean that you are converting like removing or changing to sth is common, rare etc?",
    "Yep.",
    "y21-m05-d02",
    "feedback-discussion"
  ],
  [
    "The second sentence here is a little bit scary...",
    "Mostly converting dice rolls, rounds etc into text. Movement types into actual words, etc. Having the full of sentences like `this effect lasts for 2d6+6 rounds` wouldn't be good for tuning.",
    "y21-m05-d02",
    "feedback-discussion"
  ],
  [
    "Is there any way to search the pile without downloading? I'd gladly check if I have something that's not included there yet",
    "The whole pile? Not as far as I know.",
    "y21-m05-d02",
    "feedback-discussion"
  ],
  [
    "Does anyone know if any of Alan Dean Foster's books are in that sci-fi archive?",
    "```Alan Dean Foster - Catechist 02 - Into the Thinking Kingdoms [retail]\nAlan Dean Foster - Damned 99 - The Damned Trilogy [retail]\nAlan Dean Foster - Exceptions to Reality [SSC] [retail]\nAlan Dean Foster - Founding of the Commonwealth 01 - Phylogenesis [retail]\nAlan Dean Foster - Founding of the Commonwealth 02 - Dirge [retail]\nAlan Dean Foster - Founding of the Commonwealth 03 - Diuturnity's Dawn [retail]\nAlan Dean Foster - Humanx Commonwealth - Drowning World [retail]\nAlan Dean Foster - Humanx Commonwealth - Quofum [retail]\nAlan Dean Foster - Humanx Commonwealth - The Howling Stones [retail]\nAlan Dean Foster - Humanx Commonwealth 01 - Midworld [retail]\nAlan Dean Foster - Icerigger 99 - The Icerigger Trilogy [retail]\nAlan Dean Foster - Impossible Places [retail]``` etc etc. Most of it.\n_Nor Crystal Tears_ seems to be missing, which is a shame. There aren't many books about friendly insectoid aliens.",
    "y21-m05-d02",
    "feedback-discussion"
  ],
  [
    "the 3 million private investor? could be just about anything, their own reasons",
    "They already got the money back in February, I doubt that has anything to do with it.",
    "y21-m05-d02",
    "nsfw-discussion"
  ],
  [
    "<@!409511804293611530> any ideas where to discover the Merro Tree, literally only online source I could locate was amazon mass market paperback, which is intriguing tbh",
    "I tried looking yesterday, doesn't seem to be available anywhere online. Bit of a shame, since books with those themes aren't exactly common. ...I'd consider scanning it, but I have no idea where my copy is. Got too many unsorted boxes full of books...\nAnother book that I suggested was Janet Kagan's _Hellspark_, which I did find in epub format easily enough. (Though I'm not sure how the AI would react to names such as `Oloitokitok`. Tokens: `O | lo | it | ok | it | ok`. <:topkek:581961580229558295> )",
    "y21-m05-d02",
    "community-research"
  ],
  [
    "Oh! Here's one that's been rattling around in my head for a while: Why does it know about Pokemon? Does `Pokemon` or `Pok\u00e9mon` return any hits?",
    "Okay, that's lacking. This is the only one I can see there: `Pokemon Fever - Hank Schlesinger.epub              17-Jan-2020 17:34    226K`",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "Oh, here's an interesting one: What about metafiction like House of Leaves by Danielewski or People of Paper by Plascencia?",
    "First one's included, can't find the second. Neither the title nor author return anything.",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "> Some, at least. I dunno what names to look under.\ntry with those ones\nKeith R.A. DeCandido\nChristie Golden \nAaron Rosenberg\nRichard A. Knaak\nMichael A. Stackpole\nWilliam King",
    "```Genesis - Keith R. A. DeCandido.mobi               17-Jan-2020 16:11    309K\nOmen - Christie Golden.epub                        14-Jan-2020 23:08      2M\nToo Small for Tall - Aaron Rosenberg.epub          17-Jan-2020 05:53    314K\nWolfheart - Richard A. Knaak.epub                  17-Jan-2020 07:44      5M\nBlack City Demon - Richard A. Knaak.epub           17-Jan-2020 03:37    416K\nDawn of the Aspects Part I  - Richard A. Knaak...> 16-Jan-2020 12:46      4M\nDawn of the Aspects Part II - Richard A. Knaak...> 16-Jan-2020 08:34      4M\nDawn of the Aspects Part III - Richard A. Knaak..> 16-Jan-2020 13:27      3M\nDawn of the Aspects Part IV - Richard A. Knaak...> 16-Jan-2020 08:34      3M\nDawn of the Aspects Part V - Richard A. Knaak.epub 16-Jan-2020 08:32      3M\nLegends of the Dragonrealm - Richard A. Knaak.azw3 17-Jan-2020 15:21      1M\nLegends of the Dragonrealm - Richard A. Knaak.epub 17-Jan-2020 05:52      5M\nLegends of the Dragonrealm, Vol. II - Richard A..> 17-Jan-2020 15:26      1M\nLegends of the Dragonrealm, Vol. III - Richard ..> 17-Jan-2020 15:26      2M\nLegends of the Dragonrealm_ Knights of the - Ri..> 17-Jan-2020 06:08    463K\nRogue Squadron - Michael A. Stackpole.epub         15-Jan-2020 00:34      4M\nThe Bacta War - Michael A. Stackpole.epub          16-Jan-2020 03:08      4M\nIllidan - William King.epub                        17-Jan-2020 07:44      4M``` ...and a lot more. Not gonna list them all. (10 matches for Stackpole, 10 for Golden, 34 for Knaak.)",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "Bobiverse by Dennis E. Taylor ?",
    "I have no idea what that is, but... `Dennis E. Taylor - All These Worlds (Bobiverse ..> 15-Jan-2020 20:05    409K`\nAlso `Dennis Taylor - Intimate Warfare.epub              16-Jan-2020 04:05     42M`, which I assume is same author.",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "What about Asimov? or Dune?",
    "```Isaac Asimov - 10 Foundation 90 - The Foundatio..> 15-Jan-2020 23:12      6M\nIsaac Asimov - Foundation [retail].epub            16-Jan-2020 00:31      2M\nIsaac Asimov - Foundation and Empire [retail].epub 15-Jan-2020 20:02      2M\nIsaac Asimov - Foundation's Edge [retail].epub     14-Jan-2020 17:34      2M\nIsaac Asimov - I. Asimov_ A Memoir [retail].epub   16-Jan-2020 07:20      3M\nIsaac Asimov - Isaac Asimov's Guide to Earth an..> 16-Jan-2020 13:03      4M\nIsaac Asimov - Misbegotten Missionary [SS] [ret..> 14-Jan-2020 23:32      2M\nIsaac Asimov - Second Foundation [retail].epub     15-Jan-2020 20:02      2M\nIsaac Asimov - The Complete Robot.epub             16-Jan-2020 00:04    594K\nIsaac Asimov - The Martian Way [retail].epub       14-Jan-2020 23:52    538K\nIsaac Asimov's Aurora - Mark W. Tiedemann.epub     17-Jan-2020 07:30    520K\nIsaac Asimov's Guide to Earth a - Isaac Asimov...> 16-Jan-2020 08:06    645K\nIsaac Asimov's I Robot_ To Obey - Mickey Zucker..> 16-Jan-2020 16:56      1M\nIsaac Asimov's Mirage - Mark W. Tiedemann.pdf      17-Jan-2020 13:08      2M\nIsaac Asimov, Robert Silverberg - Nightfall.epub   15-Jan-2020 23:12      2M```",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "warcraft books?",
    "```World of Warcraft - Arthas - Christie Golden.mobi   17-Jan-2020 12:58    617K\nWorld of Warcraft Chronicle Volume 2.pdf           14-Jan-2020 18:47    362M\nBefore the Storm (World of Warcraft) - Christie..> 16-Jan-2020 16:10      5M\nThrall - Christie Golden.epub                      17-Jan-2020 08:25      3M``` Some, at least. I dunno what names to look under.",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "I take it the Broken Earth Trilogy isn't in there",
    "```The Fifth Season - N. K. Jemisin.azw3              16-Jan-2020 01:23    828K\nThe Obelisk Gate (The Broken Earth Book 2) - N...> 16-Jan-2020 00:05    757K\nThe Stone Sky (The Broken Earth Book 3) - N. K...> 16-Jan-2020 00:17    971K```",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "Out of curiosity, do you have your list hosted anywhere? I know it's the same thing that's on the-eye but it sounds like you made an easier to read version",
    "The list is not exactly in easy-to-read format since I only tossed them into Notepad++, but good enough for search. Tried uploading the list to justpaste, but that timed out. (It's 202709 lines long.)",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "Thanks for checking! I found all of Robert Jordan's Wheel of Time there in the list. Wish I could search the whole thing instead of going letter-by-letter. A lot of other books are already in it too.\n<@!146708005197447169> Since Books3\/Bibliotik is already in EleutherAI's The Pile it should be able to recognize the classic characters without any issue.",
    "I already checked everything. https:\/\/gitlab.com\/nolialsea\/novelaicontributions\/-\/blob\/master\/book_suggestions.md\n(Yeah, Jordan and a few of the other authors are scattered all over. Had to combine the lists to properly search it.)",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "Setting genital sizes was weird too, the AI loved to force dudes to have tiny peens.",
    "Never had this problem. ...unless I was playing as a small race, like a kobold.",
    "y21-m05-d01",
    "nsfw-discussion"
  ],
  [
    "Any chance of training the AI on Brian Jacques's Redwall series? Its another fantasy series with distinct non-human races. Could be good for training for monster or anthro protags.",
    "Some of it is in the pile: ```Brian Jacques - [Redwall 15] - Triss.epub          14-Jan-2020 21:49      1M\nBrian Jacques - [Redwall 16] - Loamhedge (retai..> 14-Jan-2020 21:50      2M\nBrian Jacques - [Redwall 17] - Rakkety Tam.epub    14-Jan-2020 21:49      1M\nBrian Jacques - [Redwall 21] - The Sable Quean...> 14-Jan-2020 22:30      2M\nBrian Jacques - [Redwall 22] - The Rogue Crew.epub 16-Jan-2020 01:44      2M```",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "To be honest, tracking book suggestions is more work than I originally thought =\/\nI can't really add everything without checking which type of book\/author\/fanfic website it is, I don't mean to censure anything, but it's so easy for people to just post what comes to their mind, it's really hard to follow and filter what is pertinent, what's already asked, what's just trolling...",
    "Here's a suggestion that got missed:\nTui T. Sutherland: the Wings of Fire series (fantasy, dragon protagonists, humans nearly nonexistent - might be good for offsetting AI's constant need to insert humans into any scene.)",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "Noli is tracking book suggestions https:\/\/discord.com\/channels\/836774308772446268\/837077266918932512\/837667041925660672",
    "Many of those book suggestions seem to already be included in the pile, in the Books3 dataset. \nAt a quick glance, pretty much all of Gaiman is in there, some Guy Gavriel Kay, dozen novels from Brandon Sanderson, one book of Jordan's Wheel of Time, some Pratchett and Banks (but not Excession), two Witcher books (one in English), Naomi Novik's Temeraire series, pretty much all of Mercedes Lackey (but no Black Gryphon)...",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "Just for future reference https:\/\/github.com\/EleutherAI\/the-pile\/tree\/master I bookmarked it",
    "Okay, that's a lot of books. And I see that some of the suggested ones are already included. Let's see... All of animorphs books, some Pratchett, some Iain Banks (but no Excession)... Will have to double-reference the list, so NovelAI doesn't get finetuned with something that's already in there.",
    "y21-m05-d01",
    "novelai-discussion"
  ],
  [
    "Or are tokens not from the training data? That's something I wasn't quite clear on when looking some of this up",
    "I'm not sure either, but if I've understood it right.. the list of tokens that the GTP2 tokenizer uses are static, and all models copied that tokenizer.",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "Yes, one of the tokens was wasted on that. I repeat, that is one token in the GPT tokenizer.",
    "That came up on Eleuther Discord yesterday, along with other useless tokens such as `GoldMagikarp`. ...I hope it motivates them into making a new tokenizer.",
    "y21-m05-d01",
    "feedback-discussion"
  ],
  [
    "That was mentioned earlier today. There are issues with copyright and formatting of RPG resources like that",
    "Again: https:\/\/discord.com\/channels\/836774308772446268\/837077266918932512\/837647789651132438",
    "y21-m05-d01",
    "feedback-suggstions"
  ],
  [
    "Was bestiality already nuked? I saw people mentioning that.",
    "They tried by banning horse and dog, but that backfired when their knight scenario bricked.",
    "y21-m05-d01",
    "novelai-discussion"
  ],
  [
    "the uniqueness of the individual tokens is more important than number *of* tokens",
    "I briefly tested that with the `umbledore` token a while back, and sure enough, AI spelled it as Dumbledore 100% of time. ...it is pretty unique as far as tokens go.",
    "y21-m04-d30",
    "community-research"
  ],
  [
    "the real challenge is compiling the training dataset",
    "I already volunteered to clean up the older D&D monstrous manuals (pruning out dice rolls, hit dice, and other terminology), just need to know if those would be useful at all. I don't want to put in the work, if they won't be included.",
    "y21-m04-d30",
    "community-research"
  ],
  [
    "I've got my eyes on sofurry for a model that would specialize in non-human understanding, (which horni sucks at in its current state). And despite its name, furry-stuff is merely a drop in the bucket on the literature written there, it's anything non-human (eg kobolds and other classic fantasy races, monstergirls, pokemon, etc), ultimately just a mass source of anything non-human.",
    "For such model, adding novels like Sutherland's _Wings of Fire_ series might work wonders. Nonhuman protagonists, with no humans whatsoever. I know they're aimed for younger audience, but that'd be offset by other data..",
    "y21-m04-d30",
    "community-research"
  ],
  [
    "I saw Zaltys even saying prose will be better",
    "Old formats won't work -- at least not without major adjustments -- due to how different Neo is. Therefore, prose will be the best 'format' in the beginning, until (if) someone finds something that works better.",
    "y21-m04-d30",
    "community-research"
  ],
  [
    "https:\/\/files.catbox.moe\/6pq8o8.png",
    "Ooh, nice. Hydrus is exactly the kind of software that I've been looking for years, thanks.",
    "y21-m04-d30",
    "novelai-discussion"
  ],
  [
    "even with a real basic WI to try and point it in the right direction:\n\n```< catkin: anthropomorphic feline folk>\n\nDetailed description of what a catkin looks like: A catkin is the cloth used to cover a woman's pubic area. It's usually made from silk dishonestly called \"silk\". The fabric has the same color as the skin vetting it for blood and other impurities. The women use them in lieu of panties, as they are more comfortable, and more practical.```",
    "This might just be because it has no idea about what 'anthropomorphic' means.",
    "y21-m04-d30",
    "nsfw-discussion"
  ],
  [
    "> though what do *these* tokens look like? Is it character clumps, or words, usually?\n<@140237240902090752> apparantlt gpt-neo uses GPT-2 tokens from one of the devs here",
    "No, I checked Eleuther. Same data, but tokenized differently. So the old token-checkers won't work, someone needs to make a new one.",
    "y21-m04-d30",
    "nsfw-discussion"
  ],
  [
    "i wonder if GPT-Neo will work differently with the existing formats",
    "AID filtered `<>` and (to lesser degree) `[]` from the output. That's the only reason why formats worked.\nTrying to use them in horni outputs the formatting nine times out of ten, not usable.",
    "y21-m04-d30",
    "novelai-discussion"
  ],
  [
    "so the starting stages will not be like Griffin or Dragon, thats what im hearing right?",
    "Definitely better than Classic, though.",
    "y21-m04-d30",
    "novelai-discussion"
  ],
  [
    "Anon data wouldn't be very useful since it would be flooded and hard to police Grammar errors to prevent them from corrupting the AI, as OpenAI and Latitude allowed to happen.",
    "Much of that was because of the repetition penalty, which is a problem in Neo too. And folks over at Eleuther seem to think that typos are required, so the AI knows how to handle those in input.",
    "y21-m04-d30",
    "novelai-discussion"
  ],
  [
    "We have no current plans to offer a Novel provided explore feature. At most, we will work with community endeavors to share content.",
    "I was talking about using old AID generated stories for training. Wouldn't want to share those as dataset, unless it's anon.",
    "y21-m04-d30",
    "novelai-discussion"
  ],
  [
    "The WI and the output have nothing in common, though. Maybe reptile=aggressive?",
    "Hm? That's just the output, not the WI.",
    "y21-m04-d30",
    "nsfw-discussion"
  ]
]